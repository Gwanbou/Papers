> [!Summary] Summary
> This repository comprises a collection of research articles relevant to ***natural language processing***, ***vision language model***, ***document processing***, and ***general AI topics***.

## DOX

<!-- AUTOGENERATED_DOX -->
- `2025 Liu` | [Structured Attention Matters to Multimodal LLMs in Document Understanding](./files/DOX/[2025%20@vivo%20Liu]%20Structured%20Attention%20Matters%20to%20Multimodal%20LLMs%20in%20Document%20Understanding.pdf) | #vivo
- `2025 Ni` | [PP-DocBee: Improving Multimodal Document Understanding Through a Bag of Tricks](./files/DOX/[2025%20@baidu%20@paddle%20Ni]%20PP-DocBee_Improving%20Multimodal%20Document%20Understanding%20Through%20a%20Bag%20of%20Tricks.pdf) | #baidu #paddle
- `2025 Chen` | [Graph-based Document Structure Analysis](./files/DOX/[2025%20@iclr%20Chen]%20Graph-based%20Document%20Structure%20Analysis.pdf) | #iclr
- `2025 Chen` | [SV-RAG: LoRA-Contextualizing Adaptation of Large Multimodal Models for Multi-page Document Understanding](./files/DOX/[2025%20@iclr%20Chen]%20SV-RAG_LoRA-Contextualizing%20Adaptation%20of%20Large%20Multimodal%20Models%20for%20Multi-page%20Document%20Understanding.pdf) | #iclr
- `2025 Faysse` | [ColPali: Efficient Document Retrieval with Vision Language Models](./files/DOX/[2025%20@iclr%20Faysse]%20ColPali_Efficient%20Document%20Retrieval%20with%20Vision%20Language%20Models.pdf) | #iclr
- `2025 Huang` | [Mini-Monkey: Alleviating the Semantic Sawtooth Effect for Lightweight MLLMs via Complementary Image Pyramid](./files/DOX/[2025%20@iclr%20Huang]%20Mini-Monkey_Alleviating%20the%20Semantic%20Sawtooth%20Effect%20for%20Lightweight%20MLLMs%20via%20Complementary%20Image%20Pyramid.pdf) | #iclr
- `2025 Morris` | [Contextual Document Embeddings](./files/DOX/[2025%20@iclr%20Morris]%20Contextual%20Document%20Embeddings.pdf) | #iclr
- `2025 Yu` | [VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents](./files/DOX/[2025%20@iclr%20Yu]%20VisRAG_Vision-based%20Retrieval-augmented%20Generation%20on%20Multi-modality%20Documents.pdf) | #iclr
- `2025 Zhu` | [Enhancing Document Understanding with Group Position Embedding: A Novel Approach to Incorporate Layout Information](./files/DOX/[2025%20@iclr%20Zhu]%20Enhancing%20Document%20Understanding%20with%20Group%20Position%20Embedding_A%20Novel%20Approach%20to%20Incorporate%20Layout%20Information.pdf) | #iclr
- `2025 Mo` | [Doc-CoB: Enhancing Multi-Modal Document Understanding with Visual Chain-of-Boxes Reasoning](./files/DOX/[2025%20@alibaba%20Mo]%20Doc-CoB_Enhancing%20Multi-Modal%20Document%20Understanding%20with%20Visual%20Chain-of-Boxes%20Reasoning.pdf) | #alibaba
- `2025 Shao` | [Is Cognition Consistent with Perception? Assessing and Mitigating Multimodal Knowledge Conflicts in Document Understanding](./files/DOX/[2025%20@alibaba%20Shao]%20Is%20Cognition%20Consistent%20with%20Perception?%20Assessing%20and%20Mitigating%20Multimodal%20Knowledge%20Conflicts%20in%20Document%20Understanding.pdf) | #alibaba
- `2025 Sampaio` | [Unsupervised Document and Template Clustering using Multimodal Embeddings](./files/DOX/[2025%20Sampaio]%20Unsupervised%20Document%20and%20Template%20Clustering%20using%20Multimodal%20Embeddings.pdf)
- `2025 Feng` | [Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting](./files/DOX/[2025%20@bytedance%20Feng]%20Dolphin_Document%20Image%20Parsing%20via%20Heterogeneous%20Anchor%20Prompting.pdf) | #bytedance
- `2024 Zhang` | [DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming](./files/DOX/[2024%20@aaai%20Zhang]%20DocKylin_A%20Large%20Multimodal%20Model%20for%20Visual%20Document%20Understanding%20with%20Efficient%20Visual%20Slimming.pdf) | #aaai
- `2025 Liskavets` | [Prompt Compression with Context-Aware Sentence Encoding for Fast and Improved LLM Inference](./files/DOX/[2025%20@aaai%20Liskavets]%20Prompt%20Compression%20with%20Context-Aware%20Sentence%20Encoding%20for%20Fast%20and%20Improved%20LLM%20Inference.pdf) | #aaai
- `2025 Li` | [GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling](./files/DOX/[2025%20Li]%20GDI-Bench_A%20Benchmark%20for%20General%20Document%20Intelligence%20with%20Vision%20and%20Reasoning%20Decoupling.pdf)
- `2025 Wang` | [CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs](./files/DOX/[2025%20@neurips%20Wang]%20CharXiv_Charting%20Gaps%20in%20Realistic%20Chart%20Understanding%20in%20Multimodal%20LLMs.pdf) | #neurips
- `2024 Zhang` | [Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction](./files/DOX/[2024%20Zhang]%20Document%20Parsing%20Unveiled_Techniques,%20Challenges,%20and%20Prospects%20for%20Structured%20Information%20Extraction.pdf)
- `2025 Le` | [QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding](./files/DOX/[2025%20Le]%20QID_Efficient%20Query-Informed%20ViTs%20in%20Data-Scarce%20Regimes%20for%20OCR-free%20Visual%20Document%20Understanding.pdf)
- `2022 Pfitzmann` | [DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis](./files/DOX/[2022%20@ibm%20Pfitzmann]%20DocLayNet_A%20Large%20Human-Annotated%20Dataset%20for%20Document-Layout%20Analysis.pdf) | #ibm
- `2025 Nassar` | [SmolDocling: An ultra-compact vision-language model for end-to-end multi-modal document conversion](./files/DOX/[2025%20@ibm%20Nassar]%20SmolDocling_An%20ultra-compact%20vision-language%20model%20for%20end-to-end%20multi-modal%20document%20conversion.pdf) | #ibm
- `2025 Ouyang` | [OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations](./files/DOX/[2025%20Ouyang]%20OmniDocBench_Benchmarking%20Diverse%20PDF%20Document%20Parsing%20with%20Comprehensive%20Annotations.pdf)
- `2025 GraniteVision` | [Granite Vision: A Lightweight, Open-Source Multimodal Model for Enterprise Intelligence](./files/DOX/[2025%20@ibm%20GraniteVision]%20Granite%20Vision_A%20Lightweight,%20Open-Source%20Multimodal%20Model%20for%20Enterprise%20Intelligence.pdf) | #ibm
- `2025 Ni` | [PP-DocBee: Improving Multimodal Document Understanding Through a Bag of Tricks](./files/DOX/[2025%20@baidu%20Ni]%20PP-DocBee_Improving%20Multimodal%20Document%20Understanding%20Through%20a%20Bag%20of%20Tricks.pdf) | #baidu
- `2025 Barboule` | [Survey on Question Answering over Visually Rich Documents: Methods, Challenges, and Trends](./files/DOX/[2025%20Barboule]%20Survey%20on%20Question%20Answering%20over%20Visually%20Rich%20Documents_Methods,%20Challenges,%20and%20Trends.pdf)
- `2025 Khang` | [KIEval: Evaluation Metric for Document Key Information Extraction](./files/DOX/[2025%20Khang]%20KIEval_Evaluation%20Metric%20for%20Document%20Key%20Information%20Extraction.pdf)
- `2025 Poznanski` | [olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models](./files/DOX/[2025%20Poznanski]%20olmOCR_Unlocking%20Trillions%20of%20Tokens%20in%20PDFs%20with%20Vision%20Language%20Models.pdf)
- `2025 Yu` | [OmniParser V2: Structured-Points-of-Thought for Unified Visual Text Parsing and Its Generality to Multimodal Large Language Models](./files/DOX/[2025%20Yu]%20OmniParser%20V2_Structured-Points-of-Thought%20for%20Unified%20Visual%20Text%20Parsing%20and%20Its%20Generality%20to%20Multimodal%20Large%20Language%20Models.pdf)
- `2024 Xu` | [Large language models for generative information extraction: a survey](./files/DOX/[2024%20Xu]%20Large%20language%20models%20for%20generative%20information%20extraction_a%20survey.pdf)
- `2025 Wasserman` | [REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark](./files/DOX/[2025%20@ibm%20Wasserman]%20REAL-MM-RAG_A%20Real-World%20Multi-Modal%20Retrieval%20Benchmark.pdf) | #ibm
- `2025 Gutteridge` | [Judge a Book by its Cover: Investigating Multi-Modal LLMs for Multi-Page Handwritten Document Transcription](./files/DOX/[2025%20Gutteridge]%20Judge%20a%20Book%20by%20its%20Cover_Investigating%20Multi-Modal%20LLMs%20for%20Multi-Page%20Handwritten%20Document%20Transcription.pdf)
- `2025 Hu` | [DocMamba: Efficient Document Pre-training with State Space Model](./files/DOX/[2025%20Hu]%20DocMamba_Efficient%20Document%20Pre-training%20with%20State%20Space%20Model.pdf)
- `2025 Suri` | [VisDoM: Multi-Document QA with Visually Rich Elements Using Multimodal Retrieval-Augmented Generation](./files/DOX/[2025%20Suri]%20VisDoM_Multi-Document%20QA%20with%20Visually%20Rich%20Elements%20Using%20Multimodal%20Retrieval-Augmented%20Generation.pdf)
- `2025 Xie` | [PDF-WuKong: A Large Multimodal Model for Efficient Long PDF Reading with End-to-End Sparse Sampling](./files/DOX/[2025%20Xie]%20PDF-WuKong_A%20Large%20Multimodal%20Model%20for%20Efficient%20Long%20PDF%20Reading%20with%20End-to-End%20Sparse%20Sampling.pdf)
- `2024 Cho` | [M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding](./files/DOX/[2024%20Cho]%20M3DocRAG_Multi-modal%20Retrieval%20is%20What%20You%20Need%20for%20Multi-page%20Multi-document%20Understanding.pdf)
- `2024 Hu` | [mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding](./files/DOX/[2024%20Hu]%20mPLUG-DocOwl2_High-resolution%20Compressing%20for%20OCR-free%20Multi-page%20Document%20Understanding.pdf)
- `2024 Deng` | [LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating](./files/DOX/[2024%20Deng]%20LongDocURL_a%20Comprehensive%20Multimodal%20Long%20Document%20Benchmark%20Integrating%20Understanding,%20Reasoning,%20and%20Locating.pdf)
- `2024 Zhang` | [SAIL: Sample-Centric In-Context Learning for Document Information Extraction](./files/DOX/[2024%20Zhang]%20SAIL_Sample-Centric%20In-Context%20Learning%20for%20Document%20Information%20Extraction.pdf)
- `2024 He` | [DR-RAG: Applying Dynamic Document Relevance to RetrievalAugmented Generation for Question-Answering](./files/DOX/[2024%20He]%20DR-RAG_Applying%20Dynamic%20Document%20Relevance%20to%20RetrievalAugmented%20Generation%20for%20Question-Answering.pdf)
- `2020 Li` | [A Survey on Deep Learning for Named Entity Recognition](./files/DOX/[2020%20Li]%20A%20Survey%20on%20Deep%20Learning%20for%20Named%20Entity%20Recognition.pdf)
- `2021 Li` | [TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models](./files/DOX/[2021%20@microsoft%20Li]%20TrOCR_Transformer-based%20Optical%20Character%20Recognition%20with%20Pre-trained%20Models.pdf) | #microsoft
- `2024 Ma` | [Unifying Multimodal Retrieval via Document Screenshot Embedding](./files/DOX/[2024%20@emnlp%20Ma]%20Unifying%20Multimodal%20Retrieval%20via%20Document%20Screenshot%20Embedding.pdf) | #emnlp
- `2023 Ren` | [Retrieve-and-Sample: Document-level Event Argument Extraction via Hybrid Retrieval Augmentation](./files/DOX/[2023%20@acl%20Ren]%20Retrieve-and-Sample_Document-level%20Event%20Argument%20Extraction%20via%20Hybrid%20Retrieval%20Augmentation.pdf) | #acl
- `2024 Wang` | [Knowledge Graph Prompting for Multi-Document Question Answering](./files/DOX/[2024%20@aaai%20Wang]%20Knowledge%20Graph%20Prompting%20for%20Multi-Document%20Question%20Answering.pdf) | #aaai
- `2024 Hui` | [UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis](./files/DOX/[2024%20Hui]%20UDA_A%20Benchmark%20Suite%20for%20Retrieval%20Augmented%20Generation%20in%20Real-world%20Document%20Analysis.pdf)
- `2023 Tang` | [Unifying Vision, Text, and Layout for Universal Document Processing](./files/DOX/[2023%20@cvpr%20@microsoft%20Tang]%20Unifying%20Vision,%20Text,%20and%20Layout%20for%20Universal%20Document%20Processing.pdf) | #cvpr #microsoft
- `2023 Wang` | [Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering](./files/DOX/[2023%20Wang]%20Layout%20and%20Task%20Aware%20Instruction%20Prompt%20for%20Zero-shot%20Document%20Image%20Question%20Answering.pdf)
- `2024 Qi` | [ADELIE: Aligning Large Language Models on Information Extraction](./files/DOX/[2024%20Qi]%20ADELIE_Aligning%20Large%20Language%20Models%20on%20Information%20Extraction.pdf)
- `2024 Li` | [ChuLo: Chunk-Level Key Information Representation for Long Document Processing](./files/DOX/[2024%20@iclr%20Li]%20ChuLo_Chunk-Level%20Key%20Information%20Representation%20for%20Long%20Document%20Processing.pdf) | #iclr
- `2024 Zhu` | [MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding](./files/DOX/[2024%20Zhu]%20MMDocBench_Benchmarking%20Large%20Vision-Language%20Models%20for%20Fine-Grained%20Visual%20Document%20Understanding.pdf)
- `2024 Adhikari` | [A Comparative Study of PDF Parsing Tools Across Diverse Document Categories](./files/DOX/[2024%20Adhikari]%20A%20Comparative%20Study%20of%20PDF%20Parsing%20Tools%20Across%20Diverse%20Document%20Categories.pdf)
- `2024 Morris` | [Contextual Document Embeddings](./files/DOX/[2024%20Morris]%20Contextual%20Document%20Embeddings.pdf)
- `2024 Lin` | [PEneo: Unifying Line Extraction, Line Grouping, and Entity Linking for End-to-end Document Pair Extraction](./files/DOX/[2024%20Lin]%20PEneo_Unifying%20Line%20Extraction,%20Line%20Grouping,%20and%20Entity%20Linking%20for%20End-to-end%20Document%20Pair%20Extraction.pdf)
- `2024 Hu` | [DocMamba: Efficient Document Pre-training with State Space Model](./files/DOX/[2024%20@aaai%20Hu]%20DocMamba_Efficient%20Document%20Pre-training%20with%20State%20Space%20Model.pdf) | #aaai
- `2024 Sinha` | [Guiding Vision-Language Model Selection for Visual Question-Answering Across Tasks, Domains, and Knowledge Types](./files/DOX/[2024%20@amazon%20Sinha]%20Guiding%20Vision-Language%20Model%20Selection%20for%20Visual%20Question-Answering%20Across%20Tasks,%20Domains,%20and%20Knowledge%20Types.pdf) | #amazon
- `2024 Hu` | [mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding](./files/DOX/[2024%20@emnlp%20@alibaba%20Hu]%20mPLUG-DocOwl%201.5_Unified%20Structure%20Learning%20for%20OCR-free%20Document%20Understanding.pdf) | #emnlp #alibaba
- `2024 Chen` | [MDCR: A Dataset for Multi-Document Conditional Reasoning](./files/DOX/[2024%20@emnlp%20@aws%20Chen]%20MDCR_A%20Dataset%20for%20Multi-Document%20Conditional%20Reasoning.pdf) | #emnlp #aws
- `2024 Buchmann` | [Attribute or Abstain: Large Language Models as Long Document Assistants](./files/DOX/[2024%20@emnlp%20Buchmann]%20Attribute%20or%20Abstain_Large%20Language%20Models%20as%20Long%20Document%20Assistants.pdf) | #emnlp
- `2024 Mass` | [More Bang for your Context: Virtual Documents for Question Answering over Long Documents](./files/DOX/[2024%20@emnlp%20Mass]%20More%20Bang%20for%20your%20Context_Virtual%20Documents%20for%20Question%20Answering%20over%20Long%20Documents.pdf) | #emnlp
- `2024 Phogat` | [Fine-tuning Smaller Language Models for Question Answering over Financial Documents](./files/DOX/[2024%20@emnlp%20Phogat]%20Fine-tuning%20Smaller%20Language%20Models%20for%20Question%20Answering%20over%20Financial%20Documents.pdf) | #emnlp
- `2024 Ye` | [GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization](./files/DOX/[2024%20@emnlp%20Ye]%20GlobeSumm_A%20Challenging%20Benchmark%20Towards%20Unifying%20Multi-lingual,%20Cross-lingual%20and%20Multi-document%20News%20Summarization.pdf) | #emnlp
- `2024 Zhang` | [Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding](./files/DOX/[2024%20@emnlp%20Zhang]%20Modeling%20Layout%20Reading%20Order%20as%20Ordering%20Relations%20for%20Visually-rich%20Document%20Understanding.pdf) | #emnlp
- `2023 Ozyurt` | [Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models](./files/DOX/[2023%20Ozyurt]%20Document-Level%20In-Context%20Few-Shot%20Relation%20Extraction%20via%20Pre-Trained%20Language%20Models.pdf)
- `2024 Wang` | [DAPR: A Benchmark on Document-Aware Passage Retrieval](./files/DOX/[2024%20@acl%20@cohere%20Wang]%20DAPR_A%20Benchmark%20on%20Document-Aware%20Passage%20Retrieval.pdf) | #acl #cohere
- `2024 Deng` | [Document-level Claim Extraction and Decontextualisation for Fact-Checking](./files/DOX/[2024%20@acl%20Deng]%20Document-level%20Claim%20Extraction%20and%20Decontextualisation%20for%20Fact-Checking.pdf) | #acl
- `2024 Gao` | [TTM-RE: Memory-Augmented Document-Level Relation Extraction](./files/DOX/[2024%20@acl%20Gao]%20TTM-RE_Memory-Augmented%20Document-Level%20Relation%20Extraction.pdf) | #acl
- `2024 Min` | [Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models](./files/DOX/[2024%20@acl%20Min]%20Synergetic%20Event%20Understanding_A%20Collaborative%20Approach%20to%20Cross-Document%20Event%20Coreference%20Resolution%20with%20Large%20Language%20Models.pdf) | #acl
- `2024 Na` | [Reward-based Input Construction for Cross-document Relation Extraction](./files/DOX/[2024%20@acl%20Na]%20Reward-based%20Input%20Construction%20for%20Cross-document%20Relation%20Extraction.pdf) | #acl
- `2024 Qi` | [End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction](./files/DOX/[2024%20@acl%20Qi]%20End-to-end%20Learning%20of%20Logical%20Rules%20for%20Enhancing%20Document-level%20Relation%20Extraction.pdf) | #acl
- `2024 Xhen` | [MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking](./files/DOX/[2024%20@acl%20Xhen]%20MetaSumPerceiver_Multimodal%20Multi-Document%20Evidence%20Summarization%20for%20Fact-Checking.pdf) | #acl
- `2024 Zhao` | [DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents](./files/DOX/[2024%20@acl%20Zhao]%20DocMath-Eval_Evaluating%20Math%20Reasoning%20Capabilities%20of%20LLMs%20in%20Understanding%20Financial%20Documents.pdf) | #acl
- `2024 Zhou` | [LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction](./files/DOX/[2024%20@acl%20Zhou]%20LLMs%20Learn%20Task%20Heuristics%20from%20Demonstrations_A%20Heuristic-Driven%20Prompting%20Strategy%20for%20Document-Level%20Event%20Argument%20Extraction.pdf) | #acl
- `2024 Zhu` | [FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models](./files/DOX/[2024%20@acl%20Zhu]%20FanOutQA_A%20Multi-Hop,%20Multi-Document%20Question%20Answering%20Benchmark%20for%20Large%20Language%20Models.pdf) | #acl
- `2024 Yang` | [FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document](./files/DOX/[2024%20@emnlp%20@adobe%20Yang]%20FIZZ_Factual%20Inconsistency%20Detection%20by%20Zoom-in%20Summary%20and%20Zoom-out%20Document.pdf) | #emnlp #adobe
- `2024 Wang` | [Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA](./files/DOX/[2024%20@emnlp%20@alibaba%20Wang]%20Leave%20No%20Document%20Behind_Benchmarking%20Long-Context%20LLMs%20with%20Extended%20Multi-Doc%20QA.pdf) | #emnlp #alibaba
- `2024 Zhuang` | [PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval](./files/DOX/[2024%20@emnlp%20Zhuang]%20PromptReps_Prompting%20Large%20Language%20Models%20to%20Generate%20Dense%20and%20Sparse%20Representations%20for%20Zero-Shot%20Document%20Retrieval.pdf) | #emnlp
- `2024 Choi` | [Model-based Preference Optimization in Abstractive Summarization without Human Feedback](./files/DOX/[2024%20Choi]%20Model-based%20Preference%20Optimization%20in%20Abstractive%20Summarization%20without%20Human%20Feedback.pdf)
- `2024 Liu` | [See then Tell: Enhancing Key Information Extraction with Vision Grounding](./files/DOX/[2024%20Liu]%20See%20then%20Tell_Enhancing%20Key%20Information%20Extraction%20with%20Vision%20Grounding.pdf)
- `2024 Li` | [Hypergraph based Understanding for Document Semantic Entity Recognition](./files/DOX/[2024%20@acl%20Li]%20Hypergraph%20based%20Understanding%20for%20Document%20Semantic%20Entity%20Recognition.pdf) | #acl
- `2024 Liao` | [DocLayLLM: An Efficient and Effective Multi-modal Extension of Large Language Models for Text-rich Document Understanding](./files/DOX/[2024%20@alibaba%20Liao]%20DocLayLLM_An%20Efficient%20and%20Effective%20Multi-modal%20Extension%20of%20Large%20Language%20Models%20for%20Text-rich%20Document%20Understanding.pdf) | #alibaba
- `2024 Xia` | [Vision Language Models for Spreadsheet Understanding: Challenges and Opportunities](./files/DOX/[2024%20@microsoft%20Xia]%20Vision%20Language%20Models%20for%20Spreadsheet%20Understanding_Challenges%20and%20Opportunities.pdf) | #microsoft
- `2024 Li` | [Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models](./files/DOX/[2024%20Li]%20Enhancing%20Visual%20Document%20Understanding%20with%20Contrastive%20Learning%20in%20Large%20Visual-Language%20Models.pdf)
- `2024 Liu` | [Fox: Focus Anywhere for Fine-grained Multi-page Document Understanding](./files/DOX/[2024%20Liu]%20Fox_Focus%20Anywhere%20for%20Fine-grained%20Multi-page%20Document%20Understanding.pdf)
- `2024 Zhao` | [TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy](./files/DOX/[2024%20Zhao]%20TabPedia_Towards%20Comprehensive%20Visual%20Table%20Understanding%20with%20Concept%20Synergy.pdf)
- `2024 Lu` | [From Text to Pixel: Advancing Long-Context Understanding in MLLMs](./files/DOX/[2024%20Lu]%20From%20Text%20to%20Pixel_Advancing%20Long-Context%20Understanding%20in%20MLLMs.pdf)
- `2024 Constantinou` | [Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification](./files/DOX/[2024%20Constantinou]%20Out-of-Distribution%20Detection%20with%20Attention%20Head%20Masking%20for%20Multimodal%20Document%20Classification.pdf)
- `2024 Perot` | [LMDX: Language Model-based Document Information Extraction and Localization](./files/DOX/[2024%20@google%20Perot]%20LMDX_Language%20Model-based%20Document%20Information%20Extraction%20and%20Localization.pdf) | #google
- `2024 Wang` | [DocLLM: A layout-aware generative language model for multimodal document understanding](./files/DOX/[2024%20@acl%20Wang]%20DocLLM_A%20layout-aware%20generative%20language%20model%20for%20multimodal%20document%20understanding.pdf) | #acl
- `2022 Wang` | [LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding](./files/DOX/[2022%20@acl%20Wang]%20LiLT_A%20Simple%20yet%20Effective%20Language-Independent%20Layout%20Transformer%20for%20Structured%20Document%20Understanding.pdf) | #acl
- `2024 Liao` | [DocTr: Document Transformer for Structured Information Extraction in Documents](./files/DOX/[2024%20@aws%20Liao]%20DocTr_Document%20Transformer%20for%20Structured%20Information%20Extraction%20in%20Documents.pdf) | #aws
- `2024 Mao` | [Visually Guided Generative Text-Layout Pre-training for Document Intelligence](./files/DOX/[2024%20Mao]%20Visually%20Guided%20Generative%20Text-Layout%20Pre-training%20for%20Document%20Intelligence.pdf)
- `2024 Abdallah` | [Transformers and Language Models in Form Understanding: A Comprehensive Review of Scanned Document Analysis](./files/DOX/[2024%20Abdallah]%20Transformers%20and%20Language%20Models%20in%20Form%20Understanding_A%20Comprehensive%20Review%20of%20Scanned%20Document%20Analysis.pdf)
- `2024 Lu` | [A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding](./files/DOX/[2024%20Lu]%20A%20Bounding%20Box%20is%20Worth%20One%20Token_Interleaving%20Layout%20and%20Text%20in%20a%20Large%20Language%20Model%20for%20Document%20Understanding.pdf)
- `2024 Mohammadshirazi` | [DocParseNet: Advanced Semantic Segmentation and OCR Embeddings for Efficient Scanned Document Annotation](./files/DOX/[2024%20Mohammadshirazi]%20DocParseNet_Advanced%20Semantic%20Segmentation%20and%20OCR%20Embeddings%20for%20Efficient%20Scanned%20Document%20Annotation.pdf)
- `2024 Futeral` | [mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus](./files/DOX/[2024%20Futeral]%20mOSCAR_A%20Large-scale%20Multilingual%20and%20Multimodal%20Document-level%20Corpus.pdf)
- `2024 Biswas` | [DocSynthv2: A Practical Autoregressive Modeling for Document Generation](./files/DOX/[2024%20Biswas]%20DocSynthv2_A%20Practical%20Autoregressive%20Modeling%20for%20Document%20Generation.pdf)
- `2024 Hsu` | [M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation](./files/DOX/[2024%20Hsu]%20M3T_A%20New%20Benchmark%20Dataset%20for%20Multi-Modal%20Document-Level%20Machine%20Translation.pdf)
- `2024 Abdallah` | [CORU: Comprehensive Post-OCR Parsing and Receipt Understanding Dataset](./files/DOX/[2024%20Abdallah]%20CORU_Comprehensive%20Post-OCR%20Parsing%20and%20Receipt%20Understanding%20Dataset.pdf)
- `2024 Wang` | [DLAFormer: An End-to-End Transformer For Document Layout Analysis](./files/DOX/[2024%20@microsoft%20Wang]%20DLAFormer_An%20End-to-End%20Transformer%20For%20Document%20Layout%20Analysis.pdf) | #microsoft
- `2024 Luo` | [LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding](./files/DOX/[2024%20@alibaba%20Luo]%20LayoutLLM_Layout%20Instruction%20Tuning%20with%20Large%20Language%20Models%20for%20Document%20Understanding.pdf) | #alibaba
- `2024 Wan` | [OmniParser: A Unified Framework for Text Spotting, Key Information Extraction and Table Recognition](./files/DOX/[2024%20@alibaba%20Wan]%20OmniParser_A%20Unified%20Framework%20for%20Text%20Spotting,%20Key%20Information%20Extraction%20and%20Table%20Recognition.pdf) | #alibaba
- `2024 Shehzadi` | [A Hybrid Approach for Document Layout Analysis in Document images](./files/DOX/[2024%20Shehzadi]%20A%20Hybrid%20Approach%20for%20Document%20Layout%20Analysis%20in%20Document%20images.pdf)
- `2018 Katti` | [Chargrid: Towards Understanding 2D Documents](./files/DOX/[2018%20@sap%20Katti]%20Chargrid_Towards%20Understanding%202D%20Documents.pdf) | #sap
- `2024 Ding` | [PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based Visual Question Answering](./files/DOX/[2024%20Ding]%20PDF-MVQA_A%20Dataset%20for%20Multimodal%20Information%20Retrieval%20in%20PDF-based%20Visual%20Question%20Answering.pdf)
- `2023 Yu` | [DocumentNet: Bridging the Data Gap in Document Pre-Training](./files/DOX/[2023%20@emnlp%20Yu]%20DocumentNet_Bridging%20the%20Data%20Gap%20in%20Document%20Pre-Training.pdf) | #emnlp
- `2024 Yu` | [TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models](./files/DOX/[2024%20Yu]%20TextHawk_Exploring%20Efficient%20Fine-Grained%20Perception%20of%20Multimodal%20Large%20Language%20Models.pdf)
- `2024 Zmigrod` | [BuDDIE: A Business Document Dataset for Multi-task Information Extraction](./files/DOX/[2024%20Zmigrod]%20BuDDIE_A%20Business%20Document%20Dataset%20for%20Multi-task%20Information%20Extraction.pdf)
- `2024 Liu` | [TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document](./files/DOX/[2024%20Liu]%20TextMonkey_An%20OCR-Free%20Large%20Multimodal%20Model%20for%20Understanding%20Document.pdf)
- `2024 Boytsov` | [Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding](./files/DOX/[2024%20Boytsov]%20Understanding%20Performance%20of%20Long-Document%20Ranking%20Models%20through%20Comprehensive%20Evaluation%20and%20Leaderboarding.pdf)
- `2024 Bronnec` | [LOCOST: State-Space Models for Long Document Abstractive Summarization](./files/DOX/[2024%20Bronnec]%20LOCOST_State-Space%20Models%20for%20Long%20Document%20Abstractive%20Summarization.pdf)
- `2019 Xu` | [LayoutLM: Pre-training of Text and Layout for Document Image Understanding](./files/DOX/[2019%20@microsoft%20Xu]%20LayoutLM_Pre-training%20of%20Text%20and%20Layout%20for%20Document%20Image%20Understanding.pdf) | #microsoft
- `2020 Reisswig` | [Chargrid-OCR: End-to-end Trainable Optical Character Recognition for Printed Documents using Instance Segmentation](./files/DOX/[2020%20@sap%20Reisswig]%20Chargrid-OCR_End-to-end%20Trainable%20Optical%20Character%20Recognition%20for%20Printed%20Documents%20using%20Instance%20Segmentation.pdf) | #sap
- `2024 Xia` | [StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding](./files/DOX/[2024%20Xia]%20StructChart_Perception,%20Structuring,%20Reasoning%20for%20Visual%20Chart%20Understanding.pdf)
- `2023 Masry` | [UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning](./files/DOX/[2023%20Masry]%20UniChart_A%20Universal%20Vision-language%20Pretrained%20Model%20for%20Chart%20Comprehension%20and%20Reasoning.pdf)
- `2023 Han` | [ChartLlama: A Multimodal LLM for Chart Understanding and Generation](./files/DOX/[2023%20Han]%20ChartLlama_A%20Multimodal%20LLM%20for%20Chart%20Understanding%20and%20Generation.pdf)
- `2023 Blecher` | [Nougat: Neural Optical Understanding for Academic Documents](./files/DOX/[2023%20@meta%20Blecher]%20Nougat_Neural%20Optical%20Understanding%20for%20Academic%20Documents.pdf) | #meta
- `2023 Wang` | [VRDU: A Benchmark for Visually-rich Document Understanding](./files/DOX/[2023%20Wang]%20VRDU_A%20Benchmark%20for%20Visually-rich%20Document%20Understanding.pdf)
<!-- AUTOGENERATED_DOX -->

## NLP

<!-- AUTOGENERATED_NLP -->
- `2023 Mueller` | [In-context Learning Generalizes, But Not Always Robustly: The Case of Syntax](./files/NLP/[2023%20@google%20Mueller]%20In-context%20Learning%20Generalizes,%20But%20Not%20Always%20Robustly_The%20Case%20of%20Syntax.pdf) | #google
- `2025 Nie` | [Large Language Diffusion Models](./files/NLP/[2025%20@alibaba%20@meetup%20Nie]%20Large%20Language%20Diffusion%20Models.pdf) | #alibaba #meetup
- `2025 Arriola` | [Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models](./files/NLP/[2025%20@meetup%20Arriola]%20Block%20Diffusion_Interpolating%20Between%20Autoregressive%20and%20Diffusion%20Language%20Models.pdf) | #meetup
- `2025 Yue` | [Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?](./files/NLP/[2025%20Yue]%20Does%20Reinforcement%20Learning%20Really%20Incentivize%20Reasoning%20Capacity%20in%20LLMs%20Beyond%20the%20Base%20Model?.pdf)
- `2025 Charakorn` | [Text-to-LoRA: Instant Transformer Adaption](./files/NLP/[2025%20@iclr%20Charakorn]%20Text-to-LoRA_Instant%20Transformer%20Adaption.pdf) | #iclr
- `2025 OppoAI` | [OAgents: An Empirical Study of Building Effective Agents](./files/NLP/[2025%20@oppo%20OppoAI]%20OAgents_An%20Empirical%20Study%20of%20Building%20Effective%20Agents.pdf) | #oppo
- `2025 Qiu` | [Alita: Generalist Agent Enabling Scalable Agentic Reasoning with Minimal Predefinition and Maximal Self-Evolution](./files/NLP/[2025%20Qiu]%20Alita_Generalist%20Agent%20Enabling%20Scalable%20Agentic%20Reasoning%20with%20Minimal%20Predefinition%20and%20Maximal%20Self-Evolution.pdf)
- `2024 Luong` | [REFT: Reasoning with REinforced Fine-Tuning](./files/NLP/[2024%20@bytedance%20Luong]%20REFT_Reasoning%20with%20REinforced%20Fine-Tuning.pdf.pdf) | #bytedance
- `2025 Chu` | [SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training](./files/NLP/[2025%20Chu]%20SFT%20Memorizes,%20RL%20Generalizes_A%20Comparative%20Study%20of%20Foundation%20Model%20Post-training.pdf)
- `2024 Liu` | [Inference-Time Language Model Alignment via Integrated Value Guidance](./files/NLP/[2024%20Liu]%20Inference-Time%20Language%20Model%20Alignment%20via%20Integrated%20Value%20Guidance.pdf)
- `2024 Wang` | [InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance](./files/NLP/[2024%20Wang]%20InferAligner_Inference-Time%20Alignment%20for%20Harmlessness%20through%20Cross-Model%20Guidance.pdf)
- `2025 Gemini` | [Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities](./files/NLP/[2025%20@google%20@gemini%20Gemini]%20Gemini%202.5_Pushing%20the%20Frontier%20with%20Advanced%20Reasoning,%20Multimodality,%20Long%20Context,%20and%20Next%20Generation%20Agentic%20Capabilities.pdf) | #google #gemini
- `2025 OpenAI` | [A Practical Guide to Building Agents](./files/NLP/[2025%20@openai%20OpenAI]%20A%20Practical%20Guide%20to%20Building%20Agents.pdf) | #openai
- `2023 Wang` | [A Survey on Large Language Model based Autonomous Agents](./files/NLP/[2023%20@agent%20Wang]%20A%20Survey%20on%20Large%20Language%20Model%20based%20Autonomous%20Agents.pdf) | #agent
- `2024 Zhang` | [A Survey on the Memory Mechanism of Large Language Model based Agents](./files/NLP/[2024%20@agent%20Zhang]%20A%20Survey%20on%20the%20Memory%20Mechanism%20of%20Large%20Language%20Model%20based%20Agents.pdf) | #agent
- `2025 Rawat` | [Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents](./files/NLP/[2025%20@agent%20Rawat]%20Pre-Act_Multi-Step%20Planning%20and%20Reasoning%20Improves%20Acting%20in%20LLM%20Agents.pdf) | #agent
- `2025 Yehudai` | [Survey on Evaluation of LLM-based Agents](./files/NLP/[2025%20@agent%20Yehudai]%20Survey%20on%20Evaluation%20of%20LLM-based%20Agents.pdf) | #agent
- `2025 Zhu` | [MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents](./files/NLP/[2025%20@agent%20Zhu]%20MultiAgentBench_Evaluating%20the%20Collaboration%20and%20Competition%20of%20LLM%20agents.pdf) | #agent
- `2025 Han` | [Reinforcement Learning from User Feedback](./files/NLP/[2025%20@meta%20Han]%20Reinforcement%20Learning%20from%20User%20Feedback.pdf) | #meta
- `2024 Chen` | [Aioli: A Unified Optimization Framework for Language Model Data Mixing](./files/NLP/[2024%20@pretrain-data%20Chen]%20Aioli_A%20Unified%20Optimization%20Framework%20for%20Language%20Model%20Data%20Mixing.pdf) | #pretrain-data
- `2024 Engstrom` | [DsDm: Model-Aware Dataset Selection with Datamodels](./files/NLP/[2024%20@pretrain-data%20Engstrom]%20DsDm_Model-Aware%20Dataset%20Selection%20with%20Datamodels.pdf) | #pretrain-data
- `2024 Jiang` | [Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws](./files/NLP/[2024%20@pretrain-data%20Jiang]%20Adaptive%20Data%20Optimization_Dynamic%20Sample%20Selection%20with%20Scaling%20Laws.pdf) | #pretrain-data
- `2024 Yu` | [MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models](./files/NLP/[2024%20@pretrain-data%20Yu]%20MATES_Model-Aware%20Data%20Selection%20for%20Efficient%20Pretraining%20with%20Data%20Influence%20Models.pdf) | #pretrain-data
- `2024 Zhang` | [Harnessing Diversity for Important Data Selection in Pretraining Large Language Models](./files/NLP/[2024%20@pretrain-data%20Zhang]%20Harnessing%20Diversity%20for%20Important%20Data%20Selection%20in%20Pretraining%20Large%20Language%20Models.pdf) | #pretrain-data
- `2024 Zhou` | [Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale](./files/NLP/[2024%20@pretrain-data%20Zhou]%20Programming%20Every%20Example_Lifting%20Pre-training%20Data%20Quality%20Like%20Experts%20at%20Scale.pdf) | #pretrain-data
- `2025 Silver` | [Welcome to the Era of Experience](./files/NLP/[2025%20@blog%20Silver]%20Welcome%20to%20the%20Era%20of%20Experience.pdf) | #blog
- `2025 Weng` | [Why We Think](./files/NLP/[2025%20@blog%20Weng]%20Why%20We%20Think.pdf) | #blog
- `2025 Zhao` | [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](./files/NLP/[2025%20Zhao]%20Absolute%20Zero_Reinforced%20Self-play%20Reasoning%20with%20Zero%20Data.pdf)
- `2024 Guo` | [Large Language Model based Multi-Agents: A Survey of Progress and Challenges](./files/NLP/[2024%20@agent%20Guo]%20Large%20Language%20Model%20based%20Multi-Agents_A%20Survey%20of%20Progress%20and%20Challenges.pdf) | #agent
- `2025 Luo` | [Large Language Model Agent: A Survey on Methodology, Applications and Challenges](./files/NLP/[2025%20@agent%20Luo]%20Large%20Language%20Model%20Agent_A%20Survey%20on%20Methodology,%20Applications%20and%20Challenges.pdf) | #agent
- `2025 Ke` | [A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems](./files/NLP/[2025%20@salesforce%20@reasoning%20@agent%20Ke]%20A%20Survey%20of%20Frontiers%20in%20LLM%20Reasoning_Inference%20Scaling,%20Learning%20to%20Reason,%20and%20Agentic%20Systems.pdf) | #salesforce #reasoning #agent
- `2024 Jimenez` | [SWE-bench: Can Language Models Resolve Real-World GitHub Issues?](./files/NLP/[2024%20@iclr%20Jimenez]%20SWE-bench_Can%20Language%20Models%20Resolve%20Real-World%20GitHub%20Issues?.pdf) | #iclr
- `2024 Li` | [DataComp-LM: In search of the next generation of training sets for language models](./files/NLP/[2024%20Li]%20DataComp-LM_In%20search%20of%20the%20next%20generation%20of%20training%20sets%20for%20language%20models.pdf)
- `2024 Durante` | [Agent AI: Surveying the Horizons of Multimodal Interaction](./files/NLP/[2024%20@agent%20Durante]%20Agent%20AI_Surveying%20the%20Horizons%20of%20Multimodal%20Interaction.pdf) | #agent
- `2024 Hao` | [Training Large Language Models to Reason in a Continuous Latent Space](./files/NLP/[2024%20@meta%20Hao]%20Training%20Large%20Language%20Models%20to%20Reason%20in%20a%20Continuous%20Latent%20Space.pdf) | #meta
- `2025 Muennighoff` | [OLMoE: Open Mixture-of-Experts Language Models](./files/NLP/[2025%20@iclr%20Muennighoff]%20OLMoE_Open%20Mixture-of-Experts%20Language%20Models.pdf) | #iclr
- `2025 Golovneva` | [Multi-Token Attention](./files/NLP/[2025%20@meta%20Golovneva]%20Multi-Token%20Attention.pdf) | #meta
- `2025 Li` | [From System 1 to System 2: A Survey of Reasoning Large Language Models](./files/NLP/[2025%20Li]%20From%20System%201%20to%20System%202_A%20Survey%20of%20Reasoning%20Large%20Language%20Models.pdf)
- `2025 Casper` | [The AI Agent Index](./files/NLP/[2025%20@agent%20Casper]%20The%20AI%20Agent%20Index.pdf) | #agent
- `2025 Cetin` | [An Evolved Universal Transformer Memory](./files/NLP/[2025%20Cetin]%20An%20Evolved%20Universal%20Transformer%20Memory.pdf)
- `2025 Wu` | [CollabLLM: From Passive Responders to Active Collaborators](./files/NLP/[2025%20Wu]%20CollabLLM_From%20Passive%20Responders%20to%20Active%20Collaborators.pdf)
- `2023 Shinn` | [Reflexion: Language Agents with Verbal Reinforcement Learning](./files/NLP/[2023%20@agent%20@meetup%20Shinn]%20Reflexion_Language%20Agents%20with%20Verbal%20Reinforcement%20Learning.pdf) | #agent #meetup
- `2024 Fourney` | [Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks](./files/NLP/[2024%20@agent%20@meetup%20Fourney]%20Magentic-One_A%20Generalist%20Multi-Agent%20System%20for%20Solving%20Complex%20Tasks.pdf) | #agent #meetup
- `2024 Liu` | [Large Language Model-Based Agents for Software Engineering: A Survey](./files/NLP/[2024%20@agent%20@meetup%20Liu]%20Large%20Language%20Model-Based%20Agents%20for%20Software%20Engineering_A%20Survey.pdf) | #agent #meetup
- `2024 Raad` | [Scaling Instructable Agents Across Many Simulated Worlds](./files/NLP/[2024%20@agent%20@meetup%20Raad]%20Scaling%20Instructable%20Agents%20Across%20Many%20Simulated%20Worlds.pdf) | #agent #meetup
- `2024 Wang` | [Chain-of-Thought Reasoning Without Prompting](./files/NLP/[2024%20@agent%20@meetup%20Wang]%20Chain-of-Thought%20Reasoning%20Without%20Prompting.pdf) | #agent #meetup
- `2024 Wu` | [ReFT: Representation Finetuning for Language Models](./files/NLP/[2024%20@agent%20@meetup%20Wu]%20ReFT_Representation%20Finetuning%20for%20Language%20Models.pdf) | #agent #meetup
- `2024 Zhuge` | [Agent-as-a-Judge: Evaluate Agents with Agents](./files/NLP/[2024%20@agent%20@meetup%20Zhuge]%20Agent-as-a-Judge_Evaluate%20Agents%20with%20Agents.pdf) | #agent #meetup
- `2024 Anthropic` | [Building Effective Agents](./files/NLP/[2024%20@anthropic%20@agent%20Anthropic]%20Building%20Effective%20Agents.pdf) | #anthropic #agent
- `2025 DeepSeek-AI` | [DeepSeek: R1](./files/NLP/[2025%20@deepseek%20DeepSeek-AI]%20DeepSeek_R1.pdf) | #deepseek
- `2024 Lee` | [Quantifying Positional Biases in Text Embedding Models](./files/NLP/[2024%20Lee]%20Quantifying%20Positional%20Biases%20in%20Text%20Embedding%20Models.pdf)
- `2023 Chen` | [Understanding Retrieval Augmentation for Long-Form Question Answering](./files/NLP/[2023%20Chen]%20Understanding%20Retrieval%20Augmentation%20for%20Long-Form%20Question%20Answering.pdf)
- `2023 Xu` | [Retrieval Meets Long Context Large Language Models](./files/NLP/[2023%20Xu]%20Retrieval%20Meets%20Long%20Context%20Large%20Language%20Models.pdf)
- `2024 Sarthi` | [RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval](./files/NLP/[2024%20Sarthi]%20RAPTOR_Recursive%20Abstractive%20Processing%20for%20Tree-Organized%20Retrieval.pdf)
- `2024 Zhang` | [RAFT: Adapting Language Model to Domain Specific RAG](./files/NLP/[2024%20Zhang]%20RAFT_Adapting%20Language%20Model%20to%20Domain%20Specific%20RAG.pdf)
- `2024 Zhang` | [Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an Entity-Centric Perspective](./files/NLP/[2024%20Zhang]%20Rethinking%20the%20Evaluation%20of%20Pre-trained%20Text-and-Layout%20Models%20from%20an%20Entity-Centric%20Perspective.pdf)
- `2024 Lin` | [RHO-1: Not All Tokens Are What You Need](./files/NLP/[2024%20@neurips%20@microsoft%20Lin]%20RHO-1_Not%20All%20Tokens%20Are%20What%20You%20Need.pdf) | #neurips #microsoft
- `2024 Ye` | [Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems](./files/NLP/[2024%20@meta%20@reflection-tuning%20Ye]%20Physics%20of%20Language%20Models_Part%202.2,%20How%20to%20Learn%20From%20Mistakes%20on%20Grade-School%20Math%20Problems.pdf) | #meta #reflection-tuning
- `2024 Gao` | [Towards a Unified View of Preference Learning for Large Language Models: A Survey](./files/NLP/[2024%20@preference-learning%20Gao]%20Towards%20a%20Unified%20View%20of%20Preference%20Learning%20for%20Large%20Language%20Models_A%20Survey.pdf) | #preference-learning
- `2024 Li` | [Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning](./files/NLP/[2024%20@reflection-tuning%20Li]%20Selective%20Reflection-Tuning_Student-Selected%20Data%20Recycling%20for%20LLM%20Instruction-Tuning.pdf) | #reflection-tuning
- `2022 Borgeaud` | [Improving language models by retrieving from trillions of tokens](./files/NLP/[2022%20@icml%20Borgeaud]%20Improving%20language%20models%20by%20retrieving%20from%20trillions%20of%20tokens.pdf) | #icml
- `2022 Izacard` | [Atlas: Few-shot Learning with Retrieval Augmented Language Models](./files/NLP/[2022%20Izacard]%20Atlas_Few-shot%20Learning%20with%20Retrieval%20Augmented%20Language%20Models.pdf)
- `2024 Edge` | [From Local to Global: A Graph RAG Approach to Query-Focused Summarization](./files/NLP/[2024%20Edge]%20From%20Local%20to%20Global_A%20Graph%20RAG%20Approach%20to%20Query-Focused%20Summarization.pdf)
- `2024 Peng` | [Graph Retrieval-Augmented Generation: A Survey](./files/NLP/[2024%20Peng]%20Graph%20Retrieval-Augmented%20Generation_A%20Survey.pdf)
- `2021 Li` | [Document-Level Event Argument Extraction by Conditional Generation](./files/NLP/[2021%20@naacl%20Li]%20Document-Level%20Event%20Argument%20Extraction%20by%20Conditional%20Generation.pdf) | #naacl
- `2023 Ram` | [In-Context Retrieval-Augmented Language Models](./files/NLP/[2023%20Ram]%20In-Context%20Retrieval-Augmented%20Language%20Models.pdf)
- `2024 Zhao` | [A Survey of Large Language Models](./files/NLP/[2024%20Zhao]%20A%20Survey%20of%20Large%20Language%20Models.pdf)
- `2022 Hernandez` | [Scaling Laws and Interpretability of Learning from Repeated Data](./files/NLP/[2022%20@anthropic%20Hernandez]%20Scaling%20Laws%20and%20Interpretability%20of%20Learning%20from%20Repeated%20Data.pdf) | #anthropic
- `2024 Liu` | [CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity](./files/NLP/[2024%20@alibaba%20Liu]%20CoFE-RAG_A%20Comprehensive%20Full-chain%20Evaluation%20Framework%20for%20Retrieval-Augmented%20Generation%20with%20Enhanced%20Data%20Diversity.pdf) | #alibaba
- `2024 Asthana` | [Enterprise Benchmarks for Large Language Model Evaluation](./files/NLP/[2024%20@ibm%20Asthana]%20Enterprise%20Benchmarks%20for%20Large%20Language%20Model%20Evaluation.pdf) | #ibm
- `2024 Tong` | [Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs](./files/NLP/[2024%20@neurips%20Tong]%20Cambrian-1_A%20Fully%20Open,%20Vision-Centric%20Exploration%20of%20Multimodal%20LLMs.pdf) | #neurips
- `2024 Hewitt` | [Instruction Following without Instruction Tuning](./files/NLP/[2024%20Hewitt]%20Instruction%20Following%20without%20Instruction%20Tuning.pdf)
- `2024 Liao` | [TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees](./files/NLP/[2024%20Liao]%20TPO_Aligning%20Large%20Language%20Models%20with%20Multi-branch%20&%20Multi-step%20Preference%20Trees.pdf)
- `2024 Ni` | [DIRAS: Efficient LLM Annotation of Document Relevance for Retrieval Augmented Generation](./files/NLP/[2024%20Ni]%20DIRAS_Efficient%20LLM%20Annotation%20of%20Document%20Relevance%20for%20Retrieval%20Augmented%20Generation.pdf)
- `2024 Sprague` | [To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning](./files/NLP/[2024%20Sprague]%20To%20CoT%20or%20not%20to%20CoT?%20Chain-of-thought%20helps%20mainly%20on%20math%20and%20symbolic%20reasoning.pdf)
- `2023 Tirumala` | [D4: Improving LLM Pretraining via Document De-Duplication and Diversification](./files/NLP/[2023%20@neurips%20@meta%20Tirumala]%20D4_Improving%20LLM%20Pretraining%20via%20Document%20De-Duplication%20and%20Diversification.pdf) | #neurips #meta
- `2023 Wang` | [DORIS-MAE: Scientific Document Retrieval using Multi-level Aspect-based Queries](./files/NLP/[2023%20@neurips%20Wang]%20DORIS-MAE_Scientific%20Document%20Retrieval%20using%20Multi-level%20Aspect-based%20Queries.pdf) | #neurips
- `2024 Zhao` | [LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration](./files/NLP/[2024%20@emnlp%20@agent%20Zhao]%20LongAgent_Scaling%20Language%20Models%20to%20128k%20Context%20through%20Multi-Agent%20Collaboration.pdf) | #emnlp #agent
- `2020 Lewis` | [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](./files/NLP/[2020%20@facebook%20Lewis]%20Retrieval-Augmented%20Generation%20for%20Knowledge-Intensive%20NLP%20Tasks.pdf) | #facebook
- `2021 Mao` | [Generation-Augmented Retrieval for Open-Domain Question Answering](./files/NLP/[2021%20@microsoft%20Mao]%20Generation-Augmented%20Retrieval%20for%20Open-Domain%20Question%20Answering.pdf) | #microsoft
- `2023 Gao` | [Retrieval-Augmented Generation for Large Language Models: A Survey](./files/NLP/[2023%20Gao]%20Retrieval-Augmented%20Generation%20for%20Large%20Language%20Models_A%20Survey.pdf)
- `2023 Jiang` | [Active Retrieval Augmented Generation](./files/NLP/[2023%20Jiang]%20Active%20Retrieval%20Augmented%20Generation.pdf)
- `2023 Liu` | [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](./files/NLP/[2023%20Liu]%20Pre-train,%20Prompt,%20and%20Predict_A%20Systematic%20Survey%20of%20Prompting%20Methods%20in%20Natural%20Language%20Processing.pdf)
- `2023 Siriwardhana` | [Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering](./files/NLP/[2023%20Siriwardhana]%20Improving%20the%20Domain%20Adaptation%20of%20Retrieval%20Augmented%20Generation%20(RAG)%20Models%20for%20Open%20Domain%20Question%20Answering.pdf)
- `2024 Chen` | [Benchmarking Large Language Models in Retrieval-Augmented Generation](./files/NLP/[2024%20@aaai%20Chen]%20Benchmarking%20Large%20Language%20Models%20in%20Retrieval-Augmented%20Generation.pdf) | #aaai
- `2024 @alibaba` | [On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models](./files/NLP/[2024%20@acl%20@alibaba]%20On%20the%20Role%20of%20Long-tail%20Knowledge%20in%20Retrieval%20Augmented%20Large%20Language%20Models.pdf) | #acl #alibaba
- `2024 Wang` | [Searching for Best Practices in Retrieval-Augmented Generation](./files/NLP/[2024%20@emnlp%20Wang]%20Searching%20for%20Best%20Practices%20in%20Retrieval-Augmented%20Generation.pdf) | #emnlp
- `2024 Parthasarathy` | [The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities](./files/NLP/[2024%20@finetuning%20Parthasarathy]%20The%20Ultimate%20Guide%20to%20Fine-Tuning%20LLMs%20from%20Basics%20to%20Breakthroughs_An%20Exhaustive%20Review%20of%20Technologies,%20Research,%20Best%20Practices,%20Applied%20Research%20Challenges%20and%20Opportunities.pdf) | #finetuning
- `2024 Tam` | [Let Me Speak Freely. A Study on the Impact of Format Restrictions on Performance of Large Language Model](./files/NLP/[2024%20Tam]%20Let%20Me%20Speak%20Freely.%20A%20Study%20on%20the%20Impact%20of%20Format%20Restrictions%20on%20Performance%20of%20Large%20Language%20Model.pdf)
- `2023 Huang` | [OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation](./files/NLP/[2023%20Huang]%20OPERA_Alleviating%20Hallucination%20in%20Multi-Modal%20Large%20Language%20Models%20via%20Over-Trust%20Penalty%20and%20Retrospection-Allocation.pdf)
- `2024 Wallace` | [The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions](./files/NLP/[2024%20Wallace]%20The%20Instruction%20Hierarchy_Training%20LLMs%20to%20Prioritize%20Privileged%20Instructions.pdf)
- `2023 Sainz` | [GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction](./files/NLP/[2023%20Sainz]%20GoLLIE_Annotation%20Guidelines%20improve%20Zero-Shot%20Information-Extraction.pdf)
- `2024 Doan` | [Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese](./files/NLP/[2024%20Doan]%20Vintern-1B_An%20Efficient%20Multimodal%20Large%20Language%20Model%20for%20Vietnamese.pdf)
- `2024 Laurencon` | [Building and better understanding vision-language models: insights and future directions](./files/NLP/[2024%20Laurencon]%20Building%20and%20better%20understanding%20vision-language%20models_insights%20and%20future%20directions.pdf)
- `2024 Ustun` | [Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model](./files/NLP/[2024%20@cohere%20Ustun]%20Aya%20Model_An%20Instruction%20Finetuned%20Open-Access%20Multilingual%20Language%20Model.pdf) | #cohere
- `2024 Qi` | [Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers](./files/NLP/[2024%20@microsoft%20Qi]%20Mutual%20Reasoning%20Makes%20Smaller%20LLMs%20Stronger%20Problem-Solvers.pdf) | #microsoft
- `2024 Lesci` | [Causal Estimation of Memorisation Profiles](./files/NLP/[2024%20Lesci]%20Causal%20Estimation%20of%20Memorisation%20Profiles.pdf)
- `2024 GeminiTeam` | [Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context](./files/NLP/[2024%20@google%20@gemini%20GeminiTeam]%20Gemini%201.5_Unlocking%20multimodal%20understanding%20across%20millions%20of%20tokens%20of%20context.pdf) | #google #gemini
- `2024 Sun` | [Learning to (Learn at Test Time): RNNs with Expressive Hidden States](./files/NLP/[2024%20Sun]%20Learning%20to%20(Learn%20at%20Test%20Time)_RNNs%20with%20Expressive%20Hidden%20States.pdf)
- `2024 Wang` | [One Prompt is not Enough: Automated Construction of a Mixture-of-Expert Prompts](./files/NLP/[2024%20Wang]%20One%20Prompt%20is%20not%20Enough_Automated%20Construction%20of%20a%20Mixture-of-Expert%20Prompts.pdf)
- `2024 Fan` | [A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models](./files/NLP/[2024%20Fan]%20A%20Survey%20on%20RAG%20Meeting%20LLMs_Towards%20Retrieval-Augmented%20Large%20Language%20Models.pdf)
- `2024 Nvidia` | [Nemotron-4 340B Technical Report](./files/NLP/[2024%20@nvidia%20Nvidia]%20Nemotron-4%20340B%20Technical%20Report.pdf) | #nvidia
- `2024 Sun` | [You Only Cache Once: Decoder-Decoder Architectures for Language Models](./files/NLP/[2024%20@microsoft%20Sun]%20You%20Only%20Cache%20Once_Decoder-Decoder%20Architectures%20for%20Language%20Models.pdf) | #microsoft
- `2019 Ziegler` | [Fine-Tuning Language Models from Human Preferences](./files/NLP/[2019%20@openai%20@rlhf%20Ziegler]%20Fine-Tuning%20Language%20Models%20from%20Human%20Preferences.pdf) | #openai #rlhf
- `2019 Raffel` | [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](./files/NLP/[2019%20@google%20@t5%20@milestone%20Raffel]%20Exploring%20the%20Limits%20of%20Transfer%20Learning%20with%20a%20Unified%20Text-to-Text%20Transformer.pdf) | #google #t5 #milestone
- `2020 Kaplan` | [Scaling Laws for Neural Language Models](./files/NLP/[2020%20@openai%20@milestone%20Kaplan]%20Scaling%20Laws%20for%20Neural%20Language%20Models.pdf) | #openai #milestone
- `2021 Hu` | [LoRA: Low-Rank Adaptation of Large Language Models](./files/NLP/[2021%20@microsoft%20@finetuning%20Hu]%20LoRA_Low-Rank%20Adaptation%20of%20Large%20Language%20Models.pdf) | #microsoft #finetuning
- `2021 Narayanan` | [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](./files/NLP/[2021%20@nvidia%20@distributed%20Narayanan]%20Efficient%20Large-Scale%20Language%20Model%20Training%20on%20GPU%20Clusters%20Using%20Megatron-LM.pdf) | #nvidia #distributed
- `2022 Liu` | [P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks](./files/NLP/[2022%20@finetuning%20Liu]%20P-Tuning%20v2_Prompt%20Tuning%20Can%20Be%20Comparable%20to%20Fine-tuning%20Universally%20Across%20Scales%20and%20Tasks.pdf) | #finetuning
- `2022 Wei` | [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](./files/NLP/[2022%20@google%20@prompt%20Wei]%20Chain-of-Thought%20Prompting%20Elicits%20Reasoning%20in%20Large%20Language%20Models.pdf) | #google #prompt
- `2022 Bommasani` | [On the Opportunities and Risks of Foundation Models](./files/NLP/[2022%20@milestone%20Bommasani]%20On%20the%20Opportunities%20and%20Risks%20of%20Foundation%20Models.pdf) | #milestone
- `2023 Weng` | [LLM Powered Autonomous Agents](./files/NLP/[2023%20@agent%20@blog%20Weng]%20LLM%20Powered%20Autonomous%20Agents.pdf) | #agent #blog
- `2023 Rafailov` | [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](./files/NLP/[2023%20@dpo%20Rafailov]%20Direct%20Preference%20Optimization_Your%20Language%20Model%20is%20Secretly%20a%20Reward%20Model.pdf) | #dpo
- `2023 Mistral` | [Mistral 7B](./files/NLP/[2023%20@mistral%20Mistral]%20Mistral%207B.pdf) | #mistral
- `2023 Chang` | [A Survey on Evaluation of Large Language Models](./files/NLP/[2023%20Chang]%20A%20Survey%20on%20Evaluation%20of%20Large%20Language%20Models.pdf)
- `2023 Kwon` | [Efficient Memory Management for Large Language Model Serving with PagedAttention](./files/NLP/[2023%20Kwon]%20Efficient%20Memory%20Management%20for%20Large%20Language%20Model%20Serving%20with%20PagedAttention.pdf)
- `2023 Schaeffer` | [Are Emergent Abilities of Large Language Models a Mirage](./files/NLP/[2023%20Schaeffer]%20Are%20Emergent%20Abilities%20of%20Large%20Language%20Models%20a%20Mirage.pdf)
- `2023 Zhao` | [A Survey of Large Language Models](./files/NLP/[2023%20Zhao]%20A%20Survey%20of%20Large%20Language%20Models.pdf)
- `2024 Munkhdalai` | [Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention](./files/NLP/[2024%20@google%20Munkhdalai]%20Leave%20No%20Context%20Behind_Efficient%20Infinite%20Context%20Transformers%20with%20Infini-attention.pdf) | #google
- `2024 Petridis` | [ConstitutionalExperts: Training a Mixture of Principle-based Prompts](./files/NLP/[2024%20@google%20Petridis]%20ConstitutionalExperts_Training%20a%20Mixture%20of%20Principle-based%20Prompts.pdf) | #google
- `2024 Gao` | [Higher Layers Need More LoRA Experts](./files/NLP/[2024%20Gao]%20Higher%20Layers%20Need%20More%20LoRA%20Experts.pdf)
- `2024 McKinzie` | [MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training](./files/NLP/[2024%20@apple%20McKinzie]%20MM1_Methods,%20Analysis%20&%20Insights%20from%20Multimodal%20LLM%20Pre-training.pdf) | #apple
- `2024 Hsieh` | [RULER: What's the Real Context Size of Your Long-Context Language Models](./files/NLP/[2024%20@nvidia%20Hsieh]%20RULER_What's%20the%20Real%20Context%20Size%20of%20Your%20Long-Context%20Language%20Models.pdf) | #nvidia
- `2024 Du` | [Understanding Emergent Abilities of Language Models from the Loss Perspective](./files/NLP/[2024%20Du]%20Understanding%20Emergent%20Abilities%20of%20Language%20Models%20from%20the%20Loss%20Perspective.pdf)
- `2024 Chen` | [Octopus v2: On-device language model for super agent](./files/NLP/[2024%20Chen]%20Octopus%20v2_On-device%20language%20model%20for%20super%20agent.pdf)
- `2024 Zhang` | [In-Context Principle Learning from Mistakes](./files/NLP/[2024%20Zhang]%20In-Context%20Principle%20Learning%20from%20Mistakes.pdf)
- `2024 Ji` | [Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction](./files/NLP/[2024%20Ji]%20Aligner_Achieving%20Efficient%20Alignment%20through%20Weak-to-Strong%20Correction.pdf)
- `2023 OpenAI` | [GPT-4 Technical Report](./files/NLP/[2023%20@openai%20@gpt4%20OpenAI]%20GPT-4%20Technical%20Report.pdf) | #openai #gpt4
- `2024 He` | [Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning](./files/NLP/[2024%20He]%20Zero-Shot%20Cross-Lingual%20Document-Level%20Event%20Causality%20Identification%20with%20Heterogeneous%20Graph%20Contrastive%20Transfer%20Learning.pdf)
- `2024 Wang` | [SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning](./files/NLP/[2024%20Wang]%20SeaEval%20for%20Multilingual%20Foundation%20Models_From%20Cross-Lingual%20Alignment%20to%20Cultural%20Reasoning.pdf)
- `2023 Sheng` | [S-LoRA: Serving Thousands of Concurrent LoRA Adapters](./files/NLP/[2023%20Sheng]%20S-LoRA_Serving%20Thousands%20of%20Concurrent%20LoRA%20Adapters.pdf)
- `2024 Ning` | [User-LLM: Efficient LLM Contextualization with User Embeddings](./files/NLP/[2024%20Ning]%20User-LLM_Efficient%20LLM%20Contextualization%20with%20User%20Embeddings.pdf)
- `2023 Yang` | [ResMem: Learn what you can and memorize the rest](./files/NLP/[2023%20@neurips%20Yang]%20ResMem_Learn%20what%20you%20can%20and%20memorize%20the%20rest.pdf) | #neurips
- `2020 Khandelwal` | [Generalization through Memorization: Nearest Neighbor Language Models](./files/NLP/[2020%20@iclr%20Khandelwal]%20Generalization%20through%20Memorization_Nearest%20Neighbor%20Language%20Models.pdf) | #iclr
- `2023 Jacovi` | [Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks](./files/NLP/[2023%20@emnlp%20Jacovi]%20Stop%20Uploading%20Test%20Data%20in%20Plain%20Text_Practical%20Strategies%20for%20Mitigating%20Data%20Contamination%20by%20Evaluation%20Benchmarks.pdf) | #emnlp
- `2023 Chen` | [ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up](./files/NLP/[2023%20Chen]%20ChatGPT's%20One-year%20Anniversary_Are%20Open-Source%20Large%20Language%20Models%20Catching%20up.pdf)
- `2017 Vaswani` | [Attention Is All You Need](./files/NLP/[2017%20@google%20@milestone%20Vaswani]%20Attention%20Is%20All%20You%20Need.pdf) | #google #milestone
- `2023 Dankers` | [Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation](./files/NLP/[2023%20@emnlp%20Dankers]%20Memorisation%20Cartography_Mapping%20out%20the%20Memorisation-Generalisation%20Continuum%20in%20Neural%20Machine%20Translation.pdf) | #emnlp
- `2023 Wang` | [Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning](./files/NLP/[2023%20@emnlp%20Wang]%20Label%20Words%20are%20Anchors_An%20Information%20Flow%20Perspective%20for%20Understanding%20In-Context%20Learning.pdf) | #emnlp
- `2023 Google` | [Gemini: A Family of Highly Capable Multimodal Models](./files/NLP/[2023%20@google%20Google]%20Gemini_A%20Family%20of%20Highly%20Capable%20Multimodal%20Models.pdf) | #google
- `2023 Liu` | [G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment](./files/NLP/[2023%20@emnlp%20Liu]%20G-EVAL_NLG%20Evaluation%20using%20GPT-4%20with%20Better%20Human%20Alignment.pdf) | #emnlp
- `2023 Goyal` | [News Summarization and Evaluation in the Era of GPT-3](./files/NLP/[2023%20Goyal]%20News%20Summarization%20and%20Evaluation%20in%20the%20Era%20of%20GPT-3.pdf)
- `2023 He` | [AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators](./files/NLP/[2023%20He]%20AnnoLLM_Making%20Large%20Language%20Models%20to%20Be%20Better%20Crowdsourced%20Annotators.pdf)
- `2023 Li` | [CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation](./files/NLP/[2023%20Li]%20CoAnnotating_Uncertainty-Guided%20Work%20Allocation%20between%20Human%20and%20Large%20Language%20Models%20for%20Data%20Annotation.pdf)
- `2023 Long` | [Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning](./files/NLP/[2023%20Long]%20Adapt%20in%20Contexts_Retrieval-Augmented%20Domain%20Adaptation%20via%20In-Context%20Learning.pdf)
- `2023 Shaikh` | [On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning](./files/NLP/[2023%20Shaikh]%20On%20Second%20Thought,%20Let's%20Not%20Think%20Step%20by%20Step!%20Bias%20and%20Toxicity%20in%20Zero-Shot%20Reasoning.pdf)
- `2023 He` | [Simplifying Transformer Blocks](./files/NLP/[2023%20He]%20Simplifying%20Transformer%20Blocks.pdf)
- `2022 Min` | [Rethinking the Role of Demonstrations: What Makes In-Context Learning Work](./files/NLP/[2022%20@emnlp%20Min]%20Rethinking%20the%20Role%20of%20Demonstrations_What%20Makes%20In-Context%20Learning%20Work.pdf) | #emnlp
- `2020 Guu` | [REALM: Retrieval-Augmented Language Model Pre-Training](./files/NLP/[2020%20@google%20Guu]%20REALM_Retrieval-Augmented%20Language%20Model%20Pre-Training.pdf) | #google
- `2021 Das` | [Case-Based Reasoning for Natural Language Queries over Knowledge Bases](./files/NLP/[2021%20Das]%20Case-Based%20Reasoning%20for%20Natural%20Language%20Queries%20over%20Knowledge%20Bases.pdf)
- `2022 Borgeaud` | [Improving language models by retrieving from trillions of tokens](./files/NLP/[2022%20@deepmind%20Borgeaud]%20Improving%20language%20models%20by%20retrieving%20from%20trillions%20of%20tokens.pdf) | #deepmind
- `2022 Wang` | [Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data](./files/NLP/[2022%20@microsoft%20Wang]%20Training%20Data%20is%20More%20Valuable%20than%20You%20Think_A%20Simple%20and%20Effective%20Method%20by%20Retrieving%20from%20Training%20Data.pdf) | #microsoft
- `2023 Bommasani` | [The Foundation Model Transparency Index](./files/NLP/[2023%20Bommasani]%20The%20Foundation%20Model%20Transparency%20Index.pdf)
- `2023 Shi` | [In-Context Pretraining: Language Modeling Beyond Document Boundaries](./files/NLP/[2023%20Shi]%20In-Context%20Pretraining_Language%20Modeling%20Beyond%20Document%20Boundaries.pdf)
- `2024 Sun` | [Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models](./files/NLP/[2024%20@iclr%20Sun]%20Enhancing%20Chain-of-Thoughts%20Prompting%20with%20Iterative%20Bootstrapping%20in%20Large%20Language%20Models.pdf) | #iclr
- `2021 Huang` | [WhiteningBERT: An Easy Unsupervised Sentence Embedding Approach](./files/NLP/[2021%20Huang]%20WhiteningBERT_An%20Easy%20Unsupervised%20Sentence%20Embedding%20Approach.pdf)
- `2023 Xiong` | [Effective Long-Context Scaling of Foundation Models](./files/NLP/[2023%20@meta%20Xiong]%20Effective%20Long-Context%20Scaling%20of%20Foundation%20Models.pdf) | #meta
- `2023 Yang` | [Large Language Models as Optimizers](./files/NLP/[2023%20@google%20Yang]%20Large%20Language%20Models%20as%20Optimizers.pdf) | #google
- `2023 Yao` | [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](./files/NLP/[2023%20Yao]%20Tree%20of%20Thoughts_Deliberate%20Problem%20Solving%20with%20Large%20Language%20Models.pdf)
- `2023 Sun` | [Retentive Network: A Successor to Transformer for Large Language Models](./files/NLP/[2023%20@microsoft%20Sun]%20Retentive%20Network_A%20Successor%20to%20Transformer%20for%20Large%20Language%20Models.pdf) | #microsoft
- `2023 Kaddour` | [Challenges and Applications of Large Language Models](./files/NLP/[2023%20Kaddour]%20Challenges%20and%20Applications%20of%20Large%20Language%20Models.pdf)
- `2018 Devlin` | [BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding](./files/NLP/[2018%20@google%20@milestone%20Devlin]%20BERT_Pre-Training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding.pdf) | #google #milestone
- `2019 Dai` | [Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context](./files/NLP/[2019%20@acl%20Dai]%20Transformer-XL_Attentive%20Language%20Models%20Beyond%20a%20Fixed-Length%20Context.pdf) | #acl
- `2019 Wang` | [GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding](./files/NLP/[2019%20@iclr%20Wang]%20GLUE_A%20Multi-Task%20Benchmark%20and%20Analysis%20Platform%20for%20Natural%20Language%20Understanding.pdf) | #iclr
- `2019 Liu` | [RoBERTa: A Robustly Optimized BERT Pretraining Approach](./files/NLP/[2019%20@meta%20Liu]%20RoBERTa_A%20Robustly%20Optimized%20BERT%20Pretraining%20Approach.pdf) | #meta
- `2019 Wang` | [SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding](./files/NLP/[2019%20@neurips%20Wang]%20SuperGLUE_A%20Stickier%20Benchmark%20for%20General-Purpose%20Language%20Understanding.pdf) | #neurips
- `2022 Chowdhery` | [PaLM: Scaling Language Modeling with Pathways](./files/NLP/[2022%20@google%20Chowdhery]%20PaLM_Scaling%20Language%20Modeling%20with%20Pathways.pdf) | #google
- `2023 Lee` | [RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback](./files/NLP/[2023%20@google%20@rlhf%20Lee]%20RLAIF_Scaling%20Reinforcement%20Learning%20from%20Human%20Feedback%20with%20AI%20Feedback.pdf) | #google #rlhf
- `2023 Schick` | [Toolformer: Language Models Can Teach Themselves to Use Tools](./files/NLP/[2023%20@meta%20Schick]%20Toolformer_Language%20Models%20Can%20Teach%20Themselves%20to%20Use%20Tools.pdf) | #meta
- `2023 Chang` | [Learning to Generate Better Than Your LLM](./files/NLP/[2023%20Chang]%20Learning%20to%20Generate%20Better%20Than%20Your%20LLM.pdf)
- `2023 Yin` | [A Survey on Multimodal Large Language Models](./files/NLP/[2023%20Yin]%20A%20Survey%20on%20Multimodal%20Large%20Language%20Models.pdf)
- `2020 Gururangan` | [Don't Stop Pretraining: Adapt Language Models to Domains and Tasks](./files/NLP/[2020%20@acl%20Gururangan]%20Don't%20Stop%20Pretraining_Adapt%20Language%20Models%20to%20Domains%20and%20Tasks.pdf) | #acl
- `2023 Touvron` | [LLaMA 2: Open Foundation and Fine-Tuned Chat Models](./files/NLP/[2023%20@meta%20@llama2%20Touvron]%20LLaMA%202_Open%20Foundation%20and%20Fine-Tuned%20Chat%20Models.pdf) | #meta #llama2
- `2023 Zhou` | [Large Language Models Are Human-Level Prompt Engineers](./files/NLP/[2023%20@iclr%20Zhou]%20Large%20Language%20Models%20Are%20Human-Level%20Prompt%20Engineers.pdf) | #iclr
- `2023 Touvron` | [LLaMA: Open and Efficient Foundation Language Models](./files/NLP/[2023%20@meta%20@lama%20Touvron]%20LLaMA_Open%20and%20Efficient%20Foundation%20Language%20Models.pdf) | #meta #lama
- `2023 Cai` | [Large Language Models as Tool Makers](./files/NLP/[2023%20@google%20Cai]%20Large%20Language%20Models%20as%20Tool%20Makers.pdf) | #google
- `2023 Patil` | [Gorilla: Large Language Model Connected with Massive APIs](./files/NLP/[2023%20Patil]%20Gorilla_Large%20Language%20Model%20Connected%20with%20Massive%20APIs.pdf)
- `2022 Ouyang` | [Training language models to follow instructions with human feedback](./files/NLP/[2022%20@openai%20@rlhf%20Ouyang]%20Training%20language%20models%20to%20follow%20instructions%20with%20human%20feedback.pdf) | #openai #rlhf
- `2019 Yang` | [XLNet: Generalized Autoregressive Pretraining for Language Understanding](./files/NLP/[2019%20@neurips%20Yang]%20XLNet_Generalized%20Autoregressive%20Pretraining%20for%20Language%20Understanding.pdf) | #neurips
- `2021 Liu` | [Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing](./files/NLP/[2021%20Liu]%20Pre-train,%20Prompt,%20and%20Predict_A%20Systematic%20Survey%20of%20Prompting%20Methods%20in%20Natural%20Language%20Processing.pdf)
- `2013 Mikolov` | [Distributed Representations of Words and Phrases and their Compositionality](./files/NLP/[2013%20Mikolov]%20Distributed%20Representations%20of%20Words%20and%20Phrases%20and%20their%20Compositionality.pdf)
- `2013 Mikolov` | [Efficient Estimation of Word Representations in Vector Space](./files/NLP/[2013%20Mikolov]%20Efficient%20Estimation%20of%20Word%20Representations%20in%20Vector%20Space.pdf)
- `2018 Radford` | [Improving Language Understanding by Generative Pre-Training](./files/NLP/[2018%20@openai%20@gpt%20@milestone%20Radford]%20Improving%20Language%20Understanding%20by%20Generative%20Pre-Training.pdf) | #openai #gpt #milestone
- `2019 Radford` | [Language Models are Unsupervised Multitask Learners](./files/NLP/[2019%20@openai%20@gpt2%20Radford]%20Language%20Models%20are%20Unsupervised%20Multitask%20Learners.pdf) | #openai #gpt2
- `2020 Brown` | [Language Models are Few-Shot Learners](./files/NLP/[2020%20@openai%20@gpt3%20Brown]%20Language%20Models%20are%20Few-Shot%20Learners.pdf) | #openai #gpt3
<!-- AUTOGENERATED_NLP -->

## Multimodal

<!-- AUTOGENERATED_MM -->
- `2025 Cui` | [PaddleOCR 3.0 Technical Report](./files/MM/[2025%20@baidu%20@paddle%20Cui]%20PaddleOCR%203.0%20Technical%20Report.pdf) | #baidu #paddle
- `2025 Meng` | [VLM2Vec-V2: Advancing Multimodal Embedding for Videos, Images, and Visual Documents](./files/MM/[2025%20@salesforce%20Meng]%20VLM2Vec-V2_Advancing%20Multimodal%20Embedding%20for%20Videos,%20Images,%20and%20Visual%20Documents.pdf) | #salesforce
- `2025 KwaiKeye` | [Kwai Keye-VL Technical Report](./files/MM/[2025%20KwaiKeye]%20Kwai%20Keye-VL%20Technical%20Report.pdf)
- `2025 He` | [Seeing is Believing? Mitigating OCR Hallucinations in Multimodal Large Language Models](./files/MM/[2025%20@bytedance%20He]%20Seeing%20is%20Believing?%20Mitigating%20OCR%20Hallucinations%20in%20Multimodal%20Large%20Language%20Models.pdf) | #bytedance
- `2025 Wu` | [MMSearch-R1: Incentivizing LMMs to Search](./files/MM/[2025%20@bytedance%20Wu]%20MMSearch-R1_Incentivizing%20LMMs%20to%20Search.pdf) | #bytedance
- `2025 Liu` | [VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning](./files/MM/[2025%20Liu]%20VisionReasoner_Unified%20Visual%20Perception%20and%20Reasoning%20via%20Reinforcement%20Learning.pdf)
- `2025 Neo` | [Towards Interpreting Visual Information Processing in Vision-Language Models](./files/MM/[2025%20@iclr%20Neo]%20Towards%20Interpreting%20Visual%20Information%20Processing%20in%20Vision-Language%20Models.pdf) | #iclr
- `2025 Yang` | [SWE-Bench Multimodal: Do AI Systems Generalize to Visual Software Domains?](./files/MM/[2025%20@iclr%20Yang]%20SWE-Bench%20Multimodal_Do%20AI%20Systems%20Generalize%20to%20Visual%20Software%20Domains?.pdf) | #iclr
- `2024 Li` | [Multimodal Alignment and Fusion: A Survey](./files/MM/[2024%20Li]%20Multimodal%20Alignment%20and%20Fusion_A%20Survey.pdf)
- `2024 Wardle` | [Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks](./files/MM/[2024%20Wardle]%20Image%20First%20or%20Text%20First?%20Optimising%20the%20Sequencing%20of%20Modalities%20in%20Large%20Language%20Model%20Prompting%20and%20Reasoning%20Tasks.pdf)
- `2025 Feng` | [Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting](./files/MM/[2025%20@bytedance%20Feng]%20Dolphin_Document%20Image%20Parsing%20via%20Heterogeneous%20Anchor%20Prompting.pdf) | #bytedance
- `2025 Wang` | [Vision as LoRA](./files/MM/[2025%20@bytedance%20Wang]%20Vision%20as%20LoRA.pdf) | #bytedance
- `2025 Arif` | [HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models](./files/MM/[2025%20@aaai%20Arif]%20HiRED_Attention-Guided%20Token%20Dropping%20for%20Efficient%20Inference%20of%20High-Resolution%20Vision-Language%20Models.pdf) | #aaai
- `2025 Rang` | [Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts](./files/MM/[2025%20@aaai%20Rang]%20Eve_Efficient%20Multimodal%20Vision%20Language%20Models%20with%20Elastic%20Visual%20Experts.pdf) | #aaai
- `2025 Guo` | [Seed1.5-VL Technical Report](./files/MM/[2025%20@bytedance%20Guo]%20Seed1.5-VL%20Technical%20Report.pdf) | #bytedance
- `2025 Chen` | [BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset](./files/MM/[2025%20@salesforce%20Chen]%20BLIP3-o_A%20Family%20of%20Fully%20Open%20Unified%20Multimodal%20Models-Architecture,%20Training%20and%20Dataset.pdf) | #salesforce
- `2025 Xu` | [Visual Planning: Let's Think Only with Images](./files/MM/[2025%20Xu]%20Visual%20Planning_Let's%20Think%20Only%20with%20Images.pdf)
- `2023 Bai` | [Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond](./files/MM/[2023%20@alibaba%20@qwen-vl%20Bai]%20Qwen-VL_A%20Versatile%20Vision-Language%20Model%20for%20Understanding,%20Localization,%20Text%20Reading,%20and%20Beyond.pdf) | #alibaba #qwen-vl
- `2025 QwenTeam` | [Qwen2.5-VL Technical Report](./files/MM/[2025%20@qwen2-5-vl%20QwenTeam]%20Qwen2.5-VL%20Technical%20Report.pdf) | #qwen2-5-vl
- `2025 Wolf` | [CM1 - A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models](./files/MM/[2025%20Wolf]%20CM1%20-%20A%20Dataset%20for%20Evaluating%20Few-Shot%20Information%20Extraction%20with%20Large%20Vision%20Language%20Models.pdf)
- `2025 KimiTeam` | [Kimi-VL Technical Report](./files/MM/[2025%20@kimi%20KimiTeam]%20Kimi-VL%20Technical%20Report.pdf) | #kimi
- `2025 Li` | [Imagine while Reasoning in Space: Multimodal Visualization-of-Thought](./files/MM/[2025%20@microsoft%20Li]%20Imagine%20while%20Reasoning%20in%20Space_Multimodal%20Visualization-of-Thought.pdf) | #microsoft
- `2025 Zhu` | [InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models](./files/MM/[2025%20@internvl-3%20Zhu]%20InternVL3_Exploring%20Advanced%20Training%20and%20Test-Time%20Recipes%20for%20Open-Source%20Multimodal%20Models.pdf) | #internvl-3
- `2025 QwenTeam` | [Qwen2.5-Omni Technical Report](./files/MM/[2025%20@qwen2-5-omni%20QwenTeam]%20Qwen2.5-Omni%20Technical%20Report.pdf) | #qwen2-5-omni
- `2025 Lu` | [InternVL-X: Advancing and Accelerating InternVL Series with Efficient Visual Token Compression](./files/MM/[2025%20Lu]%20InternVL-X_Advancing%20and%20Accelerating%20InternVL%20Series%20with%20Efficient%20Visual%20Token%20Compression.pdf)
- `2024 Lin` | [MoE-LLaVA: Mixture of Experts for Large Vision-Language Models](./files/MM/[2024%20Lin]%20MoE-LLaVA_Mixture%20of%20Experts%20for%20Large%20Vision-Language%20Models.pdf)
- `2024 Chen` | [Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling](./files/MM/[2024%20@internvl-2-5%20Chen]%20Expanding%20Performance%20Boundaries%20of%20Open-Source%20Multimodal%20Models%20with%20Model,%20Data,%20and%20Test-Time%20Scaling.pdf) | #internvl-2-5
- `2025 Yang` | [Magma: A Foundation Model for Multimodal AI Agents](./files/MM/[2025%20@microsoft%20Yang]%20Magma_A%20Foundation%20Model%20for%20Multimodal%20AI%20Agents.pdf) | #microsoft
- `2024 Chen` | [How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites](./files/MM/[2024%20@internvl-1-5%20Chen]%20How%20Far%20Are%20We%20to%20GPT-4V?%20Closing%20the%20Gap%20to%20Commercial%20Multimodal%20Models%20with%20Open-Source%20Suites.pdf) | #internvl-1-5
- `2024 Gao` | [Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance](./files/MM/[2024%20@mini-internvl%20Gao]%20Mini-InternVL_A%20Flexible-Transfer%20Pocket%20Multimodal%20Model%20with%205%%20Parameters%20and%2090%%20Performance.pdf) | #mini-internvl
- `2024 Masry` | [ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning](./files/MM/[2024%20Masry]%20ChartInstruct_Instruction%20Tuning%20for%20Chart%20Comprehension%20and%20Reasoning.pdf)
- `2024 Chen` | [Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey](./files/MM/[2024%20Chen]%20Next%20Token%20Prediction%20Towards%20Multimodal%20Intelligence_A%20Comprehensive%20Survey.pdf)
- `2024 Wang` | [Qwen2-VL: Enhancing Vision-Language Models Perception of the World at Any Resolution](./files/MM/[2024%20@alibaba%20@qwen2-vl%20Wang]%20Qwen2-VL_Enhancing%20Vision-Language%20Models%20Perception%20of%20the%20World%20at%20Any%20Resolution.pdf) | #alibaba #qwen2-vl
- `2023 Zhao` | [Retrieving Multimodal Information for Augmented Generation: A Survey](./files/MM/[2023%20@emnlp%20Zhao]%20Retrieving%20Multimodal%20Information%20for%20Augmented%20Generation_A%20Survey.pdf) | #emnlp
- `2024 Yu` | [VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents](./files/MM/[2024%20Yu]%20VisRAG_Vision-based%20Retrieval-augmented%20Generation%20on%20Multi-modality%20Documents.pdf)
- `2024 Zong` | [MoVA: Adapting Mixture of Vision Experts to Multimodal Context](./files/MM/[2024%20@mmlab%20Zong]%20MoVA_Adapting%20Mixture%20of%20Vision%20Experts%20to%20Multimodal%20Context.pdf) | #mmlab
- `2024 Zhou` | [Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model](./files/MM/[2024%20@meta%20Zhou]%20Transfusion_Predict%20the%20Next%20Token%20and%20Diffuse%20Images%20with%20One%20Multi-Modal%20Model.pdf) | #meta
- `2024 Gou` | [Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation](./files/MM/[2024%20Gou]%20Eyes%20Closed,%20Safety%20On_Protecting%20Multimodal%20LLMs%20via%20Image-to-Text%20Transformation.pdf)
- `2024 Yang` | [Law of Vision Representation in MLLMs](./files/MM/[2024%20Yang]%20Law%20of%20Vision%20Representation%20in%20MLLMs.pdf)
- `2023 Lin` | [LayoutPrompter: Awaken the Design Ability of Large Language Models](./files/MM/[2023%20@neurips%20@microsoft%20Lin]%20LayoutPrompter_Awaken%20the%20Design%20Ability%20of%20Large%20Language%20Models.pdf) | #neurips #microsoft
- `2024 Bordes` | [An Introduction to Vision-Language Modeling](./files/MM/[2024%20@meta%20Bordes]%20An%20Introduction%20to%20Vision-Language%20Modeling.pdf) | #meta
- `2024 Fuest` | [Diffusion Models and Representation Learning: A Survey](./files/MM/[2024%20Fuest]%20Diffusion%20Models%20and%20Representation%20Learning_A%20Survey.pdf)
- `2021 Dosovitskiy` | [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](./files/MM/[2021%20@google%20@vit%20Dosovitskiy]%20An%20Image%20is%20Worth%2016x16%20Words_Transformers%20for%20Image%20Recognition%20at%20Scale.pdf) | #google #vit
- `2021 Liu` | [Swin Transformer V2: Scaling Up Capacity and Resolution](./files/MM/[2021%20@microsoft%20@swin%20Liu]%20Swin%20Transformer%20V2_Scaling%20Up%20Capacity%20and%20Resolution.pdf) | #microsoft #swin
- `2021 Liu` | [Swin Transformer: Hierarchical Vision Transformer using Shifted Windows](./files/MM/[2021%20@microsoft%20@swin%20Liu]%20Swin%20Transformer_Hierarchical%20Vision%20Transformer%20using%20Shifted%20Windows.pdf) | #microsoft #swin
- `2021 Radford` | [Learning Transferable Visual Models From Natural Language Supervision](./files/MM/[2021%20@openai%20@clip%20Radford]%20Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision.pdf) | #openai #clip
- `2021 Rombach` | [High-Resolution Image Synthesis with Latent Diffusion Models](./files/MM/[2021%20@stable-diffusion%20Rombach]%20High-Resolution%20Image%20Synthesis%20with%20Latent%20Diffusion%20Models.pdf) | #stable-diffusion
- `2022 Peebles` | [Scalable Diffusion Models with Transformers](./files/MM/[2022%20@dit%20@sora%20Peebles]%20Scalable%20Diffusion%20Models%20with%20Transformers.pdf) | #dit #sora
- `2023 Li` | [Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models](./files/MM/[2023%20@cvpr%20Li]%20Monkey_Image%20Resolution%20and%20Text%20Label%20Are%20Important%20Things%20for%20Large%20Multi-modal%20Models.pdf) | #cvpr
- `2024 Cheng` | [YOLO-World: Real-Time Open-Vocabulary Object Detection](./files/MM/[2024%20Cheng]%20YOLO-World_Real-Time%20Open-Vocabulary%20Object%20Detection.pdf)
- `2023 Bai` | [Sequential Modeling Enables Scalable Learning for Large Vision Models](./files/MM/[2023%20Bai]%20Sequential%20Modeling%20Enables%20Scalable%20Learning%20for%20Large%20Vision%20Models.pdf)
<!-- AUTOGENERATED_MM -->

## UNSORTED

<!-- AUTOGENERATED_UNSORTED -->
- `2025 Shen` | [ACL'25 HELM](./files/UNSORTED/[2025%20@sap%20Shen]%20ACL'25%20HELM.pdf) | #sap
- `2024 HAI` | [AI Index Report 2024](./files/UNSORTED/[2024%20HAI]%20AI%20Index%20Report%202024.pdf)
- `2023 Liu` | [iTransformer: Inverted Transformers Are Effective for Time Series Forecasting](./files/UNSORTED/[2023%20Liu]%20iTransformer_Inverted%20Transformers%20Are%20Effective%20for%20Time%20Series%20Forecasting.pdf)
<!-- AUTOGENERATED_UNSORTED -->
