<h1 align="center">
Paper Vault
</h1>
<p align="center">
:bulb: This repository comprises a collection of research articles relevant to <i><b>natural language processing</i></b>, <i><b>deep tabular model</i></b>, <i><b>knowledge graph</i></b>, and <i><b>general AI topics</i></b>. Please feel free to create a PR if you come across any interesting papers. :raised_hands:
</p>


## :newspaper_roll: DOX

<!-- AUTOGENERATED_DOX -->
- [ ] [:link:](./files/DOX/[2018%20@sap%20Katti]%20Chargrid_Towards%20Understanding%202D%20Documents.pdf)
  Chargrid: Towards Understanding 2D Documents
  ![year](https://img.shields.io/badge/2018-green?style=flat)
  ![auth](https://img.shields.io/badge/Katti-red?style=flat)
  ![tags](https://img.shields.io/badge/sap-blue?style=flat)
- [ ] [:link:](./files/DOX/[2019%20@microsoft%20Xu]%20LayoutLM_Pre-training%20of%20Text%20and%20Layout%20for%20Document%20Image%20Understanding.pdf)
  LayoutLM: Pre-training of Text and Layout for Document Image Understanding
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Xu-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/DOX/[2020%20@sap%20Reisswig]%20Chargrid-OCR_End-to-end%20Trainable%20Optical%20Character%20Recognition%20for%20Printed%20Documents%20using%20Instance%20Segmentation.pdf)
  Chargrid-OCR: End-to-end Trainable Optical Character Recognition for Printed Documents using Instance Segmentation
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Reisswig-red?style=flat)
  ![tags](https://img.shields.io/badge/sap-blue?style=flat)
- [ ] [:link:](./files/DOX/[2020%20Li]%20A%20Survey%20on%20Deep%20Learning%20for%20Named%20Entity%20Recognition.pdf)
  A Survey on Deep Learning for Named Entity Recognition
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
- [ ] [:link:](./files/DOX/[2021%20@microsoft%20Li]%20TrOCR_Transformer-based%20Optical%20Character%20Recognition%20with%20Pre-trained%20Models.pdf)
  TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/DOX/[2022%20@acl%20Wang]%20LiLT_A%20Simple%20yet%20Effective%20Language-Independent%20Layout%20Transformer%20for%20Structured%20Document%20Understanding.pdf)
  LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2023%20@acl%20Ren]%20Retrieve-and-Sample_Document-level%20Event%20Argument%20Extraction%20via%20Hybrid%20Retrieval%20Augmentation.pdf)
  Retrieve-and-Sample: Document-level Event Argument Extraction via Hybrid Retrieval Augmentation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ren-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2023%20@cvpr%20@microsoft%20Tang]%20Unifying%20Vision,%20Text,%20and%20Layout%20for%20Universal%20Document%20Processing.pdf)
  Unifying Vision, Text, and Layout for Universal Document Processing
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Tang-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/DOX/[2023%20@emnlp%20Yu]%20DocumentNet_Bridging%20the%20Data%20Gap%20in%20Document%20Pre-Training.pdf)
  DocumentNet: Bridging the Data Gap in Document Pre-Training
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yu-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2023%20@meta%20Blecher]%20Nougat_Neural%20Optical%20Understanding%20for%20Academic%20Documents.pdf)
  Nougat: Neural Optical Understanding for Academic Documents
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Blecher-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/DOX/[2023%20Han]%20ChartLlama_A%20Multimodal%20LLM%20for%20Chart%20Understanding%20and%20Generation.pdf)
  ChartLlama: A Multimodal LLM for Chart Understanding and Generation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Han-red?style=flat)
- [ ] [:link:](./files/DOX/[2023%20Masry]%20UniChart_A%20Universal%20Vision-language%20Pretrained%20Model%20for%20Chart%20Comprehension%20and%20Reasoning.pdf)
  UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Masry-red?style=flat)
- [ ] [:link:](./files/DOX/[2023%20Ozyurt]%20Document-Level%20In-Context%20Few-Shot%20Relation%20Extraction%20via%20Pre-Trained%20Language%20Models.pdf)
  Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ozyurt-red?style=flat)
- [ ] [:link:](./files/DOX/[2023%20Wang]%20Layout%20and%20Task%20Aware%20Instruction%20Prompt%20for%20Zero-shot%20Document%20Image%20Question%20Answering.pdf)
  Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@aaai%20Hu]%20DocMamba_Efficient%20Document%20Pre-training%20with%20State%20Space%20Model.pdf)
  DocMamba: Efficient Document Pre-training with State Space Model
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Hu-red?style=flat)
  ![tags](https://img.shields.io/badge/aaai-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@aaai%20Wang]%20Knowledge%20Graph%20Prompting%20for%20Multi-Document%20Question%20Answering.pdf)
  Knowledge Graph Prompting for Multi-Document Question Answering
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/aaai-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20@cohere%20Wang]%20DAPR_A%20Benchmark%20on%20Document-Aware%20Passage%20Retrieval.pdf)
  DAPR: A Benchmark on Document-Aware Passage Retrieval
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/cohere-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Deng]%20Document-level%20Claim%20Extraction%20and%20Decontextualisation%20for%20Fact-Checking.pdf)
  Document-level Claim Extraction and Decontextualisation for Fact-Checking
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Deng-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Gao]%20TTM-RE_Memory-Augmented%20Document-Level%20Relation%20Extraction.pdf)
  TTM-RE: Memory-Augmented Document-Level Relation Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Gao-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Li]%20Hypergraph%20based%20Understanding%20for%20Document%20Semantic%20Entity%20Recognition.pdf)
  Hypergraph based Understanding for Document Semantic Entity Recognition
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Min]%20Synergetic%20Event%20Understanding_A%20Collaborative%20Approach%20to%20Cross-Document%20Event%20Coreference%20Resolution%20with%20Large%20Language%20Models.pdf)
  Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Min-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Na]%20Reward-based%20Input%20Construction%20for%20Cross-document%20Relation%20Extraction.pdf)
  Reward-based Input Construction for Cross-document Relation Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Na-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Qi]%20End-to-end%20Learning%20of%20Logical%20Rules%20for%20Enhancing%20Document-level%20Relation%20Extraction.pdf)
  End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Qi-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Wang]%20DocLLM_A%20layout-aware%20generative%20language%20model%20for%20multimodal%20document%20understanding.pdf)
  DocLLM: A layout-aware generative language model for multimodal document understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Xhen]%20MetaSumPerceiver_Multimodal%20Multi-Document%20Evidence%20Summarization%20for%20Fact-Checking.pdf)
  MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Xhen-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Zhao]%20DocMath-Eval_Evaluating%20Math%20Reasoning%20Capabilities%20of%20LLMs%20in%20Understanding%20Financial%20Documents.pdf)
  DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Zhou]%20LLMs%20Learn%20Task%20Heuristics%20from%20Demonstrations_A%20Heuristic-Driven%20Prompting%20Strategy%20for%20Document-Level%20Event%20Argument%20Extraction.pdf)
  LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhou-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@acl%20Zhu]%20FanOutQA_A%20Multi-Hop,%20Multi-Document%20Question%20Answering%20Benchmark%20for%20Large%20Language%20Models.pdf)
  FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhu-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@alibaba%20Liao]%20DocLayLLM_An%20Efficient%20and%20Effective%20Multi-modal%20Extension%20of%20Large%20Language%20Models%20for%20Text-rich%20Document%20Understanding.pdf)
  DocLayLLM: An Efficient and Effective Multi-modal Extension of Large Language Models for Text-rich Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liao-red?style=flat)
  ![tags](https://img.shields.io/badge/alibaba-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@alibaba%20Luo]%20LayoutLLM_Layout%20Instruction%20Tuning%20with%20Large%20Language%20Models%20for%20Document%20Understanding.pdf)
  LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Luo-red?style=flat)
  ![tags](https://img.shields.io/badge/alibaba-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@alibaba%20Wan]%20OmniParser_A%20Unified%20Framework%20for%20Text%20Spotting,%20Key%20Information%20Extraction%20and%20Table%20Recognition.pdf)
  OmniParser: A Unified Framework for Text Spotting, Key Information Extraction and Table Recognition
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wan-red?style=flat)
  ![tags](https://img.shields.io/badge/alibaba-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@amazon%20@stanford%20Sinha]%20Guiding%20Vision-Language%20Model%20Selection%20for%20Visual%20Question-Answering%20Across%20Tasks,%20Domains,%20and%20Knowledge%20Types.pdf)
  Guiding Vision-Language Model Selection for Visual Question-Answering Across Tasks, Domains, and Knowledge Types
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Sinha-red?style=flat)
  ![tags](https://img.shields.io/badge/stanford-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@aws%20Liao]%20DocTr_Document%20Transformer%20for%20Structured%20Information%20Extraction%20in%20Documents.pdf)
  DocTr: Document Transformer for Structured Information Extraction in Documents
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liao-red?style=flat)
  ![tags](https://img.shields.io/badge/aws-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@cornell%20Morris]%20Contextual%20Document%20Embeddings.pdf)
  Contextual Document Embeddings
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Morris-red?style=flat)
  ![tags](https://img.shields.io/badge/cornell-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20@adobe%20Yang]%20FIZZ_Factual%20Inconsistency%20Detection%20by%20Zoom-in%20Summary%20and%20Zoom-out%20Document.pdf)
  FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Yang-red?style=flat)
  ![tags](https://img.shields.io/badge/adobe-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20@alibaba%20Hu]%20mPLUG-DocOwl%201.5_Unified%20Structure%20Learning%20for%20OCR-free%20Document%20Understanding.pdf)
  mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Hu-red?style=flat)
  ![tags](https://img.shields.io/badge/alibaba-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20@alibaba%20Wang]%20Leave%20No%20Document%20Behind_Benchmarking%20Long-Context%20LLMs%20with%20Extended%20Multi-Doc%20QA.pdf)
  Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/alibaba-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20@aws%20Chen]%20MDCR_A%20Dataset%20for%20Multi-Document%20Conditional%20Reasoning.pdf)
  MDCR: A Dataset for Multi-Document Conditional Reasoning
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
  ![tags](https://img.shields.io/badge/aws-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20Buchmann]%20Attribute%20or%20Abstain_Large%20Language%20Models%20as%20Long%20Document%20Assistants.pdf)
  Attribute or Abstain: Large Language Models as Long Document Assistants
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Buchmann-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20Ma]%20Unifying%20Multimodal%20Retrieval%20via%20Document%20Screenshot%20Embedding.pdf)
  Unifying Multimodal Retrieval via Document Screenshot Embedding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ma-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20Mass]%20More%20Bang%20for%20your%20Context_Virtual%20Documents%20for%20Question%20Answering%20over%20Long%20Documents.pdf)
  More Bang for your Context: Virtual Documents for Question Answering over Long Documents
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Mass-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20Phogat]%20Fine-tuning%20Smaller%20Language%20Models%20for%20Question%20Answering%20over%20Financial%20Documents.pdf)
  Fine-tuning Smaller Language Models for Question Answering over Financial Documents
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Phogat-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20Ye]%20GlobeSumm_A%20Challenging%20Benchmark%20Towards%20Unifying%20Multi-lingual,%20Cross-lingual%20and%20Multi-document%20News%20Summarization.pdf)
  GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ye-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20Zhang]%20Modeling%20Layout%20Reading%20Order%20as%20Ordering%20Relations%20for%20Visually-rich%20Document%20Understanding.pdf)
  Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@emnlp%20Zhuang]%20PromptReps_Prompting%20Large%20Language%20Models%20to%20Generate%20Dense%20and%20Sparse%20Representations%20for%20Zero-Shot%20Document%20Retrieval.pdf)
  PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhuang-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@google%20Perot]%20LMDX_Language%20Model-based%20Document%20Information%20Extraction%20and%20Localization.pdf)
  LMDX: Language Model-based Document Information Extraction and Localization
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Perot-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@iclr%20Li]%20ChuLo_Chunk-Level%20Key%20Information%20Representation%20for%20Long%20Document%20Processing.pdf)
  ChuLo: Chunk-Level Key Information Representation for Long Document Processing
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@microsoft%20Wang]%20DLAFormer_An%20End-to-End%20Transformer%20For%20Document%20Layout%20Analysis.pdf)
  DLAFormer: An End-to-End Transformer For Document Layout Analysis
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@microsoft%20Xia]%20Vision%20Language%20Models%20for%20Spreadsheet%20Understanding_Challenges%20and%20Opportunities.pdf)
  Vision Language Models for Spreadsheet Understanding: Challenges and Opportunities
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Xia-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@mm%20Lin]%20PEneo_Unifying%20Line%20Extraction,%20Line%20Grouping,%20and%20Entity%20Linking%20for%20End-to-end%20Document%20Pair%20Extraction.pdf)
  PEneo: Unifying Line Extraction, Line Grouping, and Entity Linking for End-to-end Document Pair Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Lin-red?style=flat)
  ![tags](https://img.shields.io/badge/mm-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20@sail%20Zhang]%20Document%20Parsing%20Unveiled_Techniques,%20Challenges,%20and%20Prospects%20for%20Structured%20Information%20Extraction.pdf)
  Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
  ![tags](https://img.shields.io/badge/sail-blue?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Abdallah]%20CORU_Comprehensive%20Post-OCR%20Parsing%20and%20Receipt%20Understanding%20Dataset.pdf)
  CORU: Comprehensive Post-OCR Parsing and Receipt Understanding Dataset
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Abdallah-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Abdallah]%20Transformers%20and%20Language%20Models%20in%20Form%20Understanding_A%20Comprehensive%20Review%20of%20Scanned%20Document%20Analysis.pdf)
  Transformers and Language Models in Form Understanding: A Comprehensive Review of Scanned Document Analysis
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Abdallah-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Adhikari]%20A%20Comparative%20Study%20of%20PDF%20Parsing%20Tools%20Across%20Diverse%20Document%20Categories.pdf)
  A Comparative Study of PDF Parsing Tools Across Diverse Document Categories
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Adhikari-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Biswas]%20DocSynthv2_A%20Practical%20Autoregressive%20Modeling%20for%20Document%20Generation.pdf)
  DocSynthv2: A Practical Autoregressive Modeling for Document Generation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Biswas-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Boytsov]%20Understanding%20Performance%20of%20Long-Document%20Ranking%20Models%20through%20Comprehensive%20Evaluation%20and%20Leaderboarding.pdf)
  Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Boytsov-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Bronnec]%20LOCOST_State-Space%20Models%20for%20Long%20Document%20Abstractive%20Summarization.pdf)
  LOCOST: State-Space Models for Long Document Abstractive Summarization
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Bronnec-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Cho]%20M3DocRAG_Multi-modal%20Retrieval%20is%20What%20You%20Need%20for%20Multi-page%20Multi-document%20Understanding.pdf)
  M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Cho-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Choi]%20Model-based%20Preference%20Optimization%20in%20Abstractive%20Summarization%20without%20Human%20Feedback.pdf)
  Model-based Preference Optimization in Abstractive Summarization without Human Feedback
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Choi-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Constantinou]%20Out-of-Distribution%20Detection%20with%20Attention%20Head%20Masking%20for%20Multimodal%20Document%20Classification.pdf)
  Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Constantinou-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Deng]%20LongDocURL_a%20Comprehensive%20Multimodal%20Long%20Document%20Benchmark%20Integrating%20Understanding,%20Reasoning,%20and%20Locating.pdf)
  LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Deng-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Ding]%20PDF-MVQA_A%20Dataset%20for%20Multimodal%20Information%20Retrieval%20in%20PDF-based%20Visual%20Question%20Answering.pdf)
  PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based Visual Question Answering
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ding-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Faysse]%20ColPali_Efficient%20Document%20Retrieval%20with%20Vision%20Language%20Models.pdf)
  ColPali: Efficient Document Retrieval with Vision Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Faysse-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Futeral]%20mOSCAR_A%20Large-scale%20Multilingual%20and%20Multimodal%20Document-level%20Corpus.pdf)
  mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Futeral-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20He]%20DR-RAG_Applying%20Dynamic%20Document%20Relevance%20to%20RetrievalAugmented%20Generation%20for%20Question-Answering.pdf)
  DR-RAG: Applying Dynamic Document Relevance to RetrievalAugmented Generation for Question-Answering
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/He-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Hsu]%20M3T_A%20New%20Benchmark%20Dataset%20for%20Multi-Modal%20Document-Level%20Machine%20Translation.pdf)
  M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Hsu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Hu]%20mPLUG-DocOwl2_High-resolution%20Compressing%20for%20OCR-free%20Multi-page%20Document%20Understanding.pdf)
  mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Hu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Hui]%20UDA_A%20Benchmark%20Suite%20for%20Retrieval%20Augmented%20Generation%20in%20Real-world%20Document%20Analysis.pdf)
  UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Hui-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Li]%20Enhancing%20Visual%20Document%20Understanding%20with%20Contrastive%20Learning%20in%20Large%20Visual-Language%20Models.pdf)
  Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Liu]%20Fox_Focus%20Anywhere%20for%20Fine-grained%20Multi-page%20Document%20Understanding.pdf)
  Fox: Focus Anywhere for Fine-grained Multi-page Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Liu]%20See%20then%20Tell_Enhancing%20Key%20Information%20Extraction%20with%20Vision%20Grounding.pdf)
  See then Tell: Enhancing Key Information Extraction with Vision Grounding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Liu]%20TextMonkey_An%20OCR-Free%20Large%20Multimodal%20Model%20for%20Understanding%20Document.pdf)
  TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Lu]%20A%20Bounding%20Box%20is%20Worth%20One%20Token_Interleaving%20Layout%20and%20Text%20in%20a%20Large%20Language%20Model%20for%20Document%20Understanding.pdf)
  A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Lu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Lu]%20From%20Text%20to%20Pixel_Advancing%20Long-Context%20Understanding%20in%20MLLMs.pdf)
  From Text to Pixel: Advancing Long-Context Understanding in MLLMs
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Lu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Mao]%20Visually%20Guided%20Generative%20Text-Layout%20Pre-training%20for%20Document%20Intelligence.pdf)
  Visually Guided Generative Text-Layout Pre-training for Document Intelligence
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Mao-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Mohammadshirazi]%20DocParseNet_Advanced%20Semantic%20Segmentation%20and%20OCR%20Embeddings%20for%20Efficient%20Scanned%20Document%20Annotation.pdf)
  DocParseNet: Advanced Semantic Segmentation and OCR Embeddings for Efficient Scanned Document Annotation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Mohammadshirazi-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Qi]%20ADELIE_Aligning%20Large%20Language%20Models%20on%20Information%20Extraction.pdf)
  ADELIE: Aligning Large Language Models on Information Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Qi-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Shehzadi]%20A%20Hybrid%20Approach%20for%20Document%20Layout%20Analysis%20in%20Document%20images.pdf)
  A Hybrid Approach for Document Layout Analysis in Document images
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Shehzadi-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Xia]%20StructChart_Perception,%20Structuring,%20Reasoning%20for%20Visual%20Chart%20Understanding.pdf)
  StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Xia-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Yu]%20TextHawk_Exploring%20Efficient%20Fine-Grained%20Perception%20of%20Multimodal%20Large%20Language%20Models.pdf)
  TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Yu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Zhang]%20DocKylin_A%20Large%20Multimodal%20Model%20for%20Visual%20Document%20Understanding%20with%20Efficient%20Visual%20Slimming.pdf)
  DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Zhang]%20SAIL_Sample-Centric%20In-Context%20Learning%20for%20Document%20Information%20Extraction.pdf)
  SAIL: Sample-Centric In-Context Learning for Document Information Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Zhao]%20TabPedia_Towards%20Comprehensive%20Visual%20Table%20Understanding%20with%20Concept%20Synergy.pdf)
  TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Zhu]%20MMDocBench_Benchmarking%20Large%20Vision-Language%20Models%20for%20Fine-Grained%20Visual%20Document%20Understanding.pdf)
  MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhu-red?style=flat)
- [ ] [:link:](./files/DOX/[2024%20Zmigrod]%20BuDDIE_A%20Business%20Document%20Dataset%20for%20Multi-task%20Information%20Extraction.pdf)
  BuDDIE: A Business Document Dataset for Multi-task Information Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zmigrod-red?style=flat)
- [ ] [:link:](./files/DOX/[2025%20@iclr%20Chen]%20Graph-based%20Document%20Structure%20Analysis.pdf)
  Graph-based Document Structure Analysis
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/DOX/[2025%20@iclr%20Chen]%20LoRA-Contextualizing%20Adaptation%20of%20Large%20Multimodal%20Models%20for%20Multi-page%20Document%20Understanding.pdf)
  LoRA-Contextualizing Adaptation of Large Multimodal Models for Multi-page Document Understanding
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/DOX/[2025%20@iclr%20Huang]%20Mini-Monkey_Alleviating%20the%20Semantic%20Sawtooth%20Effect%20for%20Lightweight%20MLLMs%20via%20Complementary%20Image%20Pyramid.pdf)
  Mini-Monkey: Alleviating the Semantic Sawtooth Effect for Lightweight MLLMs via Complementary Image Pyramid
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Huang-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/DOX/[2025%20@iclr%20Zhu]%20Enhancing%20Document%20Understanding%20with%20Group%20Position%20Embedding_A%20Novel%20Approach%20to%20Incorporate%20Layout%20Information.pdf)
  Enhancing Document Understanding with Group Position Embedding: A Novel Approach to Incorporate Layout Information
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhu-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/DOX/[2025%20Suri]%20VisDoM_Multi-Document%20QA%20with%20Visually%20Rich%20Elements%20Using%20Multimodal%20Retrieval-Augmented%20Generation.pdf)
  VisDoM: Multi-Document QA with Visually Rich Elements Using Multimodal Retrieval-Augmented Generation
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Suri-red?style=flat)
- [ ] [:link:](./files/DOX/[2025%20Xie]%20PDF-WuKong_A%20Large%20Multimodal%20Model%20for%20Efficient%20Long%20PDF%20Reading%20with%20End-to-End%20Sparse%20Sampling.pdf)
  PDF-WuKong: A Large Multimodal Model for Efficient Long PDF Reading with End-to-End Sparse Sampling
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Xie-red?style=flat)
<!-- AUTOGENERATED_DOX -->


## :parrot: NLP

<!-- AUTOGENERATED_NLP -->
- [ ] [:link:](./files/NLP/[2013%20Mikolov]%20Distributed%20Representations%20of%20Words%20and%20Phrases%20and%20their%20Compositionality.pdf)
  Distributed Representations of Words and Phrases and their Compositionality
  ![year](https://img.shields.io/badge/2013-green?style=flat)
  ![auth](https://img.shields.io/badge/Mikolov-red?style=flat)
- [ ] [:link:](./files/NLP/[2013%20Mikolov]%20Efficient%20Estimation%20of%20Word%20Representations%20in%20Vector%20Space.pdf)
  Efficient Estimation of Word Representations in Vector Space
  ![year](https://img.shields.io/badge/2013-green?style=flat)
  ![auth](https://img.shields.io/badge/Mikolov-red?style=flat)
- [ ] [:link:](./files/NLP/[2017%20@google%20#milestone%20Vaswani]%20Attention%20Is%20All%20You%20Need.pdf)
  Attention Is All You Need
  ![year](https://img.shields.io/badge/2017-green?style=flat)
  ![auth](https://img.shields.io/badge/Vaswani-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2018%20@google%20#milestone%20Devlin]%20BERT_Pre-Training%20of%20Deep%20Bidirectional%20Transformers%20for%20Language%20Understanding.pdf)
  BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding
  ![year](https://img.shields.io/badge/2018-green?style=flat)
  ![auth](https://img.shields.io/badge/Devlin-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2018%20@openai%20#gpt%20#milestone%20Radford]%20Improving%20Language%20Understanding%20by%20Generative%20Pre-Training.pdf)
  Improving Language Understanding by Generative Pre-Training
  ![year](https://img.shields.io/badge/2018-green?style=flat)
  ![auth](https://img.shields.io/badge/Radford-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@acl%20Dai]%20Transformer-XL_Attentive%20Language%20Models%20Beyond%20a%20Fixed-Length%20Context.pdf)
  Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Dai-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@google%20#T5%20#milestone%20Raffel]%20Exploring%20the%20Limits%20of%20Transfer%20Learning%20with%20a%20Unified%20Text-to-Text%20Transformer.pdf)
  Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Raffel-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@iclr%20Wang]%20GLUE_A%20Multi-Task%20Benchmark%20and%20Analysis%20Platform%20for%20Natural%20Language%20Understanding.pdf)
  GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@meta%20Liu]%20RoBERTa_A%20Robustly%20Optimized%20BERT%20Pretraining%20Approach.pdf)
  RoBERTa: A Robustly Optimized BERT Pretraining Approach
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@neurips%20Wang]%20SuperGLUE_A%20Stickier%20Benchmark%20for%20General-Purpose%20Language%20Understanding.pdf)
  SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@neurips%20Yang]%20XLNet_Generalized%20Autoregressive%20Pretraining%20for%20Language%20Understanding.pdf)
  XLNet: Generalized Autoregressive Pretraining for Language Understanding
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Yang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@openai%20#RLHF%20Ziegler]%20Fine-Tuning%20Language%20Models%20from%20Human%20Preferences.pdf)
  Fine-Tuning Language Models from Human Preferences
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Ziegler-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2019%20@openai%20#gpt2%20Radford]%20Language%20Models%20are%20Unsupervised%20Multitask%20Learners.pdf)
  Language Models are Unsupervised Multitask Learners
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Radford-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2020%20@acl%20Gururangan]%20Don't%20Stop%20Pretraining_Adapt%20Language%20Models%20to%20Domains%20and%20Tasks.pdf)
  Don't Stop Pretraining: Adapt Language Models to Domains and Tasks
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Gururangan-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/NLP/[2020%20@facebook%20Lewis]%20Retrieval-Augmented%20Generation%20for%20Knowledge-Intensive%20NLP%20Tasks.pdf)
  Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Lewis-red?style=flat)
  ![tags](https://img.shields.io/badge/facebook-blue?style=flat)
- [ ] [:link:](./files/NLP/[2020%20@google%20Guu]%20REALM_Retrieval-Augmented%20Language%20Model%20Pre-Training.pdf)
  REALM: Retrieval-Augmented Language Model Pre-Training
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Guu-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2020%20@iclr%20Khandelwal]%20Generalization%20through%20Memorization_Nearest%20Neighbor%20Language%20Models.pdf)
  Generalization through Memorization: Nearest Neighbor Language Models
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Khandelwal-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/NLP/[2020%20@openai%20#gpt3%20Brown]%20Language%20Models%20are%20Few-Shot%20Learners.pdf)
  Language Models are Few-Shot Learners
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Brown-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2020%20@openai%20#milestone%20Kaplan]%20Scaling%20Laws%20for%20Neural%20Language%20Models.pdf)
  Scaling Laws for Neural Language Models
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Kaplan-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2021%20@microsoft%20#finetuning%20Hu]%20LoRA_Low-Rank%20Adaptation%20of%20Large%20Language%20Models.pdf)
  LoRA: Low-Rank Adaptation of Large Language Models
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Hu-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/NLP/[2021%20@microsoft%20Mao]%20Generation-Augmented%20Retrieval%20for%20Open-Domain%20Question%20Answering.pdf)
  Generation-Augmented Retrieval for Open-Domain Question Answering
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Mao-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/NLP/[2021%20@naacl%20Li]%20Document-Level%20Event%20Argument%20Extraction%20by%20Conditional%20Generation.pdf)
  Document-Level Event Argument Extraction by Conditional Generation
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
  ![tags](https://img.shields.io/badge/naacl-blue?style=flat)
- [ ] [:link:](./files/NLP/[2021%20@nvidia%20#megatron-lm%20#distributed%20Narayanan]%20Efficient%20Large-Scale%20Language%20Model%20Training%20on%20GPU%20Clusters%20Using%20Megatron-LM.pdf)
  Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Narayanan-red?style=flat)
  ![tags](https://img.shields.io/badge/nvidia-blue?style=flat)
- [ ] [:link:](./files/NLP/[2021%20Das]%20Case-Based%20Reasoning%20for%20Natural%20Language%20Queries%20over%20Knowledge%20Bases.pdf)
  Case-Based Reasoning for Natural Language Queries over Knowledge Bases
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Das-red?style=flat)
- [ ] [:link:](./files/NLP/[2021%20Huang]%20WhiteningBERT_An%20Easy%20Unsupervised%20Sentence%20Embedding%20Approach.pdf)
  WhiteningBERT: An Easy Unsupervised Sentence Embedding Approach
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Huang-red?style=flat)
- [ ] [:link:](./files/NLP/[2021%20Liu]%20Pre-train,%20Prompt,%20and%20Predict_A%20Systematic%20Survey%20of%20Prompting%20Methods%20in%20Natural%20Language%20Processing.pdf)
  Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
- [ ] [:link:](./files/NLP/[2022%20#finetuning%20Liu]%20P-Tuning%20v2_Prompt%20Tuning%20Can%20Be%20Comparable%20to%20Fine-tuning%20Universally%20Across%20Scales%20and%20Tasks.pdf)
  P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@anthropic%20Hernandez]%20Scaling%20Laws%20and%20Interpretability%20of%20Learning%20from%20Repeated%20Data.pdf)
  Scaling Laws and Interpretability of Learning from Repeated Data
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Hernandez-red?style=flat)
  ![tags](https://img.shields.io/badge/anthropic-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@deepmind%20Borgeaud]%20Improving%20language%20models%20by%20retrieving%20from%20trillions%20of%20tokens.pdf)
  Improving language models by retrieving from trillions of tokens
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Borgeaud-red?style=flat)
  ![tags](https://img.shields.io/badge/deepmind-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@emnlp%20Min]%20Rethinking%20the%20Role%20of%20Demonstrations_What%20Makes%20In-Context%20Learning%20Work.pdf)
  Rethinking the Role of Demonstrations: What Makes In-Context Learning Work
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Min-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@google%20#prompt%20Wei]%20Chain-of-Thought%20Prompting%20Elicits%20Reasoning%20in%20Large%20Language%20Models.pdf)
  Chain-of-Thought Prompting Elicits Reasoning in Large Language Models
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Wei-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@google%20Chowdhery]%20PaLM_Scaling%20Language%20Modeling%20with%20Pathways.pdf)
  PaLM: Scaling Language Modeling with Pathways
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Chowdhery-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@hai%20#milestone%20Bommasani]%20On%20the%20Opportunities%20and%20Risks%20of%20Foundation%20Models.pdf)
  On the Opportunities and Risks of Foundation Models
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Bommasani-red?style=flat)
  ![tags](https://img.shields.io/badge/hai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@icml%20Borgeaud]%20Improving%20language%20models%20by%20retrieving%20from%20trillions%20of%20tokens.pdf)
  Improving language models by retrieving from trillions of tokens
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Borgeaud-red?style=flat)
  ![tags](https://img.shields.io/badge/icml-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@microsoft%20Wang]%20Training%20Data%20is%20More%20Valuable%20than%20You%20Think_A%20Simple%20and%20Effective%20Method%20by%20Retrieving%20from%20Training%20Data.pdf)
  Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20@openai%20#RLHF%20Ouyang]%20Training%20language%20models%20to%20follow%20instructions%20with%20human%20feedback.pdf)
  Training language models to follow instructions with human feedback
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Ouyang-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2022%20Izacard]%20Atlas_Few-shot%20Learning%20with%20Retrieval%20Augmented%20Language%20Models.pdf)
  Atlas: Few-shot Learning with Retrieval Augmented Language Models
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Izacard-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20#agent%20Shinn]%20Reflexion_Language%20Agents%20with%20Verbal%20Reinforcement%20Learning.pdf)
  Reflexion: Language Agents with Verbal Reinforcement Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Shinn-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@cmu%20Liu]%20Pre-train,%20Prompt,%20and%20Predict_A%20Systematic%20Survey%20of%20Prompting%20Methods%20in%20Natural%20Language%20Processing.pdf)
  Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
  ![tags](https://img.shields.io/badge/cmu-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@emnlp%20Dankers]%20Memorisation%20Cartography_Mapping%20out%20the%20Memorisation-Generalisation%20Continuum%20in%20Neural%20Machine%20Translation.pdf)
  Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Dankers-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@emnlp%20Jacovi]%20Stop%20Uploading%20Test%20Data%20in%20Plain%20Text_Practical%20Strategies%20for%20Mitigating%20Data%20Contamination%20by%20Evaluation%20Benchmarks.pdf)
  Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Jacovi-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@emnlp%20Liu]%20G-EVAL_NLG%20Evaluation%20using%20GPT-4%20with%20Better%20Human%20Alignment.pdf)
  G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@emnlp%20Wang]%20Label%20Words%20are%20Anchors_An%20Information%20Flow%20Perspective%20for%20Understanding%20In-Context%20Learning.pdf)
  Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@google%20#RLHF%20Lee]%20RLAIF_Scaling%20Reinforcement%20Learning%20from%20Human%20Feedback%20with%20AI%20Feedback.pdf)
  RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lee-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@google%20Cai]%20Large%20Language%20Models%20as%20Tool%20Makers.pdf)
  Large Language Models as Tool Makers
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Cai-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@google%20Google]%20Gemini_A%20Family%20of%20Highly%20Capable%20Multimodal%20Models.pdf)
  Gemini: A Family of Highly Capable Multimodal Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Google-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@google%20Yang]%20Large%20Language%20Models%20as%20Optimizers.pdf)
  Large Language Models as Optimizers
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yang-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@iclr%20Zhou]%20Large%20Language%20Models%20Are%20Human-Level%20Prompt%20Engineers.pdf)
  Large Language Models Are Human-Level Prompt Engineers
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhou-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@meta%20#lama%20Touvron]%20LLaMA_Open%20and%20Efficient%20Foundation%20Language%20Models.pdf)
  LLaMA: Open and Efficient Foundation Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Touvron-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@meta%20#llama2%20Touvron]%20LLaMA%202_Open%20Foundation%20and%20Fine-Tuned%20Chat%20Models.pdf)
  LLaMA 2: Open Foundation and Fine-Tuned Chat Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Touvron-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@meta%20Schick]%20Toolformer_Language%20Models%20Can%20Teach%20Themselves%20to%20Use%20Tools.pdf)
  Toolformer: Language Models Can Teach Themselves to Use Tools
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Schick-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@meta%20Xiong]%20Effective%20Long-Context%20Scaling%20of%20Foundation%20Models.pdf)
  Effective Long-Context Scaling of Foundation Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Xiong-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@microsoft%20Sun]%20Retentive%20Network_A%20Successor%20to%20Transformer%20for%20Large%20Language%20Models.pdf)
  Retentive Network: A Successor to Transformer for Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Sun-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@mistral%20Mistral]%20Mistral%207B.pdf)
  Mistral 7B
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Mistral-red?style=flat)
  ![tags](https://img.shields.io/badge/mistral-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@neurips%20@meta%20Tirumala]%20D4_Improving%20LLM%20Pretraining%20via%20Document%20De-Duplication%20and%20Diversification.pdf)
  D4: Improving LLM Pretraining via Document De-Duplication and Diversification
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Tirumala-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@neurips%20Wang]%20DORIS-MAE_Scientific%20Document%20Retrieval%20using%20Multi-level%20Aspect-based%20Queries.pdf)
  DORIS-MAE: Scientific Document Retrieval using Multi-level Aspect-based Queries
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@neurips%20Yang]%20ResMem_Learn%20what%20you%20can%20and%20memorize%20the%20rest.pdf)
  ResMem: Learn what you can and memorize the rest
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@openai%20#gpt4%20OpenAI]%20GPT-4%20Technical%20Report.pdf)
  GPT-4 Technical Report
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/OpenAI-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@stanford%20#dpo%20Rafailov]%20Direct%20Preference%20Optimization_Your%20Language%20Model%20is%20Secretly%20a%20Reward%20Model.pdf)
  Direct Preference Optimization: Your Language Model is Secretly a Reward Model
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Rafailov-red?style=flat)
  ![tags](https://img.shields.io/badge/stanford-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20@stanford%20Schaeffer]%20Are%20Emergent%20Abilities%20of%20Large%20Language%20Models%20a%20Mirage.pdf)
  Are Emergent Abilities of Large Language Models a Mirage
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Schaeffer-red?style=flat)
  ![tags](https://img.shields.io/badge/stanford-blue?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Bommasani]%20The%20Foundation%20Model%20Transparency%20Index.pdf)
  The Foundation Model Transparency Index
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Bommasani-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Chang]%20A%20Survey%20on%20Evaluation%20of%20Large%20Language%20Models.pdf)
  A Survey on Evaluation of Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Chang-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Chang]%20Learning%20to%20Generate%20Better%20Than%20Your%20LLM.pdf)
  Learning to Generate Better Than Your LLM
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Chang-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Chen]%20ChatGPT's%20One-year%20Anniversary_Are%20Open-Source%20Large%20Language%20Models%20Catching%20up.pdf)
  ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Chen]%20Understanding%20Retrieval%20Augmentation%20for%20Long-Form%20Question%20Answering.pdf)
  Understanding Retrieval Augmentation for Long-Form Question Answering
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Gao]%20Retrieval-Augmented%20Generation%20for%20Large%20Language%20Models_A%20Survey.pdf)
  Retrieval-Augmented Generation for Large Language Models: A Survey
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Gao-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Goyal]%20News%20Summarization%20and%20Evaluation%20in%20the%20Era%20of%20GPT-3.pdf)
  News Summarization and Evaluation in the Era of GPT-3
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Goyal-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20He]%20AnnoLLM_Making%20Large%20Language%20Models%20to%20Be%20Better%20Crowdsourced%20Annotators.pdf)
  AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/He-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20He]%20Simplifying%20Transformer%20Blocks.pdf)
  Simplifying Transformer Blocks
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/He-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Huang]%20OPERA_Alleviating%20Hallucination%20in%20Multi-Modal%20Large%20Language%20Models%20via%20Over-Trust%20Penalty%20and%20Retrospection-Allocation.pdf)
  OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Huang-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Jiang]%20Active%20Retrieval%20Augmented%20Generation.pdf)
  Active Retrieval Augmented Generation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Jiang-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Kaddour]%20Challenges%20and%20Applications%20of%20Large%20Language%20Models.pdf)
  Challenges and Applications of Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Kaddour-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Kwon]%20Efficient%20Memory%20Management%20for%20Large%20Language%20Model%20Serving%20with%20PagedAttention.pdf)
  Efficient Memory Management for Large Language Model Serving with PagedAttention
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Kwon-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Li]%20CoAnnotating_Uncertainty-Guided%20Work%20Allocation%20between%20Human%20and%20Large%20Language%20Models%20for%20Data%20Annotation.pdf)
  CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Lilian]%20LLM%20Powered%20Autonomous%20Agents.pdf)
  LLM Powered Autonomous Agents
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lilian-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Long]%20Adapt%20in%20Contexts_Retrieval-Augmented%20Domain%20Adaptation%20via%20In-Context%20Learning.pdf)
  Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Long-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Patil]%20Gorilla_Large%20Language%20Model%20Connected%20with%20Massive%20APIs.pdf)
  Gorilla: Large Language Model Connected with Massive APIs
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Patil-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Ram]%20In-Context%20Retrieval-Augmented%20Language%20Models.pdf)
  In-Context Retrieval-Augmented Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ram-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Sainz]%20GoLLIE_Annotation%20Guidelines%20improve%20Zero-Shot%20Information-Extraction.pdf)
  GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Sainz-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Shaikh]%20On%20Second%20Thought,%20Let's%20Not%20Think%20Step%20by%20Step!%20Bias%20and%20Toxicity%20in%20Zero-Shot%20Reasoning.pdf)
  On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Shaikh-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Sheng]%20S-LoRA_Serving%20Thousands%20of%20Concurrent%20LoRA%20Adapters.pdf)
  S-LoRA: Serving Thousands of Concurrent LoRA Adapters
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Sheng-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Shi]%20In-Context%20Pretraining_Language%20Modeling%20Beyond%20Document%20Boundaries.pdf)
  In-Context Pretraining: Language Modeling Beyond Document Boundaries
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Shi-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Siriwardhana]%20Improving%20the%20Domain%20Adaptation%20of%20Retrieval%20Augmented%20Generation%20(RAG)%20Models%20for%20Open%20Domain%20Question%20Answering.pdf)
  Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Siriwardhana-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Xu]%20Retrieval%20Meets%20Long%20Context%20Large%20Language%20Models.pdf)
  Retrieval Meets Long Context Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Xu-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Yao]%20Tree%20of%20Thoughts_Deliberate%20Problem%20Solving%20with%20Large%20Language%20Models.pdf)
  Tree of Thoughts: Deliberate Problem Solving with Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yao-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Yin]%20A%20Survey%20on%20Multimodal%20Large%20Language%20Models.pdf)
  A Survey on Multimodal Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yin-red?style=flat)
- [ ] [:link:](./files/NLP/[2023%20Zhao]%20A%20Survey%20of%20Large%20Language%20Models.pdf)
  A Survey of Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#agent%20Fourney]%20Magentic-One_A%20Generalist%20Multi-Agent%20System%20for%20Solving%20Complex%20Tasks.pdf)
  Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Fourney-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#agent%20Liu]%20Large%20Language%20Model-Based%20Agents%20for%20Software%20Engineering_A%20Survey.pdf)
  Large Language Model-Based Agents for Software Engineering: A Survey
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#agent%20Raad]%20Scaling%20Instructable%20Agents%20Across%20Many%20Simulated%20Worlds.pdf)
  Scaling Instructable Agents Across Many Simulated Worlds
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Raad-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#agent%20Wu]%20ReFT_Representation%20Finetuning%20for%20Language%20Models.pdf)
  ReFT: Representation Finetuning for Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wu-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#agent%20Zhuge]%20Agent-as-a-Judge_Evaluate%20Agents%20with%20Agents.pdf)
  Agent-as-a-Judge: Evaluate Agents with Agents
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhuge-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#finetuning%20Parthasarathy]%20The%20Ultimate%20Guide%20to%20Fine-Tuning%20LLMs%20from%20Basics%20to%20Breakthroughs_An%20Exhaustive%20Review%20of%20Technologies,%20Research,%20Best%20Practices,%20Applied%20Research%20Challenges%20and%20Opportunities.pdf)
  The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Parthasarathy-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#preference-learning%20Gao]%20Towards%20a%20Unified%20View%20of%20Preference%20Learning%20for%20Large%20Language%20Models_A%20Survey.pdf)
  Towards a Unified View of Preference Learning for Large Language Models: A Survey
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Gao-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20#reflection-tuning%20Li]%20Selective%20Reflection-Tuning_Student-Selected%20Data%20Recycling%20for%20LLM%20Instruction-Tuning.pdf)
  Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@aaai%20Chen]%20Benchmarking%20Large%20Language%20Models%20in%20Retrieval-Augmented%20Generation.pdf)
  Benchmarking Large Language Models in Retrieval-Augmented Generation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
  ![tags](https://img.shields.io/badge/aaai-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@acl%20@alibaba]%20On%20the%20Role%20of%20Long-tail%20Knowledge%20in%20Retrieval%20Augmented%20Large%20Language%20Models.pdf)
  On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/@alibaba-red?style=flat)
  ![tags](https://img.shields.io/badge/alibaba]-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@alibaba%20Liu]%20CoFE-RAG_A%20Comprehensive%20Full-chain%20Evaluation%20Framework%20for%20Retrieval-Augmented%20Generation%20with%20Enhanced%20Data%20Diversity.pdf)
  CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
  ![tags](https://img.shields.io/badge/alibaba-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@apple%20McKinzie]%20MM1_Methods,%20Analysis%20&%20Insights%20from%20Multimodal%20LLM%20Pre-training.pdf)
  MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/McKinzie-red?style=flat)
  ![tags](https://img.shields.io/badge/apple-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@cohere%20Ustun]%20Aya%20Model_An%20Instruction%20Finetuned%20Open-Access%20Multilingual%20Language%20Model.pdf)
  Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ustun-red?style=flat)
  ![tags](https://img.shields.io/badge/cohere-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@emnlp%20Wang]%20Searching%20for%20Best%20Practices%20in%20Retrieval-Augmented%20Generation.pdf)
  Searching for Best Practices in Retrieval-Augmented Generation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@emnlp%20Zhao]%20LongAgent_Scaling%20Language%20Models%20to%20128k%20Context%20through%20Multi-Agent%20Collaboration.pdf)
  LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@google%20#gemini%20Google]%20Gemini%201.5_Unlocking%20multimodal%20understanding%20across%20millions%20of%20tokens%20of%20context.pdf)
  Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Google-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@google%20Munkhdalai]%20Leave%20No%20Context%20Behind_Efficient%20Infinite%20Context%20Transformers%20with%20Infini-attention.pdf)
  Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Munkhdalai-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@google%20Petridis]%20ConstitutionalExperts_Training%20a%20Mixture%20of%20Principle-based%20Prompts.pdf)
  ConstitutionalExperts: Training a Mixture of Principle-based Prompts
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Petridis-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@ibm%20Asthana]%20Enterprise%20Benchmarks%20for%20Large%20Language%20Model%20Evaluation.pdf)
  Enterprise Benchmarks for Large Language Model Evaluation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Asthana-red?style=flat)
  ![tags](https://img.shields.io/badge/ibm-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@iclr%20Sun]%20Enhancing%20Chain-of-Thoughts%20Prompting%20with%20Iterative%20Bootstrapping%20in%20Large%20Language%20Models.pdf)
  Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Sun-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@meta%20#reflection-tuning%20Ye]%20Physics%20of%20Language%20Models_Part%202.2,%20How%20to%20Learn%20From%20Mistakes%20on%20Grade-School%20Math%20Problems.pdf)
  Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ye-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@microsoft%20Qi]%20Mutual%20Reasoning%20Makes%20Smaller%20LLMs%20Stronger%20Problem-Solvers.pdf)
  Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Qi-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@microsoft%20Sun]%20You%20Only%20Cache%20Once_Decoder-Decoder%20Architectures%20for%20Language%20Models.pdf)
  You Only Cache Once: Decoder-Decoder Architectures for Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Sun-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@neurips%20@microsoft%20Lin]%20RHO-1_Not%20All%20Tokens%20Are%20What%20You%20Need.pdf)
  RHO-1: Not All Tokens Are What You Need
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Lin-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@neurips%20Tong]%20Cambrian-1_A%20Fully%20Open,%20Vision-Centric%20Exploration%20of%20Multimodal%20LLMs.pdf)
  Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Tong-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@nvidia%20Hsieh]%20RULER_What's%20the%20Real%20Context%20Size%20of%20Your%20Long-Context%20Language%20Models.pdf)
  RULER: What's the Real Context Size of Your Long-Context Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Hsieh-red?style=flat)
  ![tags](https://img.shields.io/badge/nvidia-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@nvidia%20Nvidia]%20Nemotron-4%20340B%20Technical%20Report.pdf)
  Nemotron-4 340B Technical Report
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Nvidia-red?style=flat)
  ![tags](https://img.shields.io/badge/nvidia-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@pku%20Liao]%20TPO_Aligning%20Large%20Language%20Models%20with%20Multi-branch%20&%20Multi-step%20Preference%20Trees.pdf)
  TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Liao-red?style=flat)
  ![tags](https://img.shields.io/badge/pku-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@stanford%20Hewitt]%20Instruction%20Following%20without%20Instruction%20Tuning.pdf)
  Instruction Following without Instruction Tuning
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Hewitt-red?style=flat)
  ![tags](https://img.shields.io/badge/stanford-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20@stanford%20Sun]%20Learning%20to%20(Learn%20at%20Test%20Time)_RNNs%20with%20Expressive%20Hidden%20States.pdf)
  Learning to (Learn at Test Time): RNNs with Expressive Hidden States
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Sun-red?style=flat)
  ![tags](https://img.shields.io/badge/stanford-blue?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Chen]%20How%20Far%20Are%20We%20to%20GPT-4V.%20Closing%20the%20Gap%20to%20Commercial%20Multimodal%20Models%20with%20Open-Source%20Suites.pdf)
  How Far Are We to GPT-4V. Closing the Gap to Commercial Multimodal Models with Open-Source Suites
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Chen]%20Octopus%20v2_On-device%20language%20model%20for%20super%20agent.pdf)
  Octopus v2: On-device language model for super agent
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Doan]%20Vintern-1B_An%20Efficient%20Multimodal%20Large%20Language%20Model%20for%20Vietnamese.pdf)
  Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Doan-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Du]%20Understanding%20Emergent%20Abilities%20of%20Language%20Models%20from%20the%20Loss%20Perspective.pdf)
  Understanding Emergent Abilities of Language Models from the Loss Perspective
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Du-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Edge]%20From%20Local%20to%20Global_A%20Graph%20RAG%20Approach%20to%20Query-Focused%20Summarization.pdf)
  From Local to Global: A Graph RAG Approach to Query-Focused Summarization
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Edge-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Fan]%20A%20Survey%20on%20RAG%20Meeting%20LLMs_Towards%20Retrieval-Augmented%20Large%20Language%20Models.pdf)
  A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Fan-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Gao]%20Higher%20Layers%20Need%20More%20LoRA%20Experts.pdf)
  Higher Layers Need More LoRA Experts
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Gao-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20He]%20Zero-Shot%20Cross-Lingual%20Document-Level%20Event%20Causality%20Identification%20with%20Heterogeneous%20Graph%20Contrastive%20Transfer%20Learning.pdf)
  Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/He-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Ji]%20Aligner_Achieving%20Efficient%20Alignment%20through%20Weak-to-Strong%20Correction.pdf)
  Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ji-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Laurencon]%20Building%20and%20better%20understanding%20vision-language%20models_insights%20and%20future%20directions.pdf)
  Building and better understanding vision-language models: insights and future directions
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Laurencon-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Lesci]%20Causal%20Estimation%20of%20Memorisation%20Profiles.pdf)
  Causal Estimation of Memorisation Profiles
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Lesci-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Ni]%20DIRAS_Efficient%20LLM%20Annotation%20of%20Document%20Relevance%20for%20Retrieval%20Augmented%20Generation.pdf)
  DIRAS: Efficient LLM Annotation of Document Relevance for Retrieval Augmented Generation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ni-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Ning]%20User-LLM_Efficient%20LLM%20Contextualization%20with%20User%20Embeddings.pdf)
  User-LLM: Efficient LLM Contextualization with User Embeddings
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ning-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Peng]%20Graph%20Retrieval-Augmented%20Generation_A%20Survey.pdf)
  Graph Retrieval-Augmented Generation: A Survey
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Peng-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Sarthi]%20RAPTOR_Recursive%20Abstractive%20Processing%20for%20Tree-Organized%20Retrieval.pdf)
  RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Sarthi-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Sprague]%20To%20CoT%20or%20not%20to%20CoT?%20Chain-of-thought%20helps%20mainly%20on%20math%20and%20symbolic%20reasoning.pdf)
  To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Sprague-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Tam]%20Let%20Me%20Speak%20Freely.%20A%20Study%20on%20the%20Impact%20of%20Format%20Restrictions%20on%20Performance%20of%20Large%20Language%20Model.pdf)
  Let Me Speak Freely. A Study on the Impact of Format Restrictions on Performance of Large Language Model
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Tam-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Wallace]%20The%20Instruction%20Hierarchy_Training%20LLMs%20to%20Prioritize%20Privileged%20Instructions.pdf)
  The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wallace-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Wang]%20One%20Prompt%20is%20not%20Enough_Automated%20Construction%20of%20a%20Mixture-of-Expert%20Prompts.pdf)
  One Prompt is not Enough: Automated Construction of a Mixture-of-Expert Prompts
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Wang]%20Qwen2-VL_Enhancing%20Vision-Language%20Model’s%20Perception%20of%20the%20World%20at%20AnyResolution.pdf)
  Qwen2-VL: Enhancing Vision-Language Model’s Perception of the World at AnyResolution
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Wang]%20SeaEval%20for%20Multilingual%20Foundation%20Models_From%20Cross-Lingual%20Alignment%20to%20Cultural%20Reasoning.pdf)
  SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Zhang]%20In-Context%20Principle%20Learning%20from%20Mistakes.pdf)
  In-Context Principle Learning from Mistakes
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Zhang]%20RAFT_Adapting%20Language%20Model%20to%20Domain%20Specific%20RAG.pdf)
  RAFT: Adapting Language Model to Domain Specific RAG
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Zhang]%20Rethinking%20the%20Evaluation%20of%20Pre-trained%20Text-and-Layout%20Models%20from%20an%20Entity-Centric%20Perspective.pdf)
  Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an Entity-Centric Perspective
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20Zhao]%20A%20Survey%20of%20Large%20Language%20Models.pdf)
  A Survey of Large Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
- [ ] [:link:](./files/NLP/[2024%20lee]%20Quantifying%20Positional%20Biases%20in%20Text%20Embedding%20Models.pdf)
  Quantifying Positional Biases in Text Embedding Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/lee-red?style=flat)
- [ ] [:link:](./files/NLP/[2025%20Casper]%20The%20AI%20Agent%20Index.pdf)
  The AI Agent Index
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Casper-red?style=flat)
- [ ] [:link:](./files/NLP/[2025%20Cetin]%20An%20Evolved%20Universal%20Transformer%20Memory.pdf)
  An Evolved Universal Transformer Memory
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Cetin-red?style=flat)
- [ ] [:link:](./files/NLP/[2025%20Wu]%20CollabLLM_From%20Passive%20Responders%20to%20Active%20Collaborators.pdf)
  CollabLLM: From Passive Responders to Active Collaborators
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/Wu-red?style=flat)
- [ ] [:link:](./files/NLP/[2025]%20DeepSeek_R1.pdf)
  DeepSeek: R1
  ![year](https://img.shields.io/badge/2025-green?style=flat)
  ![auth](https://img.shields.io/badge/[2025-red?style=flat)
<!-- AUTOGENERATED_NLP -->


## :file_folder: TAB

<!-- AUTOGENERATED_TAB -->
- [ ] [:link:](./files/TAB/[2008%20Zeng]%20Using%20Predictive%20Analysis%20to%20Improve%20Invoice-to-Cash%20Collection.pdf)
  Using Predictive Analysis to Improve Invoice-to-Cash Collection
  ![year](https://img.shields.io/badge/2008-green?style=flat)
  ![auth](https://img.shields.io/badge/Zeng-red?style=flat)
- [ ] [:link:](./files/TAB/[2020%20@acl%20Yin]%20TABERT_Pretraining%20for%20Joint%20Understanding%20of%20Textual%20and%20Tabular%20Data.pdf)
  TABERT: Pretraining for Joint Understanding of Textual and Tabular Data
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Yin-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2020%20@aws%20Erickson]%20AutoGluon-Tabular_Robust%20and%20Accurate%20AutoML%20for%20Structured%20Data.pdf)
  AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Erickson-red?style=flat)
  ![tags](https://img.shields.io/badge/aws-blue?style=flat)
- [ ] [:link:](./files/TAB/[2020%20@aws%20Huang]%20TabTransformer_Tabular%20Data%20Modeling%20Using%20Contextual%20Embeddings.pdf)
  TabTransformer: Tabular Data Modeling Using Contextual Embeddings
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Huang-red?style=flat)
  ![tags](https://img.shields.io/badge/aws-blue?style=flat)
- [ ] [:link:](./files/TAB/[2020%20@cvpr%20Prasad]%20CascadeTabNet_An%20approach%20for%20end%20to%20end%20table%20detection%20and%20structure%20recognition%20from%20image-based%20documents.pdf)
  CascadeTabNet: An approach for end to end table detection and structure recognition from image-based documents
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Prasad-red?style=flat)
  ![tags](https://img.shields.io/badge/cvpr-blue?style=flat)
- [ ] [:link:](./files/TAB/[2020%20@neurips%20Yoon]%20VIME_Extending%20the%20Success%20of%20Self-%20and%20Semi-supervised%20Learning%20to%20Tabular%20Domain.pdf)
  VIME: Extending the Success of Self- and Semi-supervised Learning to Tabular Domain
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Yoon-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2021%20@aaai%20Arik]%20TabNet_Attentive%20Interpretable%20Tabular%20Learning.pdf)
  TabNet: Attentive Interpretable Tabular Learning
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Arik-red?style=flat)
  ![tags](https://img.shields.io/badge/aaai-blue?style=flat)
- [ ] [:link:](./files/TAB/[2021%20@google%20Bahri]%20SCARF_Self-Supervised%20Contrastive%20Learning%20using%20Random%20Feature%20Corruption.pdf)
  SCARF: Self-Supervised Contrastive Learning using Random Feature Corruption
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Bahri-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/TAB/[2021%20@neurips%20Gorishniy]%20Revisiting%20Deep%20Learning%20Models%20for%20Tabular%20Data.pdf)
  Revisiting Deep Learning Models for Tabular Data
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Gorishniy-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2021%20@neurips%20Kossen]%20Self-Attention%20Between%20Datapoints_Going%20Beyond%20Individual%20Input-Output%20Pairs%20in%20Deep%20Learning.pdf)
  Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Kossen-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2021%20@sigkdd%20Wang]%20TUTA_Tree-based%20Transformers%20for%20Generally%20Structured%20Table.pdf)
  TUTA: Tree-based Transformers for Generally Structured Table
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/sigkdd-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@if%20Shwartz-Ziv]%20Tabular%20data_Deep%20learning%20is%20not%20all%20you%20need.pdf)
  Tabular data: Deep learning is not all you need
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Shwartz_Ziv-red?style=flat)
  ![tags](https://img.shields.io/badge/if-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@ijcai%20Dong]%20Table%20Pre-training_A%20Survey%20on%20Model%20Architectures,%20Pre-training%20Objectives,%20and%20Downstream%20Tasks.pdf)
  Table Pre-training: A Survey on Model Architectures, Pre-training Objectives, and Downstream Tasks
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Dong-red?style=flat)
  ![tags](https://img.shields.io/badge/ijcai-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@microsoft%20Chen]%20CASPR_Customer%20Activity%20Sequence-based%20Prediction%20and%20Representation.pdf)
  CASPR: Customer Activity Sequence-based Prediction and Representation
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips%20Dinh]%20LIFT_Language-Interfaced%20Fine-Tuning%20for%20Non-Language%20Machine%20Learning%20Tasks.pdf)
  LIFT: Language-Interfaced Fine-Tuning for Non-Language Machine Learning Tasks
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Dinh-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips%20Gorishniy]%20On%20Embeddings%20for%20Numerical%20Features%20in%20Tabular%20Deep%20Learning.pdf)
  On Embeddings for Numerical Features in Tabular Deep Learning
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Gorishniy-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips%20Grinsztajn]%20Why%20do%20tree-based%20models%20still%20outperform%20deep%20learning%20on%20typical%20tabular%20data.pdf)
  Why do tree-based models still outperform deep learning on typical tabular data
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Grinsztajn-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips%20Wang]%20TransTab_Learning%20Transferable%20Tabular%20Transformers%20Across%20Tables.pdf)
  TransTab: Learning Transferable Tabular Transformers Across Tables
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Agarwal]%20Self-supervised%20Representation%20Learning%20Across%20Sequential%20and%20Tabular%20Features%20Using%20Transformers.pdf)
  Self-supervised Representation Learning Across Sequential and Tabular Features Using Transformers
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Agarwal-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Chitlangia]%20Self%20Supervised%20Pre-training%20for%20Large%20Scale%20Tabular%20Data.pdf)
  Self Supervised Pre-training for Large Scale Tabular Data
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Chitlangia-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Hajiramezanali]%20STab_Self-supervised%20Learning%20for%20Tabular%20Data.pdf)
  STab: Self-supervised Learning for Tabular Data
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Hajiramezanali-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Koleva]%20Analysis%20of%20the%20Attention%20in%20Tabular%20Language%20Models.pdf)
  Analysis of the Attention in Tabular Language Models
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Koleva-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Levin]%20Transfer%20Learning%20with%20Deep%20Tabular%20Models.pdf)
  Transfer Learning with Deep Tabular Models
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Levin-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Majmundar]%20MET_Masked%20Encoding%20for%20Tabular%20Data.pdf)
  MET: Masked Encoding for Tabular Data
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Majmundar-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Pietruszka]%20STable_Table%20Generation%20Framework%20for%20Encoder-Decoder%20Models.pdf)
  STable: Table Generation Framework for Encoder-Decoder Models
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Pietruszka-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Somepalli]%20SAINT_Improved%20Neural%20Networks%20for%20Tabular%20Data%20via%20Row%20Attention%20and%20Contrastive%20Pre-Training.pdf)
  SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Somepalli-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Vos]%20Towards%20Parameter-Efficient%20Automation%20of%20Data%20Wrangling%20Tasks%20with%20Prefix-Tuning.pdf)
  Towards Parameter-Efficient Automation of Data Wrangling Tasks with Prefix-Tuning
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Vos-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Wang]%20REGCLR_A%20Self-Supervised%20Framework%20for%20Tabular%20Representation%20Learning%20in%20the%20Wild.pdf)
  REGCLR: A Self-Supervised Framework for Tabular Representation Learning in the Wild
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@neurips_trl%20Zein]%20Tabular%20Data%20Generation_Can%20We%20Fool%20XGBoost?.pdf)
  Tabular Data Generation: Can We Fool XGBoost?
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Zein-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20@nnls%20Borisov]%20Deep%20Neural%20Networks%20and%20Tabular%20Data_A%20Survey.pdf)
  Deep Neural Networks and Tabular Data: A Survey
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Borisov-red?style=flat)
  ![tags](https://img.shields.io/badge/nnls-blue?style=flat)
- [ ] [:link:](./files/TAB/[2022%20Narayan]%20Can%20Foundation%20Models%20Wrangle%20Your%20Data.pdf)
  Can Foundation Models Wrangle Your Data
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Narayan-red?style=flat)
- [ ] [:link:](./files/TAB/[2022%20Rubachev]%20Revisiting%20Pretraining%20Objectives%20for%20Tabular%20Deep%20Learning.pdf)
  Revisiting Pretraining Objectives for Tabular Deep Learning
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Rubachev-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@acl%20Lin]%20An%20Inner%20Table%20Retriever%20for%20Robust%20Table%20Question%20Answering.pdf)
  An Inner Table Retriever for Robust Table Question Answering
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lin-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@aistats%20Hegselmann]%20TabLLM_Few-shot%20Classification%20of%20Tabular%20Data%20with%20Large%20Language%20Models.pdf)
  TabLLM: Few-shot Classification of Tabular Data with Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Hegselmann-red?style=flat)
  ![tags](https://img.shields.io/badge/aistats-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@aws%20Hou]%20Pretrained%20deep%20models%20outperform%20GBDTs%20in%20Learning-To-Rank%20under%20label%20scarcity.pdf)
  Pretrained deep models outperform GBDTs in Learning-To-Rank under label scarcity
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Hou-red?style=flat)
  ![tags](https://img.shields.io/badge/aws-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@aws%20Zhang]%20NameGuess_Column%20Name%20Expansion%20for%20Tabular%20Data.pdf)
  NameGuess: Column Name Expansion for Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
  ![tags](https://img.shields.io/badge/aws-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@cvpr%20Cheng]%20M6Doc_A%20Large-Scale%20Multi-Format,%20Multi-Type,%20Multi-Layout,%20Multi-Language,%20Multi-Annotation%20Category%20Dataset%20for%20Modern%20Document%20Layout%20Analysis.pdf)
  M6Doc: A Large-Scale Multi-Format, Multi-Type, Multi-Layout, Multi-Language, Multi-Annotation Category Dataset for Modern Document Layout Analysis
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Cheng-red?style=flat)
  ![tags](https://img.shields.io/badge/cvpr-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@cvpr%20Da]%20Vision%20Grid%20Transformer%20for%20Document%20Layout%20Analysis.pdf)
  Vision Grid Transformer for Document Layout Analysis
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Da-red?style=flat)
  ![tags](https://img.shields.io/badge/cvpr-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@cvpr%20Huang]%20Improving%20Table%20Structure%20Recognition%20With%20Visual-Alignment%20Sequential%20Coordinate%20Modeling.pdf)
  Improving Table Structure Recognition With Visual-Alignment Sequential Coordinate Modeling
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Huang-red?style=flat)
  ![tags](https://img.shields.io/badge/cvpr-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Akhtar]%20Exploring%20the%20Numerical%20Reasoning%20Capabilities%20of%20Language%20Models_A%20Comprehensive%20Analysis%20on%20Tabular%20Data.pdf)
  Exploring the Numerical Reasoning Capabilities of Language Models: A Comprehensive Analysis on Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Akhtar-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Cao]%20API-Assisted%20Code%20Generation%20for%20Question%20Answering%20on%20Varied%20Table%20Structures.pdf)
  API-Assisted Code Generation for Question Answering on Varied Table Structures
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Cao-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Ghosal]%20ReTAG_Reasoning%20Aware%20Table%20to%20Analytic%20Text%20Generation.pdf)
  ReTAG: Reasoning Aware Table to Analytic Text Generation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ghosal-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Gupta]%20TEMPTABQA_Temporal%20Question%20Answering%20for%20Semi-Structured%20Tables.pdf)
  TEMPTABQA: Temporal Question Answering for Semi-Structured Tables
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Gupta-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Lou]%20S2abEL_A%20Dataset%20for%20Entity%20Linking%20from%20Scientific%20Tables.pdf)
  S2abEL: A Dataset for Entity Linking from Scientific Tables
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lou-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Lu]%20SCITAB_A%20Challenging%20Benchmark%20for%20Compositional%20Reasoning%20and%20Claim%20Verification%20on%20Scientific%20Tables.pdf)
  SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lu-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Zhang]%20Generative%20Table%20Pre-training%20Empowers%20Models%20for%20Tabular%20Prediction.pdf)
  Generative Table Pre-training Empowers Models for Tabular Prediction
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Zhang]%20NameGuess_Column%20Name%20Expansion%20for%20Tabular%20Data.pdf)
  NameGuess: Column Name Expansion for Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@emnlp%20Zhao]%20QTSumm_Query-Focused%20Summarization%20over%20Tabular%20Data.pdf)
  QTSumm: Query-Focused Summarization over Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@iclr%20Hollmann]%20TabPFN_A%20Transformer%20That%20Solves%20Small%20Tabular%20Classification%20Problems%20in%20a%20Second.pdf)
  TabPFN: A Transformer That Solves Small Tabular Classification Problems in a Second
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Hollmann-red?style=flat)
  ![tags](https://img.shields.io/badge/iclr-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@microsoft%20Sui]%20GPT4Table_Can%20Large%20Language%20Models%20Understand%20Structured%20Table%20Data?%20A%20Benchmark%20and%20Empirical%20Study.pdf)
  GPT4Table: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Sui-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips%20Chen]%20HYTREL_Hypergraph-enhanced%20Tabular%20Data%20Representation%20Learning.pdf)
  HYTREL: Hypergraph-enhanced Tabular Data Representation Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips%20Ye]%20Training-Free%20Generalization%20on%20Heterogeneous%20Tabular%20Data%20via%20Meta-Representation.pdf)
  Training-Free Generalization on Heterogeneous Tabular Data via Meta-Representation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ye-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Bonet]%20HyperFast_Instant%20Classification%20for%20Tabular%20Data.pdf)
  HyperFast: Instant Classification for Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Bonet-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Bordt]%20Elephants%20Never%20Forget_Testing%20Language%20Models%20for%20Memorization%20of%20Tabular%20Data.pdf)
  Elephants Never Forget: Testing Language Models for Memorization of Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Bordt-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Breejen]%20Fine-Tuning%20the%20Retrieval%20Mechanism%20for%20Tabular%20Deep%20Learning.pdf)
  Fine-Tuning the Retrieval Mechanism for Tabular Deep Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Breejen-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Chang]%20How%20to%20Prompt%20LLMs%20for%20Text-to-SQL_A%20Study%20in%20Zero-shot,%20Single-domain,%20and%20Cross-domain%20Settings.pdf)
  How to Prompt LLMs for Text-to-SQL: A Study in Zero-shot, Single-domain, and Cross-domain Settings
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Chang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Grinsztajn]%20Modeling%20String%20Entries%20for%20Tabular%20Data%20Prediction_Do%20We%20Need%20Big%20Large%20Language%20Models.pdf)
  Modeling String Entries for Tabular Data Prediction: Do We Need Big Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Grinsztajn-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Huang]%20Data%20Ambiguity%20Strikes%20Back_How%20Documentation%20Improves%20GPT's%20Text-to-SQL.pdf)
  Data Ambiguity Strikes Back: How Documentation Improves GPT's Text-to-SQL
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Huang-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Huh]%20Pool-Search-Demonstrate_Improving%20Data-wrangling%20LLMs%20via%20better%20in-context%20examples.pdf)
  Pool-Search-Demonstrate: Improving Data-wrangling LLMs via better in-context examples
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Huh-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Lee]%20Binning%20as%20a%20Pretext%20Task_Improving%20Self-Supervised%20Learning%20in%20Tabular%20Domains.pdf)
  Binning as a Pretext Task: Improving Self-Supervised Learning in Tabular Domains
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lee-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Ma]%20TabPFGen%20-%20Tabular%20Data%20Generation%20with%20TabPFN.pdf)
  TabPFGen - Tabular Data Generation with TabPFN
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ma-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Margeloiu]%20GCondNet_A%20Novel%20Method%20for%20Improving%20Neural%20Networks%20on%20Small%20High-Dimensional%20Tabular%20Data.pdf)
  GCondNet: A Novel Method for Improving Neural Networks on Small High-Dimensional Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Margeloiu-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Ness]%20In%20Defense%20of%20Zero%20Imputation%20for%20Tabular%20Deep%20Learning.pdf)
  In Defense of Zero Imputation for Tabular Deep Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ness-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Pal]%20MultiTabQA_Generating%20Tabular%20Answers%20for%20Multi-Table%20Question%20Answering.pdf)
  MultiTabQA: Generating Tabular Answers for Multi-Table Question Answering
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Pal-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Peng]%20High-Performance%20Transformers%20for%20Table%20Structure%20Recognition%20Need%20Early%20Convolutions.pdf)
  High-Performance Transformers for Table Structure Recognition Need Early Convolutions
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Peng-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Sarkar]%20Testing%20the%20Limits%20of%20Unified%20Seq2Seq%20LLM%20Pretraining%20on%20Diverse%20Table%20Data%20Tasks.pdf)
  Testing the Limits of Unified Seq2Seq LLM Pretraining on Diverse Table Data Tasks
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Sarkar-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Singha]%20Tabular%20Representation,%20Noisy%20Operators,%20and%20Impacts%20on%20Table%20Structure%20Understanding%20Tasks%20in%20LLMs.pdf)
  Tabular Representation, Noisy Operators, and Impacts on Table Structure Understanding Tasks in LLMs
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Singha-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Sui]%20Self-supervised%20Representation%20Learning%20from%20Random%20Data%20Projectors.pdf)
  Self-supervised Representation Learning from Random Data Projectors
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Sui-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Yak]%20IngesTables_Scalable%20and%20Efficient%20Training%20of%20LLM-Enabled%20Tabular%20Foundation%20Models.pdf)
  IngesTables: Scalable and Efficient Training of LLM-Enabled Tabular Foundation Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yak-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Ye]%20Training-Free%20Generalization%20on%20Heterogeneous%20Tabular%20Data%20via%20Meta-Representation.pdf)
  Training-Free Generalization on Heterogeneous Tabular Data via Meta-Representation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ye-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Zahradnik]%20A%20Deep%20Learning%20Blueprint%20for%20Relational%20Databases.pdf)
  A Deep Learning Blueprint for Relational Databases
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zahradnik-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@neurips_trl%20Zhou]%20Unlocking%20the%20Transferability%20of%20Tokens%20in%20Deep%20Models%20for%20Tabular%20Data.pdf)
  Unlocking the Transferability of Tokens in Deep Models for Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhou-red?style=flat)
  ![tags](https://img.shields.io/badge/neurips_trl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@sap%20Merantix]%20Towards%20Tabular%20Foundation%20Models.pdf)
  Towards Tabular Foundation Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Merantix-red?style=flat)
  ![tags](https://img.shields.io/badge/sap-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20@tacl%20Badaro]%20Transformers%20for%20Tabular%20Data%20Representation_A%20Survey%20of%20Models%20and%20Applications.pdf)
  Transformers for Tabular Data Representation: A Survey of Models and Applications
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Badaro-red?style=flat)
  ![tags](https://img.shields.io/badge/tacl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Alkhatib]%20Interpretable%20Graph%20Neural%20Networks%20for%20Tabular%20Data.pdf)
  Interpretable Graph Neural Networks for Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Alkhatib-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Boudewijn]%20Privacy%20Measurement%20in%20Tabular%20Synthetic%20Data_State%20of%20the%20Art%20and%20Future%20Research%20Directions.pdf)
  Privacy Measurement in Tabular Synthetic Data: State of the Art and Future Research Directions
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Boudewijn-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Cherepanova]%20A%20Performance-Driven%20Benchmark%20for%20Feature%20Selection%20in%20Tabular%20Deep%20Learning.pdf)
  A Performance-Driven Benchmark for Feature Selection in Tabular Deep Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Cherepanova-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Eggert]%20TabLib_A%20Dataset%20of%20627M%20Tables%20with%20Context.pdf)
  TabLib: A Dataset of 627M Tables with Context
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Eggert-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Gorishniy]%20TabR_Unlocking%20the%20Power%20of%20Retrieval-Augmented%20Tabular%20Deep%20Learning.pdf)
  TabR: Unlocking the Power of Retrieval-Augmented Tabular Deep Learning
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Gorishniy-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Lu]%20SCITAB_A%20Challenging%20Benchmark%20for%20Compositional%20Reasoning%20and%20Claim%20Verification%20on%20Scientific%20Tables.pdf)
  SCITAB: A Challenging Benchmark for Compositional Reasoning and Claim Verification on Scientific Tables
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lu-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Ramani]%20Classification%20of%20Tabular%20Data%20by%20Text%20Processing.pdf)
  Classification of Tabular Data by Text Processing
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Ramani-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Wang]%20AnyPredict_Foundation%20Model%20for%20Tabular%20Prediction.pdf)
  AnyPredict: Foundation Model for Tabular Prediction
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Yang]%20UniTabE_Pretraining%20a%20Unified%20Tabular%20Encoder%20for%20Heterogeneous%20Tabular%20Data.pdf)
  UniTabE: Pretraining a Unified Tabular Encoder for Heterogeneous Tabular Data
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yang-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Zhang]%20Natural%20Language%20Interfaces%20for%20Tabular%20Data%20Querying%20and%20Visualization_A%20Survey.pdf)
  Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/TAB/[2023%20Zhu]%20XTab_Cross-table%20Pretraining%20for%20Tabular%20Transformers.pdf)
  XTab: Cross-table Pretraining for Tabular Transformers
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhu-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20@acl%20@aws%20Chen]%20Is%20Table%20Retrieval%20a%20Solved%20Problem?%20Exploring%20Join-Aware%20Multi-Table%20Retrieval.pdf)
  Is Table Retrieval a Solved Problem? Exploring Join-Aware Multi-Table Retrieval
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
  ![tags](https://img.shields.io/badge/aws-blue?style=flat)
- [ ] [:link:](./files/TAB/[2024%20@acl%20Zheng]%20Multimodal%20Table%20Understanding.pdf)
  Multimodal Table Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zheng-red?style=flat)
  ![tags](https://img.shields.io/badge/acl-blue?style=flat)
- [ ] [:link:](./files/TAB/[2024%20@amazon%20Fang]%20Large%20Language%20Models%20on%20Tabular%20Data%20-%20A%20Survey.pdf)
  Large Language Models on Tabular Data - A Survey
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Fang-red?style=flat)
  ![tags](https://img.shields.io/badge/amazon-blue?style=flat)
- [ ] [:link:](./files/TAB/[2024%20@bytedance%20Zhao]%20TabPedia_Towards%20Comprehensive%20Visual%20Table%20Understanding%20with%20Concept%20Synergy.pdf)
  TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
  ![tags](https://img.shields.io/badge/bytedance-blue?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Ajayi]%20Uncertainty%20Quantification%20in%20Table%20Structure%20Recognition.pdf)
  Uncertainty Quantification in Table Structure Recognition
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Ajayi-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Bonet]%20HyperFast_Instant%20Classification%20for%20Tabular%20Data.pdf)
  HyperFast: Instant Classification for Tabular Data
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Bonet-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Deng]%20Tables%20as%20Images_Exploring%20the%20Strengths%20and%20Limitations%20of%20LLMs%20on%20Multimodal%20Representations%20of%20Tabular%20Data.pdf)
  Tables as Images: Exploring the Strengths and Limitations of LLMs on Multimodal Representations of Tabular Data
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Deng-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Li]%20Graph%20Neural%20Networks%20for%20Tabular%20Data%20Learning_A%20Survey%20with%20Taxonomy%20and%20Directions.pdf)
  Graph Neural Networks for Tabular Data Learning: A Survey with Taxonomy and Directions
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Li]%20Unlocking%20Instructive%20In-Context%20Learning%20with%20Tabular%20Prompting%20for%20Relational%20Triple%20Extraction.pdf)
  Unlocking Instructive In-Context Learning with Tabular Prompting for Relational Triple Extraction
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Muller]%20MotherNet_A%20Foundational%20Hypernetwork%20for%20Tabular%20Classification.pdf)
  MotherNet: A Foundational Hypernetwork for Tabular Classification
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Muller-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Sui]%20Table%20Meets%20LLM_Can%20Large%20Language%20Models%20Understand%20Structured%20Table%20Data?%20A%20Benchmark%20and%20Empirical%20Study.pdf)
  Table Meets LLM: Can Large Language Models Understand Structured Table Data? A Benchmark and Empirical Study
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Sui-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Wang]%20Chain-of-Table_Evolving%20Tables%20in%20the%20Reasoning%20Chain%20for%20Table%20Understanding.pdf)
  Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Wu]%20TableBench_A%20Comprehensive%20and%20Complex%20Benchmark%20for%20Table%20Question%20Answering.pdf)
  TableBench: A Comprehensive and Complex Benchmark for Table Question Answering
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wu-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Yak]%20IngesTables_Scalable%20and%20Efficient%20Training%20of%20LLM-Enabled%20Tabular%20Foundation%20Models.pdf)
  IngesTables: Scalable and Efficient Training of LLM-Enabled Tabular Foundation Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Yak-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Zhang]%20SMUTF_Schema%20Matching%20Using%20Generative%20Tags%20and%20Hybrid%20Features.pdf)
  SMUTF: Schema Matching Using Generative Tags and Hybrid Features
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/TAB/[2024%20Zhang]%20TableLLM_Enabling%20Tabular%20Data%20Manipulation%20by%20LLMs%20in%20Real%20Office%20Usage%20Scenarios.pdf)
  TableLLM: Enabling Tabular Data Manipulation by LLMs in Real Office Usage Scenarios
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
<!-- AUTOGENERATED_TAB -->


## :sunrise: Multimodal

<!-- AUTOGENERATED_MM -->
- [ ] [:link:](./files/MM/[2021%20#stable-diff%20Rombach]%20High-Resolution%20Image%20Synthesis%20with%20Latent%20Diffusion%20Models.pdf)
  High-Resolution Image Synthesis with Latent Diffusion Models
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Rombach-red?style=flat)
- [ ] [:link:](./files/MM/[2021%20@google%20#vit%20Dosovitskiy]%20An%20Image%20is%20Worth%2016x16%20Words%20-%20Transformers%20for%20Image%20Recognition%20at%20Scale.pdf)
  An Image is Worth 16x16 Words - Transformers for Image Recognition at Scale
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Dosovitskiy-red?style=flat)
  ![tags](https://img.shields.io/badge/google-blue?style=flat)
- [ ] [:link:](./files/MM/[2021%20@microsoft%20#swin%20Liu]%20Swin%20Transformer%20-%20Hierarchical%20Vision%20Transformer%20using%20Shifted%20Windows.pdf)
  Swin Transformer - Hierarchical Vision Transformer using Shifted Windows
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/MM/[2021%20@microsoft%20#swin%20Liu]%20Swin%20Transformer%20V2%20-%20Scaling%20Up%20Capacity%20and%20Resolution.pdf)
  Swin Transformer V2 - Scaling Up Capacity and Resolution
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/MM/[2021%20@openai%20#clip%20Radford]%20Learning%20Transferable%20Visual%20Models%20From%20Natural%20Language%20Supervision.pdf)
  Learning Transferable Visual Models From Natural Language Supervision
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Radford-red?style=flat)
  ![tags](https://img.shields.io/badge/openai-blue?style=flat)
- [ ] [:link:](./files/MM/[2022%20#DiT%20#SoRA%20Peebles]%20Scalable%20Diffusion%20Models%20with%20Transformers.pdf)
  Scalable Diffusion Models with Transformers
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Peebles-red?style=flat)
- [ ] [:link:](./files/MM/[2023%20@cvpr%20Li]%20Monkey_Image%20Resolution%20and%20Text%20Label%20Are%20Important%20Things%20for%20Large%20Multi-modal%20Models.pdf)
  Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Li-red?style=flat)
  ![tags](https://img.shields.io/badge/cvpr-blue?style=flat)
- [ ] [:link:](./files/MM/[2023%20@emnlp%20Zhao]%20Retrieving%20Multimodal%20Information%20for%20Augmented%20Generation_A%20Survey.pdf)
  Retrieving Multimodal Information for Augmented Generation: A Survey
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhao-red?style=flat)
  ![tags](https://img.shields.io/badge/emnlp-blue?style=flat)
- [ ] [:link:](./files/MM/[2023%20@neurips%20@microsoft%20Lin]%20LayoutPrompter_Awaken%20the%20Design%20Ability%20of%20Large%20Language%20Models.pdf)
  LayoutPrompter: Awaken the Design Ability of Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Lin-red?style=flat)
  ![tags](https://img.shields.io/badge/microsoft-blue?style=flat)
- [ ] [:link:](./files/MM/[2023%20Bai]%20Qwen-VL_A%20Versatile%20Vision-Language%20Model%20for%20Understanding,%20Localization,%20Text%20Reading,%20and%20Beyond.pdf)
  Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Bai-red?style=flat)
- [ ] [:link:](./files/MM/[2023%20Bai]%20Sequential%20Modeling%20Enables%20Scalable%20Learning%20for%20Large%20Vision%20Models.pdf)
  Sequential Modeling Enables Scalable Learning for Large Vision Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Bai-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20@meta%20Bordes]%20An%20Introduction%20to%20Vision-Language%20Modeling.pdf)
  An Introduction to Vision-Language Modeling
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Bordes-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/MM/[2024%20@meta%20Zhou]%20Transfusion_Predict%20the%20Next%20Token%20and%20Diffuse%20Images%20with%20One%20Multi-Modal%20Model.pdf)
  Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhou-red?style=flat)
  ![tags](https://img.shields.io/badge/meta-blue?style=flat)
- [ ] [:link:](./files/MM/[2024%20@mmlab%20Zong]%20MoVA_Adapting%20Mixture%20of%20Vision%20Experts%20to%20Multimodal%20Context.pdf)
  MoVA: Adapting Mixture of Vision Experts to Multimodal Context
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Zong-red?style=flat)
  ![tags](https://img.shields.io/badge/mmlab-blue?style=flat)
- [ ] [:link:](./files/MM/[2024%20Chen]%20Expanding%20Performance%20Boundaries%20of%20Open-Source%20Multimodal%20Models%20with%20Model,%20Data,%20and%20Test-Time%20Scaling.pdf)
  Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Chen]%20Next%20Token%20Prediction%20Towards%20Multimodal%20Intelligence_A%20Comprehensive%20Survey.pdf)
  Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Chen-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Cheng]%20YOLO-World_Real-Time%20Open-Vocabulary%20Object%20Detection.pdf)
  YOLO-World: Real-Time Open-Vocabulary Object Detection
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Cheng-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Faysse]%20ColPali_Efficient%20Document%20Retrieval%20with%20Vision%20Language%20Models.pdf)
  ColPali: Efficient Document Retrieval with Vision Language Models
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Faysse-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Fuest]%20Diffusion%20Models%20and%20Representation%20Learning_A%20Survey.pdf)
  Diffusion Models and Representation Learning: A Survey
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Fuest-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Gao]%20Mini-InternVL_A%20Flexible-Transfer%20Pocket%20Multimodal%20Model%20with%205%%20Parameters%20and%2090%%20Performance.pdf)
  Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Gao-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Gou]%20Eyes%20Closed,%20Safety%20On_Protecting%20Multimodal%20LLMs%20via%20Image-to-Text%20Transformation.pdf)
  Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Gou-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Masry]%20ChartInstruct_Instruction%20Tuning%20for%20Chart%20Comprehension%20and%20Reasoning.pdf)
  ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Masry-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Wang]%20Chain-of-Thought%20Reasoning%20Without%20Prompting.pdf)
  Chain-of-Thought Reasoning Without Prompting
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Wang]%20Qwen2-VL_Enhancing%20Vision-Language%20Model’s%20Perception%20of%20the%20World%20at%20Any%20Resolution.pdf)
  Qwen2-VL: Enhancing Vision-Language Model’s Perception of the World at Any Resolution
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Yang]%20Law%20of%20Vision%20Representation%20in%20MLLMs.pdf)
  Law of Vision Representation in MLLMs
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Yang-red?style=flat)
- [ ] [:link:](./files/MM/[2024%20Yu]%20VisRAG_Vision-based%20Retrieval-augmented%20Generation%20on%20Multi-modality%20Documents.pdf)
  VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/Yu-red?style=flat)
<!-- AUTOGENERATED_MM -->


## :spider_web: KG

<!-- AUTOGENERATED_KG -->
- [ ] [:link:](./files/KG/[2017%20Hamilton]%20Inductive%20Representation%20Learning%20on%20Large%20Graphs.pdf)
  Inductive Representation Learning on Large Graphs
  ![year](https://img.shields.io/badge/2017-green?style=flat)
  ![auth](https://img.shields.io/badge/Hamilton-red?style=flat)
- [ ] [:link:](./files/KG/[2018%20Battaglia]%20Relational%20inductive%20biases,%20deep%20learning,%20and%20graph%20networks.pdf)
  Relational inductive biases, deep learning, and graph networks
  ![year](https://img.shields.io/badge/2018-green?style=flat)
  ![auth](https://img.shields.io/badge/Battaglia-red?style=flat)
- [ ] [:link:](./files/KG/[2018%20Velickovic]%20Graph%20Attention%20Networks.pdf)
  Graph Attention Networks
  ![year](https://img.shields.io/badge/2018-green?style=flat)
  ![auth](https://img.shields.io/badge/Velickovic-red?style=flat)
- [ ] [:link:](./files/KG/[2018%20Zhang]%20An%20End-to-End%20Deep%20Learning%20Architecture%20for%20Graph%20Classification.pdf)
  An End-to-End Deep Learning Architecture for Graph Classification
  ![year](https://img.shields.io/badge/2018-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/KG/[2019%20Fey]%20Fast%20Graph%20Representation%20Learning%20with%20Pytorch%20Geometric.pdf)
  Fast Graph Representation Learning with Pytorch Geometric
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Fey-red?style=flat)
- [ ] [:link:](./files/KG/[2019%20Lee]%20Self-Attention%20Graph%20Pooling.pdf)
  Self-Attention Graph Pooling
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Lee-red?style=flat)
- [ ] [:link:](./files/KG/[2019%20Xu]%20How%20Powerful%20Are%20Graph%20Neural%20Networks.pdf)
  How Powerful Are Graph Neural Networks
  ![year](https://img.shields.io/badge/2019-green?style=flat)
  ![auth](https://img.shields.io/badge/Xu-red?style=flat)
- [ ] [:link:](./files/KG/[2020%20Bacciu]%20A%20gentle%20introduction%20to%20deep%20learning%20for%20graphs.pdf)
  A gentle introduction to deep learning for graphs
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Bacciu-red?style=flat)
- [ ] [:link:](./files/KG/[2020%20Errica]%20A%20Fair%20Comparison%20of%20Graph%20Neural%20Networks%20for%20Graph%20Classification.pdf)
  A Fair Comparison of Graph Neural Networks for Graph Classification
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Errica-red?style=flat)
- [ ] [:link:](./files/KG/[2020%20Zhang]%20Deep%20Learning%20on%20Graphs_A%20Survey.pdf)
  Deep Learning on Graphs: A Survey
  ![year](https://img.shields.io/badge/2020-green?style=flat)
  ![auth](https://img.shields.io/badge/Zhang-red?style=flat)
- [ ] [:link:](./files/KG/[2021%20@naacl%20Yasunaga]%20QA-GNN_Reasoning%20with%20Language%20Models%20and%20Knowledge%20Graphs%20for%20Question%20Answering.pdf)
  QA-GNN: Reasoning with Language Models and Knowledge Graphs for Question Answering
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Yasunaga-red?style=flat)
  ![tags](https://img.shields.io/badge/naacl-blue?style=flat)
- [ ] [:link:](./files/KG/[2021%20Sanchez-Lengeling]%20A%20Gentle%20Introduction%20to%20Graph%20Neural%20Networks.pdf)
  A Gentle Introduction to Graph Neural Networks
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Sanchez_Lengeling-red?style=flat)
- [ ] [:link:](./files/KG/[2021%20Wu]%20A%20Comprehensive%20Survey%20on%20Graph%20Neural%20Networks.pdf)
  A Comprehensive Survey on Graph Neural Networks
  ![year](https://img.shields.io/badge/2021-green?style=flat)
  ![auth](https://img.shields.io/badge/Wu-red?style=flat)
- [ ] [:link:](./files/KG/[2022%20Min]%20Transformer%20for%20Graphs_An%20Overview%20from%20Architecture%20Perspective.pdf)
  Transformer for Graphs: An Overview from Architecture Perspective
  ![year](https://img.shields.io/badge/2022-green?style=flat)
  ![auth](https://img.shields.io/badge/Min-red?style=flat)
- [ ] [:link:](./files/KG/[2023%20@kdd%20Sun]%20All%20in%20One_Multi-task%20Prompting%20for%20Graph%20Neural%20Networks.pdf)
  All in One: Multi-task Prompting for Graph Neural Networks
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Sun-red?style=flat)
  ![tags](https://img.shields.io/badge/kdd-blue?style=flat)
- [ ] [:link:](./files/KG/[2023%20Besta]%20Graph%20of%20Thoughts_Solving%20Elaborate%20Problems%20with%20Large%20Language%20Models.pdf)
  Graph of Thoughts: Solving Elaborate Problems with Large Language Models
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Besta-red?style=flat)
- [ ] [:link:](./files/KG/[2023%20Dong]%20Generations%20of%20Knowledge%20Graphs_The%20Crazy%20Ideas%20and%20the%20Business%20Impact.pdf)
  Generations of Knowledge Graphs: The Crazy Ideas and the Business Impact
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Dong-red?style=flat)
- [ ] [:link:](./files/KG/[2023%20Fey]%20Relational%20Deep%20Learning_Graph%20Representation%20Learning%20on%20Relational%20Databases.pdf)
  Relational Deep Learning: Graph Representation Learning on Relational Databases
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Fey-red?style=flat)
- [ ] [:link:](./files/KG/[2023%20Guo]%20A%20Systematic%20Survey%20on%20Deep%20Generative%20Models%20for%20Graph%20Generation.pdf)
  A Systematic Survey on Deep Generative Models for Graph Generation
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Guo-red?style=flat)
- [ ] [:link:](./files/KG/[2023%20Wang]%20VRDU_A%20Benchmark%20for%20Visually-rich%20Document%20Understanding.pdf)
  VRDU: A Benchmark for Visually-rich Document Understanding
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Wang-red?style=flat)
- [ ] [:link:](./files/KG/[2023%20Yuan]%20Explainability%20in%20Graph%20Neural%20Networks_A%20Taxonomic%20Survey.pdf)
  Explainability in Graph Neural Networks: A Taxonomic Survey
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Yuan-red?style=flat)
<!-- AUTOGENERATED_KG -->


## :inbox_tray: UNSORTED

<!-- AUTOGENERATED_UNSORTED -->
- [ ] [:link:](./files/UNSORTED/[2023%20Liu]%20iTransformer_Inverted%20Transformers%20Are%20Effective%20for%20Time%20Series%20Forecasting.pdf)
  iTransformer: Inverted Transformers Are Effective for Time Series Forecasting
  ![year](https://img.shields.io/badge/2023-green?style=flat)
  ![auth](https://img.shields.io/badge/Liu-red?style=flat)
- [ ] [:link:](./files/UNSORTED/[2024%20@stanford%20HAI]%20AI%20Index%20Report%202024.pdf)
  AI Index Report 2024
  ![year](https://img.shields.io/badge/2024-green?style=flat)
  ![auth](https://img.shields.io/badge/HAI-red?style=flat)
  ![tags](https://img.shields.io/badge/stanford-blue?style=flat)
<!-- AUTOGENERATED_UNSORTED -->


## Automation

1. Rename and put downloaded article into categorical folder.
2. Run `automation/automation.py`.
3. Add :white_check_mark: `:white_check_mark:` manually while you complete reading an article.
