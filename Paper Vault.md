> [!Summary] Summary
> This repository comprises a collection of research articles relevant to ***natural language processing***, ***vision language model***, ***document processing***, and ***general AI topics***.

## DOX

%%AUTOGENERATED_DOX%%
`2025 Barboule` | [[./files/DOX/[2025 Barboule] Survey on Question Answering over Visually Rich Documents_Methods, Challenges, and Trends.pdf|Survey on Question Answering over Visually Rich Documents: Methods, Challenges, and Trends]]
`2025 Chen` | [[./files/DOX/[2025 @iclr Chen] Graph-based Document Structure Analysis.pdf|Graph-based Document Structure Analysis]] | #paper/iclr
`2025 Chen` | [[./files/DOX/[2025 @iclr Chen] SV-RAG_LoRA-Contextualizing Adaptation of Large Multimodal Models for Multi-page Document Understanding.pdf|SV-RAG: LoRA-Contextualizing Adaptation of Large Multimodal Models for Multi-page Document Understanding]] | #paper/iclr
`2025 Faysse` | [[./files/DOX/[2025 @iclr Faysse] ColPali_Efficient Document Retrieval with Vision Language Models.pdf|ColPali: Efficient Document Retrieval with Vision Language Models]] | #paper/iclr
`2025 Feng` | [[./files/DOX/[2025 @bytedance Feng] Dolphin_Document Image Parsing via Heterogeneous Anchor Prompting.pdf|Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting]] | #paper/bytedance
`2025 GraniteVision` | [[./files/DOX/[2025 @ibm GraniteVision] Granite Vision_A Lightweight, Open-Source Multimodal Model for Enterprise Intelligence.pdf|Granite Vision: A Lightweight, Open-Source Multimodal Model for Enterprise Intelligence]] | #paper/ibm
`2025 Gutteridge` | [[./files/DOX/[2025 Gutteridge] Judge a Book by its Cover_Investigating Multi-Modal LLMs for Multi-Page Handwritten Document Transcription.pdf|Judge a Book by its Cover: Investigating Multi-Modal LLMs for Multi-Page Handwritten Document Transcription]]
`2025 Hu` | [[./files/DOX/[2025 Hu] DocMamba_Efficient Document Pre-training with State Space Model.pdf|DocMamba: Efficient Document Pre-training with State Space Model]]
`2025 Huang` | [[./files/DOX/[2025 @iclr Huang] Mini-Monkey_Alleviating the Semantic Sawtooth Effect for Lightweight MLLMs via Complementary Image Pyramid.pdf|Mini-Monkey: Alleviating the Semantic Sawtooth Effect for Lightweight MLLMs via Complementary Image Pyramid]] | #paper/iclr
`2025 Khang` | [[./files/DOX/[2025 Khang] KIEval_Evaluation Metric for Document Key Information Extraction.pdf|KIEval: Evaluation Metric for Document Key Information Extraction]]
`2025 Le` | [[./files/DOX/[2025 Le] QID_Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding.pdf|QID: Efficient Query-Informed ViTs in Data-Scarce Regimes for OCR-free Visual Document Understanding]]
`2025 Li` | [[./files/DOX/[2025 Li] GDI-Bench_A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling.pdf|GDI-Bench: A Benchmark for General Document Intelligence with Vision and Reasoning Decoupling]]
`2025 Liskavets` | [[./files/DOX/[2025 @aaai Liskavets] Prompt Compression with Context-Aware Sentence Encoding for Fast and Improved LLM Inference.pdf|Prompt Compression with Context-Aware Sentence Encoding for Fast and Improved LLM Inference]] | #paper/aaai
`2025 Mo` | [[./files/DOX/[2025 @alibaba Mo] Doc-CoB_Enhancing Multi-Modal Document Understanding with Visual Chain-of-Boxes Reasoning.pdf|Doc-CoB: Enhancing Multi-Modal Document Understanding with Visual Chain-of-Boxes Reasoning]] | #paper/alibaba
`2025 Morris` | [[./files/DOX/[2025 @iclr Morris] Contextual Document Embeddings.pdf|Contextual Document Embeddings]] | #paper/iclr
`2025 Nassar` | [[./files/DOX/[2025 @ibm Nassar] SmolDocling_An ultra-compact vision-language model for end-to-end multi-modal document conversion.pdf|SmolDocling: An ultra-compact vision-language model for end-to-end multi-modal document conversion]] | #paper/ibm
`2025 Ni` | [[./files/DOX/[2025 @baidu Ni] PP-DocBee_Improving Multimodal Document Understanding Through a Bag of Tricks.pdf|PP-DocBee: Improving Multimodal Document Understanding Through a Bag of Tricks]] | #paper/baidu
`2025 Ouyang` | [[./files/DOX/[2025 Ouyang] OmniDocBench_Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations.pdf|OmniDocBench: Benchmarking Diverse PDF Document Parsing with Comprehensive Annotations]]
`2025 Poznanski` | [[./files/DOX/[2025 Poznanski] olmOCR_Unlocking Trillions of Tokens in PDFs with Vision Language Models.pdf|olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models]]
`2025 Sampaio` | [[./files/DOX/[2025 Sampaio] Unsupervised Document and Template Clustering using Multimodal Embeddings.pdf|Unsupervised Document and Template Clustering using Multimodal Embeddings]]
`2025 Shao` | [[./files/DOX/[2025 @alibaba Shao] Is Cognition Consistent with Perception? Assessing and Mitigating Multimodal Knowledge Conflicts in Document Understanding.pdf|Is Cognition Consistent with Perception? Assessing and Mitigating Multimodal Knowledge Conflicts in Document Understanding]] | #paper/alibaba
`2025 Suri` | [[./files/DOX/[2025 Suri] VisDoM_Multi-Document QA with Visually Rich Elements Using Multimodal Retrieval-Augmented Generation.pdf|VisDoM: Multi-Document QA with Visually Rich Elements Using Multimodal Retrieval-Augmented Generation]]
`2025 Wang` | [[./files/DOX/[2025 @neurips Wang] CharXiv_Charting Gaps in Realistic Chart Understanding in Multimodal LLMs.pdf|CharXiv: Charting Gaps in Realistic Chart Understanding in Multimodal LLMs]] | #paper/neurips
`2025 Wasserman` | [[./files/DOX/[2025 @ibm Wasserman] REAL-MM-RAG_A Real-World Multi-Modal Retrieval Benchmark.pdf|REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark]] | #paper/ibm
`2025 Xie` | [[./files/DOX/[2025 Xie] PDF-WuKong_A Large Multimodal Model for Efficient Long PDF Reading with End-to-End Sparse Sampling.pdf|PDF-WuKong: A Large Multimodal Model for Efficient Long PDF Reading with End-to-End Sparse Sampling]]
`2025 Yu` | [[./files/DOX/[2025 @iclr Yu] VisRAG_Vision-based Retrieval-augmented Generation on Multi-modality Documents.pdf|VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents]] | #paper/iclr
`2025 Yu` | [[./files/DOX/[2025 Yu] OmniParser V2_Structured-Points-of-Thought for Unified Visual Text Parsing and Its Generality to Multimodal Large Language Models.pdf|OmniParser V2: Structured-Points-of-Thought for Unified Visual Text Parsing and Its Generality to Multimodal Large Language Models]]
`2025 Zhu` | [[./files/DOX/[2025 @iclr Zhu] Enhancing Document Understanding with Group Position Embedding_A Novel Approach to Incorporate Layout Information.pdf|Enhancing Document Understanding with Group Position Embedding: A Novel Approach to Incorporate Layout Information]] | #paper/iclr
`2024 Abdallah` | [[./files/DOX/[2024 Abdallah] CORU_Comprehensive Post-OCR Parsing and Receipt Understanding Dataset.pdf|CORU: Comprehensive Post-OCR Parsing and Receipt Understanding Dataset]]
`2024 Abdallah` | [[./files/DOX/[2024 Abdallah] Transformers and Language Models in Form Understanding_A Comprehensive Review of Scanned Document Analysis.pdf|Transformers and Language Models in Form Understanding: A Comprehensive Review of Scanned Document Analysis]]
`2024 Adhikari` | [[./files/DOX/[2024 Adhikari] A Comparative Study of PDF Parsing Tools Across Diverse Document Categories.pdf|A Comparative Study of PDF Parsing Tools Across Diverse Document Categories]]
`2024 Biswas` | [[./files/DOX/[2024 Biswas] DocSynthv2_A Practical Autoregressive Modeling for Document Generation.pdf|DocSynthv2: A Practical Autoregressive Modeling for Document Generation]]
`2024 Boytsov` | [[./files/DOX/[2024 Boytsov] Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding.pdf|Understanding Performance of Long-Document Ranking Models through Comprehensive Evaluation and Leaderboarding]]
`2024 Bronnec` | [[./files/DOX/[2024 Bronnec] LOCOST_State-Space Models for Long Document Abstractive Summarization.pdf|LOCOST: State-Space Models for Long Document Abstractive Summarization]]
`2024 Buchmann` | [[./files/DOX/[2024 @emnlp Buchmann] Attribute or Abstain_Large Language Models as Long Document Assistants.pdf|Attribute or Abstain: Large Language Models as Long Document Assistants]] | #paper/emnlp
`2024 Chen` | [[./files/DOX/[2024 @emnlp @aws Chen] MDCR_A Dataset for Multi-Document Conditional Reasoning.pdf|MDCR: A Dataset for Multi-Document Conditional Reasoning]] | #paper/emnlp #paper/aws
`2024 Cho` | [[./files/DOX/[2024 Cho] M3DocRAG_Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding.pdf|M3DocRAG: Multi-modal Retrieval is What You Need for Multi-page Multi-document Understanding]]
`2024 Choi` | [[./files/DOX/[2024 Choi] Model-based Preference Optimization in Abstractive Summarization without Human Feedback.pdf|Model-based Preference Optimization in Abstractive Summarization without Human Feedback]]
`2024 Constantinou` | [[./files/DOX/[2024 Constantinou] Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification.pdf|Out-of-Distribution Detection with Attention Head Masking for Multimodal Document Classification]]
`2024 Deng` | [[./files/DOX/[2024 @acl Deng] Document-level Claim Extraction and Decontextualisation for Fact-Checking.pdf|Document-level Claim Extraction and Decontextualisation for Fact-Checking]] | #paper/acl
`2024 Deng` | [[./files/DOX/[2024 Deng] LongDocURL_a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating.pdf|LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating]]
`2024 Ding` | [[./files/DOX/[2024 Ding] PDF-MVQA_A Dataset for Multimodal Information Retrieval in PDF-based Visual Question Answering.pdf|PDF-MVQA: A Dataset for Multimodal Information Retrieval in PDF-based Visual Question Answering]]
`2024 Futeral` | [[./files/DOX/[2024 Futeral] mOSCAR_A Large-scale Multilingual and Multimodal Document-level Corpus.pdf|mOSCAR: A Large-scale Multilingual and Multimodal Document-level Corpus]]
`2024 Gao` | [[./files/DOX/[2024 @acl Gao] TTM-RE_Memory-Augmented Document-Level Relation Extraction.pdf|TTM-RE: Memory-Augmented Document-Level Relation Extraction]] | #paper/acl
`2024 He` | [[./files/DOX/[2024 He] DR-RAG_Applying Dynamic Document Relevance to RetrievalAugmented Generation for Question-Answering.pdf|DR-RAG: Applying Dynamic Document Relevance to RetrievalAugmented Generation for Question-Answering]]
`2024 Hsu` | [[./files/DOX/[2024 Hsu] M3T_A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation.pdf|M3T: A New Benchmark Dataset for Multi-Modal Document-Level Machine Translation]]
`2024 Hu` | [[./files/DOX/[2024 @aaai Hu] DocMamba_Efficient Document Pre-training with State Space Model.pdf|DocMamba: Efficient Document Pre-training with State Space Model]] | #paper/aaai
`2024 Hu` | [[./files/DOX/[2024 @emnlp @alibaba Hu] mPLUG-DocOwl 1.5_Unified Structure Learning for OCR-free Document Understanding.pdf|mPLUG-DocOwl 1.5: Unified Structure Learning for OCR-free Document Understanding]] | #paper/emnlp #paper/alibaba
`2024 Hu` | [[./files/DOX/[2024 Hu] mPLUG-DocOwl2_High-resolution Compressing for OCR-free Multi-page Document Understanding.pdf|mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding]]
`2024 Hui` | [[./files/DOX/[2024 Hui] UDA_A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis.pdf|UDA: A Benchmark Suite for Retrieval Augmented Generation in Real-world Document Analysis]]
`2024 Li` | [[./files/DOX/[2024 @acl Li] Hypergraph based Understanding for Document Semantic Entity Recognition.pdf|Hypergraph based Understanding for Document Semantic Entity Recognition]] | #paper/acl
`2024 Li` | [[./files/DOX/[2024 @iclr Li] ChuLo_Chunk-Level Key Information Representation for Long Document Processing.pdf|ChuLo: Chunk-Level Key Information Representation for Long Document Processing]] | #paper/iclr
`2024 Li` | [[./files/DOX/[2024 Li] Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models.pdf|Enhancing Visual Document Understanding with Contrastive Learning in Large Visual-Language Models]]
`2024 Liao` | [[./files/DOX/[2024 @alibaba Liao] DocLayLLM_An Efficient and Effective Multi-modal Extension of Large Language Models for Text-rich Document Understanding.pdf|DocLayLLM: An Efficient and Effective Multi-modal Extension of Large Language Models for Text-rich Document Understanding]] | #paper/alibaba
`2024 Liao` | [[./files/DOX/[2024 @aws Liao] DocTr_Document Transformer for Structured Information Extraction in Documents.pdf|DocTr: Document Transformer for Structured Information Extraction in Documents]] | #paper/aws
`2024 Lin` | [[./files/DOX/[2024 Lin] PEneo_Unifying Line Extraction, Line Grouping, and Entity Linking for End-to-end Document Pair Extraction.pdf|PEneo: Unifying Line Extraction, Line Grouping, and Entity Linking for End-to-end Document Pair Extraction]]
`2024 Liu` | [[./files/DOX/[2024 Liu] Fox_Focus Anywhere for Fine-grained Multi-page Document Understanding.pdf|Fox: Focus Anywhere for Fine-grained Multi-page Document Understanding]]
`2024 Liu` | [[./files/DOX/[2024 Liu] See then Tell_Enhancing Key Information Extraction with Vision Grounding.pdf|See then Tell: Enhancing Key Information Extraction with Vision Grounding]]
`2024 Liu` | [[./files/DOX/[2024 Liu] TextMonkey_An OCR-Free Large Multimodal Model for Understanding Document.pdf|TextMonkey: An OCR-Free Large Multimodal Model for Understanding Document]]
`2024 Lu` | [[./files/DOX/[2024 Lu] A Bounding Box is Worth One Token_Interleaving Layout and Text in a Large Language Model for Document Understanding.pdf|A Bounding Box is Worth One Token: Interleaving Layout and Text in a Large Language Model for Document Understanding]]
`2024 Lu` | [[./files/DOX/[2024 Lu] From Text to Pixel_Advancing Long-Context Understanding in MLLMs.pdf|From Text to Pixel: Advancing Long-Context Understanding in MLLMs]]
`2024 Luo` | [[./files/DOX/[2024 @alibaba Luo] LayoutLLM_Layout Instruction Tuning with Large Language Models for Document Understanding.pdf|LayoutLLM: Layout Instruction Tuning with Large Language Models for Document Understanding]] | #paper/alibaba
`2024 Ma` | [[./files/DOX/[2024 @emnlp Ma] Unifying Multimodal Retrieval via Document Screenshot Embedding.pdf|Unifying Multimodal Retrieval via Document Screenshot Embedding]] | #paper/emnlp
`2024 Mao` | [[./files/DOX/[2024 Mao] Visually Guided Generative Text-Layout Pre-training for Document Intelligence.pdf|Visually Guided Generative Text-Layout Pre-training for Document Intelligence]]
`2024 Mass` | [[./files/DOX/[2024 @emnlp Mass] More Bang for your Context_Virtual Documents for Question Answering over Long Documents.pdf|More Bang for your Context: Virtual Documents for Question Answering over Long Documents]] | #paper/emnlp
`2024 Min` | [[./files/DOX/[2024 @acl Min] Synergetic Event Understanding_A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models.pdf|Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models]] | #paper/acl
`2024 Mohammadshirazi` | [[./files/DOX/[2024 Mohammadshirazi] DocParseNet_Advanced Semantic Segmentation and OCR Embeddings for Efficient Scanned Document Annotation.pdf|DocParseNet: Advanced Semantic Segmentation and OCR Embeddings for Efficient Scanned Document Annotation]]
`2024 Morris` | [[./files/DOX/[2024 Morris] Contextual Document Embeddings.pdf|Contextual Document Embeddings]]
`2024 Na` | [[./files/DOX/[2024 @acl Na] Reward-based Input Construction for Cross-document Relation Extraction.pdf|Reward-based Input Construction for Cross-document Relation Extraction]] | #paper/acl
`2024 Perot` | [[./files/DOX/[2024 @google Perot] LMDX_Language Model-based Document Information Extraction and Localization.pdf|LMDX: Language Model-based Document Information Extraction and Localization]] | #paper/google
`2024 Phogat` | [[./files/DOX/[2024 @emnlp Phogat] Fine-tuning Smaller Language Models for Question Answering over Financial Documents.pdf|Fine-tuning Smaller Language Models for Question Answering over Financial Documents]] | #paper/emnlp
`2024 Qi` | [[./files/DOX/[2024 @acl Qi] End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction.pdf|End-to-end Learning of Logical Rules for Enhancing Document-level Relation Extraction]] | #paper/acl
`2024 Qi` | [[./files/DOX/[2024 Qi] ADELIE_Aligning Large Language Models on Information Extraction.pdf|ADELIE: Aligning Large Language Models on Information Extraction]]
`2024 Shehzadi` | [[./files/DOX/[2024 Shehzadi] A Hybrid Approach for Document Layout Analysis in Document images.pdf|A Hybrid Approach for Document Layout Analysis in Document images]]
`2024 Sinha` | [[./files/DOX/[2024 @amazon Sinha] Guiding Vision-Language Model Selection for Visual Question-Answering Across Tasks, Domains, and Knowledge Types.pdf|Guiding Vision-Language Model Selection for Visual Question-Answering Across Tasks, Domains, and Knowledge Types]] | #paper/amazon
`2024 Wan` | [[./files/DOX/[2024 @alibaba Wan] OmniParser_A Unified Framework for Text Spotting, Key Information Extraction and Table Recognition.pdf|OmniParser: A Unified Framework for Text Spotting, Key Information Extraction and Table Recognition]] | #paper/alibaba
`2024 Wang` | [[./files/DOX/[2024 @aaai Wang] Knowledge Graph Prompting for Multi-Document Question Answering.pdf|Knowledge Graph Prompting for Multi-Document Question Answering]] | #paper/aaai
`2024 Wang` | [[./files/DOX/[2024 @acl @cohere Wang] DAPR_A Benchmark on Document-Aware Passage Retrieval.pdf|DAPR: A Benchmark on Document-Aware Passage Retrieval]] | #paper/acl #paper/cohere
`2024 Wang` | [[./files/DOX/[2024 @acl Wang] DocLLM_A layout-aware generative language model for multimodal document understanding.pdf|DocLLM: A layout-aware generative language model for multimodal document understanding]] | #paper/acl
`2024 Wang` | [[./files/DOX/[2024 @emnlp @alibaba Wang] Leave No Document Behind_Benchmarking Long-Context LLMs with Extended Multi-Doc QA.pdf|Leave No Document Behind: Benchmarking Long-Context LLMs with Extended Multi-Doc QA]] | #paper/emnlp #paper/alibaba
`2024 Wang` | [[./files/DOX/[2024 @microsoft Wang] DLAFormer_An End-to-End Transformer For Document Layout Analysis.pdf|DLAFormer: An End-to-End Transformer For Document Layout Analysis]] | #paper/microsoft
`2024 Xhen` | [[./files/DOX/[2024 @acl Xhen] MetaSumPerceiver_Multimodal Multi-Document Evidence Summarization for Fact-Checking.pdf|MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking]] | #paper/acl
`2024 Xia` | [[./files/DOX/[2024 @microsoft Xia] Vision Language Models for Spreadsheet Understanding_Challenges and Opportunities.pdf|Vision Language Models for Spreadsheet Understanding: Challenges and Opportunities]] | #paper/microsoft
`2024 Xia` | [[./files/DOX/[2024 Xia] StructChart_Perception, Structuring, Reasoning for Visual Chart Understanding.pdf|StructChart: Perception, Structuring, Reasoning for Visual Chart Understanding]]
`2024 Xu` | [[./files/DOX/[2024 Xu] Large language models for generative information extraction_a survey.pdf|Large language models for generative information extraction: a survey]]
`2024 Yang` | [[./files/DOX/[2024 @emnlp @adobe Yang] FIZZ_Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document.pdf|FIZZ: Factual Inconsistency Detection by Zoom-in Summary and Zoom-out Document]] | #paper/emnlp #paper/adobe
`2024 Ye` | [[./files/DOX/[2024 @emnlp Ye] GlobeSumm_A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization.pdf|GlobeSumm: A Challenging Benchmark Towards Unifying Multi-lingual, Cross-lingual and Multi-document News Summarization]] | #paper/emnlp
`2024 Yu` | [[./files/DOX/[2024 Yu] TextHawk_Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models.pdf|TextHawk: Exploring Efficient Fine-Grained Perception of Multimodal Large Language Models]]
`2024 Zhang` | [[./files/DOX/[2024 @aaai Zhang] DocKylin_A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming.pdf|DocKylin: A Large Multimodal Model for Visual Document Understanding with Efficient Visual Slimming]] | #paper/aaai
`2024 Zhang` | [[./files/DOX/[2024 @emnlp Zhang] Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding.pdf|Modeling Layout Reading Order as Ordering Relations for Visually-rich Document Understanding]] | #paper/emnlp
`2024 Zhang` | [[./files/DOX/[2024 Zhang] Document Parsing Unveiled_Techniques, Challenges, and Prospects for Structured Information Extraction.pdf|Document Parsing Unveiled: Techniques, Challenges, and Prospects for Structured Information Extraction]]
`2024 Zhang` | [[./files/DOX/[2024 Zhang] SAIL_Sample-Centric In-Context Learning for Document Information Extraction.pdf|SAIL: Sample-Centric In-Context Learning for Document Information Extraction]]
`2024 Zhao` | [[./files/DOX/[2024 @acl Zhao] DocMath-Eval_Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents.pdf|DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents]] | #paper/acl
`2024 Zhao` | [[./files/DOX/[2024 Zhao] TabPedia_Towards Comprehensive Visual Table Understanding with Concept Synergy.pdf|TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy]]
`2024 Zhou` | [[./files/DOX/[2024 @acl Zhou] LLMs Learn Task Heuristics from Demonstrations_A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction.pdf|LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction]] | #paper/acl
`2024 Zhu` | [[./files/DOX/[2024 @acl Zhu] FanOutQA_A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models.pdf|FanOutQA: A Multi-Hop, Multi-Document Question Answering Benchmark for Large Language Models]] | #paper/acl
`2024 Zhu` | [[./files/DOX/[2024 Zhu] MMDocBench_Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding.pdf|MMDocBench: Benchmarking Large Vision-Language Models for Fine-Grained Visual Document Understanding]]
`2024 Zhuang` | [[./files/DOX/[2024 @emnlp Zhuang] PromptReps_Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval.pdf|PromptReps: Prompting Large Language Models to Generate Dense and Sparse Representations for Zero-Shot Document Retrieval]] | #paper/emnlp
`2024 Zmigrod` | [[./files/DOX/[2024 Zmigrod] BuDDIE_A Business Document Dataset for Multi-task Information Extraction.pdf|BuDDIE: A Business Document Dataset for Multi-task Information Extraction]]
`2023 Blecher` | [[./files/DOX/[2023 @meta Blecher] Nougat_Neural Optical Understanding for Academic Documents.pdf|Nougat: Neural Optical Understanding for Academic Documents]] | #paper/meta
`2023 Han` | [[./files/DOX/[2023 Han] ChartLlama_A Multimodal LLM for Chart Understanding and Generation.pdf|ChartLlama: A Multimodal LLM for Chart Understanding and Generation]]
`2023 Masry` | [[./files/DOX/[2023 Masry] UniChart_A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning.pdf|UniChart: A Universal Vision-language Pretrained Model for Chart Comprehension and Reasoning]]
`2023 Ozyurt` | [[./files/DOX/[2023 Ozyurt] Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models.pdf|Document-Level In-Context Few-Shot Relation Extraction via Pre-Trained Language Models]]
`2023 Ren` | [[./files/DOX/[2023 @acl Ren] Retrieve-and-Sample_Document-level Event Argument Extraction via Hybrid Retrieval Augmentation.pdf|Retrieve-and-Sample: Document-level Event Argument Extraction via Hybrid Retrieval Augmentation]] | #paper/acl
`2023 Tang` | [[./files/DOX/[2023 @cvpr @microsoft Tang] Unifying Vision, Text, and Layout for Universal Document Processing.pdf|Unifying Vision, Text, and Layout for Universal Document Processing]] | #paper/cvpr #paper/microsoft
`2023 Wang` | [[./files/DOX/[2023 Wang] Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering.pdf|Layout and Task Aware Instruction Prompt for Zero-shot Document Image Question Answering]]
`2023 Wang` | [[./files/DOX/[2023 Wang] VRDU_A Benchmark for Visually-rich Document Understanding.pdf|VRDU: A Benchmark for Visually-rich Document Understanding]]
`2023 Yu` | [[./files/DOX/[2023 @emnlp Yu] DocumentNet_Bridging the Data Gap in Document Pre-Training.pdf|DocumentNet: Bridging the Data Gap in Document Pre-Training]] | #paper/emnlp
`2022 Pfitzmann` | [[./files/DOX/[2022 @ibm Pfitzmann] DocLayNet_A Large Human-Annotated Dataset for Document-Layout Analysis.pdf|DocLayNet: A Large Human-Annotated Dataset for Document-Layout Analysis]] | #paper/ibm
`2022 Wang` | [[./files/DOX/[2022 @acl Wang] LiLT_A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding.pdf|LiLT: A Simple yet Effective Language-Independent Layout Transformer for Structured Document Understanding]] | #paper/acl
`2021 Li` | [[./files/DOX/[2021 @microsoft Li] TrOCR_Transformer-based Optical Character Recognition with Pre-trained Models.pdf|TrOCR: Transformer-based Optical Character Recognition with Pre-trained Models]] | #paper/microsoft
`2020 Li` | [[./files/DOX/[2020 Li] A Survey on Deep Learning for Named Entity Recognition.pdf|A Survey on Deep Learning for Named Entity Recognition]]
`2020 Reisswig` | [[./files/DOX/[2020 @sap Reisswig] Chargrid-OCR_End-to-end Trainable Optical Character Recognition for Printed Documents using Instance Segmentation.pdf|Chargrid-OCR: End-to-end Trainable Optical Character Recognition for Printed Documents using Instance Segmentation]] | #paper/sap
`2019 Xu` | [[./files/DOX/[2019 @microsoft Xu] LayoutLM_Pre-training of Text and Layout for Document Image Understanding.pdf|LayoutLM: Pre-training of Text and Layout for Document Image Understanding]] | #paper/microsoft
`2018 Katti` | [[./files/DOX/[2018 @sap Katti] Chargrid_Towards Understanding 2D Documents.pdf|Chargrid: Towards Understanding 2D Documents]] | #paper/sap
%%AUTOGENERATED_DOX%%

## NLP

%%AUTOGENERATED_NLP%%
`2025 Casper` | [[./files/NLP/[2025 @agent Casper] The AI Agent Index.pdf|The AI Agent Index]] | #paper/agent
`2025 Cetin` | [[./files/NLP/[2025 Cetin] An Evolved Universal Transformer Memory.pdf|An Evolved Universal Transformer Memory]]
`2025 Chu` | [[./files/NLP/[2025 Chu] SFT Memorizes, RL Generalizes_A Comparative Study of Foundation Model Post-training.pdf|SFT Memorizes, RL Generalizes: A Comparative Study of Foundation Model Post-training]]
`2025 DeepSeek-AI` | [[./files/NLP/[2025 @deepseek DeepSeek-AI] DeepSeek_R1.pdf|DeepSeek: R1]] | #paper/deepseek
`2025 Gemini` | [[./files/NLP/[2025 @google @gemini Gemini] Gemini 2.5_Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities.pdf|Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities]] | #paper/google #paper/gemini
`2025 Golovneva` | [[./files/NLP/[2025 @meta Golovneva] Multi-Token Attention.pdf|Multi-Token Attention]] | #paper/meta
`2025 Han` | [[./files/NLP/[2025 @meta Han] Reinforcement Learning from User Feedback.pdf|Reinforcement Learning from User Feedback]] | #paper/meta
`2025 Ke` | [[./files/NLP/[2025 @salesforce @reasoning @agent Ke] A Survey of Frontiers in LLM Reasoning_Inference Scaling, Learning to Reason, and Agentic Systems.pdf|A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems]] | #paper/salesforce #paper/reasoning #paper/agent
`2025 Li` | [[./files/NLP/[2025 Li] From System 1 to System 2_A Survey of Reasoning Large Language Models.pdf|From System 1 to System 2: A Survey of Reasoning Large Language Models]]
`2025 Luo` | [[./files/NLP/[2025 @agent Luo] Large Language Model Agent_A Survey on Methodology, Applications and Challenges.pdf|Large Language Model Agent: A Survey on Methodology, Applications and Challenges]] | #paper/agent
`2025 Muennighoff` | [[./files/NLP/[2025 @iclr Muennighoff] OLMoE_Open Mixture-of-Experts Language Models.pdf|OLMoE: Open Mixture-of-Experts Language Models]] | #paper/iclr
`2025 OpenAI` | [[./files/NLP/[2025 @openai OpenAI] A Practical Guide to Building Agents.pdf|A Practical Guide to Building Agents]] | #paper/openai
`2025 Rawat` | [[./files/NLP/[2025 @agent Rawat] Pre-Act_Multi-Step Planning and Reasoning Improves Acting in LLM Agents.pdf|Pre-Act: Multi-Step Planning and Reasoning Improves Acting in LLM Agents]] | #paper/agent
`2025 Silver` | [[./files/NLP/[2025 @blog Silver] Welcome to the Era of Experience.pdf|Welcome to the Era of Experience]] | #paper/blog
`2025 Weng` | [[./files/NLP/[2025 @blog Weng] Why We Think.pdf|Why We Think]] | #paper/blog
`2025 Wu` | [[./files/NLP/[2025 Wu] CollabLLM_From Passive Responders to Active Collaborators.pdf|CollabLLM: From Passive Responders to Active Collaborators]]
`2025 Yehudai` | [[./files/NLP/[2025 @agent Yehudai] Survey on Evaluation of LLM-based Agents.pdf|Survey on Evaluation of LLM-based Agents]] | #paper/agent
`2025 Zhao` | [[./files/NLP/[2025 Zhao] Absolute Zero_Reinforced Self-play Reasoning with Zero Data.pdf|Absolute Zero: Reinforced Self-play Reasoning with Zero Data]]
`2025 Zhu` | [[./files/NLP/[2025 @agent Zhu] MultiAgentBench_Evaluating the Collaboration and Competition of LLM agents.pdf|MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents]] | #paper/agent
`2024 @alibaba` | [[./files/NLP/[2024 @acl @alibaba] On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models.pdf|On the Role of Long-tail Knowledge in Retrieval Augmented Large Language Models]] | #paper/acl #paper/alibaba
`2024 Anthropic` | [[./files/NLP/[2024 @anthropic @agent Anthropic] Building Effective Agents.pdf|Building Effective Agents]] | #paper/anthropic #paper/agent
`2024 Asthana` | [[./files/NLP/[2024 @ibm Asthana] Enterprise Benchmarks for Large Language Model Evaluation.pdf|Enterprise Benchmarks for Large Language Model Evaluation]] | #paper/ibm
`2024 Chen` | [[./files/NLP/[2024 @aaai Chen] Benchmarking Large Language Models in Retrieval-Augmented Generation.pdf|Benchmarking Large Language Models in Retrieval-Augmented Generation]] | #paper/aaai
`2024 Chen` | [[./files/NLP/[2024 @pretrain-data Chen] Aioli_A Unified Optimization Framework for Language Model Data Mixing.pdf|Aioli: A Unified Optimization Framework for Language Model Data Mixing]] | #paper/pretrain-data
`2024 Chen` | [[./files/NLP/[2024 Chen] Octopus v2_On-device language model for super agent.pdf|Octopus v2: On-device language model for super agent]]
`2024 Doan` | [[./files/NLP/[2024 Doan] Vintern-1B_An Efficient Multimodal Large Language Model for Vietnamese.pdf|Vintern-1B: An Efficient Multimodal Large Language Model for Vietnamese]]
`2024 Du` | [[./files/NLP/[2024 Du] Understanding Emergent Abilities of Language Models from the Loss Perspective.pdf|Understanding Emergent Abilities of Language Models from the Loss Perspective]]
`2024 Durante` | [[./files/NLP/[2024 @agent Durante] Agent AI_Surveying the Horizons of Multimodal Interaction.pdf|Agent AI: Surveying the Horizons of Multimodal Interaction]] | #paper/agent
`2024 Edge` | [[./files/NLP/[2024 Edge] From Local to Global_A Graph RAG Approach to Query-Focused Summarization.pdf|From Local to Global: A Graph RAG Approach to Query-Focused Summarization]]
`2024 Engstrom` | [[./files/NLP/[2024 @pretrain-data Engstrom] DsDm_Model-Aware Dataset Selection with Datamodels.pdf|DsDm: Model-Aware Dataset Selection with Datamodels]] | #paper/pretrain-data
`2024 Fan` | [[./files/NLP/[2024 Fan] A Survey on RAG Meeting LLMs_Towards Retrieval-Augmented Large Language Models.pdf|A Survey on RAG Meeting LLMs: Towards Retrieval-Augmented Large Language Models]]
`2024 Fourney` | [[./files/NLP/[2024 @agent-talk Fourney] Magentic-One_A Generalist Multi-Agent System for Solving Complex Tasks.pdf|Magentic-One: A Generalist Multi-Agent System for Solving Complex Tasks]] | #paper/agent-talk
`2024 Gao` | [[./files/NLP/[2024 @preference-learning Gao] Towards a Unified View of Preference Learning for Large Language Models_A Survey.pdf|Towards a Unified View of Preference Learning for Large Language Models: A Survey]] | #paper/preference-learning
`2024 Gao` | [[./files/NLP/[2024 Gao] Higher Layers Need More LoRA Experts.pdf|Higher Layers Need More LoRA Experts]]
`2024 GeminiTeam` | [[./files/NLP/[2024 @google @gemini GeminiTeam] Gemini 1.5_Unlocking multimodal understanding across millions of tokens of context.pdf|Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context]] | #paper/google #paper/gemini
`2024 Guo` | [[./files/NLP/[2024 @agent Guo] Large Language Model based Multi-Agents_A Survey of Progress and Challenges.pdf|Large Language Model based Multi-Agents: A Survey of Progress and Challenges]] | #paper/agent
`2024 Hao` | [[./files/NLP/[2024 @meta Hao] Training Large Language Models to Reason in a Continuous Latent Space.pdf|Training Large Language Models to Reason in a Continuous Latent Space]] | #paper/meta
`2024 He` | [[./files/NLP/[2024 He] Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning.pdf|Zero-Shot Cross-Lingual Document-Level Event Causality Identification with Heterogeneous Graph Contrastive Transfer Learning]]
`2024 Hewitt` | [[./files/NLP/[2024 Hewitt] Instruction Following without Instruction Tuning.pdf|Instruction Following without Instruction Tuning]]
`2024 Hsieh` | [[./files/NLP/[2024 @nvidia Hsieh] RULER_What's the Real Context Size of Your Long-Context Language Models.pdf|RULER: What's the Real Context Size of Your Long-Context Language Models]] | #paper/nvidia
`2024 Ji` | [[./files/NLP/[2024 Ji] Aligner_Achieving Efficient Alignment through Weak-to-Strong Correction.pdf|Aligner: Achieving Efficient Alignment through Weak-to-Strong Correction]]
`2024 Jiang` | [[./files/NLP/[2024 @pretrain-data Jiang] Adaptive Data Optimization_Dynamic Sample Selection with Scaling Laws.pdf|Adaptive Data Optimization: Dynamic Sample Selection with Scaling Laws]] | #paper/pretrain-data
`2024 Jimenez` | [[./files/NLP/[2024 @iclr Jimenez] SWE-bench_Can Language Models Resolve Real-World GitHub Issues?.pdf|SWE-bench: Can Language Models Resolve Real-World GitHub Issues?]] | #paper/iclr
`2024 Laurencon` | [[./files/NLP/[2024 Laurencon] Building and better understanding vision-language models_insights and future directions.pdf|Building and better understanding vision-language models: insights and future directions]]
`2024 Lee` | [[./files/NLP/[2024 Lee] Quantifying Positional Biases in Text Embedding Models.pdf|Quantifying Positional Biases in Text Embedding Models]]
`2024 Lesci` | [[./files/NLP/[2024 Lesci] Causal Estimation of Memorisation Profiles.pdf|Causal Estimation of Memorisation Profiles]]
`2024 Li` | [[./files/NLP/[2024 @reflection-tuning Li] Selective Reflection-Tuning_Student-Selected Data Recycling for LLM Instruction-Tuning.pdf|Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning]] | #paper/reflection-tuning
`2024 Li` | [[./files/NLP/[2024 Li] DataComp-LM_In search of the next generation of training sets for language models.pdf|DataComp-LM: In search of the next generation of training sets for language models]]
`2024 Liao` | [[./files/NLP/[2024 Liao] TPO_Aligning Large Language Models with Multi-branch & Multi-step Preference Trees.pdf|TPO: Aligning Large Language Models with Multi-branch & Multi-step Preference Trees]]
`2024 Lin` | [[./files/NLP/[2024 @neurips @microsoft Lin] RHO-1_Not All Tokens Are What You Need.pdf|RHO-1: Not All Tokens Are What You Need]] | #paper/neurips #paper/microsoft
`2024 Liu` | [[./files/NLP/[2024 @agent-talk Liu] Large Language Model-Based Agents for Software Engineering_A Survey.pdf|Large Language Model-Based Agents for Software Engineering: A Survey]] | #paper/agent-talk
`2024 Liu` | [[./files/NLP/[2024 @alibaba Liu] CoFE-RAG_A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity.pdf|CoFE-RAG: A Comprehensive Full-chain Evaluation Framework for Retrieval-Augmented Generation with Enhanced Data Diversity]] | #paper/alibaba
`2024 Liu` | [[./files/NLP/[2024 Liu] Inference-Time Language Model Alignment via Integrated Value Guidance.pdf|Inference-Time Language Model Alignment via Integrated Value Guidance]]
`2024 Luong` | [[./files/NLP/[2024 @bytedance Luong] REFT_Reasoning with REinforced Fine-Tuning.pdf.pdf|REFT: Reasoning with REinforced Fine-Tuning]] | #paper/bytedance
`2024 McKinzie` | [[./files/NLP/[2024 @apple McKinzie] MM1_Methods, Analysis & Insights from Multimodal LLM Pre-training.pdf|MM1: Methods, Analysis & Insights from Multimodal LLM Pre-training]] | #paper/apple
`2024 Munkhdalai` | [[./files/NLP/[2024 @google Munkhdalai] Leave No Context Behind_Efficient Infinite Context Transformers with Infini-attention.pdf|Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention]] | #paper/google
`2024 Ni` | [[./files/NLP/[2024 Ni] DIRAS_Efficient LLM Annotation of Document Relevance for Retrieval Augmented Generation.pdf|DIRAS: Efficient LLM Annotation of Document Relevance for Retrieval Augmented Generation]]
`2024 Ning` | [[./files/NLP/[2024 Ning] User-LLM_Efficient LLM Contextualization with User Embeddings.pdf|User-LLM: Efficient LLM Contextualization with User Embeddings]]
`2024 Nvidia` | [[./files/NLP/[2024 @nvidia Nvidia] Nemotron-4 340B Technical Report.pdf|Nemotron-4 340B Technical Report]] | #paper/nvidia
`2024 Parthasarathy` | [[./files/NLP/[2024 @finetuning Parthasarathy] The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs_An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities.pdf|The Ultimate Guide to Fine-Tuning LLMs from Basics to Breakthroughs: An Exhaustive Review of Technologies, Research, Best Practices, Applied Research Challenges and Opportunities]] | #paper/finetuning
`2024 Peng` | [[./files/NLP/[2024 Peng] Graph Retrieval-Augmented Generation_A Survey.pdf|Graph Retrieval-Augmented Generation: A Survey]]
`2024 Petridis` | [[./files/NLP/[2024 @google Petridis] ConstitutionalExperts_Training a Mixture of Principle-based Prompts.pdf|ConstitutionalExperts: Training a Mixture of Principle-based Prompts]] | #paper/google
`2024 Qi` | [[./files/NLP/[2024 @microsoft Qi] Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers.pdf|Mutual Reasoning Makes Smaller LLMs Stronger Problem-Solvers]] | #paper/microsoft
`2024 Raad` | [[./files/NLP/[2024 @agent-talk Raad] Scaling Instructable Agents Across Many Simulated Worlds.pdf|Scaling Instructable Agents Across Many Simulated Worlds]] | #paper/agent-talk
`2024 Sarthi` | [[./files/NLP/[2024 Sarthi] RAPTOR_Recursive Abstractive Processing for Tree-Organized Retrieval.pdf|RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval]]
`2024 Sprague` | [[./files/NLP/[2024 Sprague] To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning.pdf|To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning]]
`2024 Sun` | [[./files/NLP/[2024 @iclr Sun] Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models.pdf|Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in Large Language Models]] | #paper/iclr
`2024 Sun` | [[./files/NLP/[2024 @microsoft Sun] You Only Cache Once_Decoder-Decoder Architectures for Language Models.pdf|You Only Cache Once: Decoder-Decoder Architectures for Language Models]] | #paper/microsoft
`2024 Sun` | [[./files/NLP/[2024 Sun] Learning to (Learn at Test Time)_RNNs with Expressive Hidden States.pdf|Learning to (Learn at Test Time): RNNs with Expressive Hidden States]]
`2024 Tam` | [[./files/NLP/[2024 Tam] Let Me Speak Freely. A Study on the Impact of Format Restrictions on Performance of Large Language Model.pdf|Let Me Speak Freely. A Study on the Impact of Format Restrictions on Performance of Large Language Model]]
`2024 Tong` | [[./files/NLP/[2024 @neurips Tong] Cambrian-1_A Fully Open, Vision-Centric Exploration of Multimodal LLMs.pdf|Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs]] | #paper/neurips
`2024 Ustun` | [[./files/NLP/[2024 @cohere Ustun] Aya Model_An Instruction Finetuned Open-Access Multilingual Language Model.pdf|Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model]] | #paper/cohere
`2024 Wallace` | [[./files/NLP/[2024 Wallace] The Instruction Hierarchy_Training LLMs to Prioritize Privileged Instructions.pdf|The Instruction Hierarchy: Training LLMs to Prioritize Privileged Instructions]]
`2024 Wang` | [[./files/NLP/[2024 @agent-talk Wang] Chain-of-Thought Reasoning Without Prompting.pdf|Chain-of-Thought Reasoning Without Prompting]] | #paper/agent-talk
`2024 Wang` | [[./files/NLP/[2024 @emnlp Wang] Searching for Best Practices in Retrieval-Augmented Generation.pdf|Searching for Best Practices in Retrieval-Augmented Generation]] | #paper/emnlp
`2024 Wang` | [[./files/NLP/[2024 Wang] InferAligner_Inference-Time Alignment for Harmlessness through Cross-Model Guidance.pdf|InferAligner: Inference-Time Alignment for Harmlessness through Cross-Model Guidance]]
`2024 Wang` | [[./files/NLP/[2024 Wang] One Prompt is not Enough_Automated Construction of a Mixture-of-Expert Prompts.pdf|One Prompt is not Enough: Automated Construction of a Mixture-of-Expert Prompts]]
`2024 Wang` | [[./files/NLP/[2024 Wang] SeaEval for Multilingual Foundation Models_From Cross-Lingual Alignment to Cultural Reasoning.pdf|SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning]]
`2024 Wu` | [[./files/NLP/[2024 @agent-talk Wu] ReFT_Representation Finetuning for Language Models.pdf|ReFT: Representation Finetuning for Language Models]] | #paper/agent-talk
`2024 Ye` | [[./files/NLP/[2024 @meta @reflection-tuning Ye] Physics of Language Models_Part 2.2, How to Learn From Mistakes on Grade-School Math Problems.pdf|Physics of Language Models: Part 2.2, How to Learn From Mistakes on Grade-School Math Problems]] | #paper/meta #paper/reflection-tuning
`2024 Yu` | [[./files/NLP/[2024 @pretrain-data Yu] MATES_Model-Aware Data Selection for Efficient Pretraining with Data Influence Models.pdf|MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models]] | #paper/pretrain-data
`2024 Zhang` | [[./files/NLP/[2024 @agent Zhang] A Survey on the Memory Mechanism of Large Language Model based Agents.pdf|A Survey on the Memory Mechanism of Large Language Model based Agents]] | #paper/agent
`2024 Zhang` | [[./files/NLP/[2024 @pretrain-data Zhang] Harnessing Diversity for Important Data Selection in Pretraining Large Language Models.pdf|Harnessing Diversity for Important Data Selection in Pretraining Large Language Models]] | #paper/pretrain-data
`2024 Zhang` | [[./files/NLP/[2024 Zhang] In-Context Principle Learning from Mistakes.pdf|In-Context Principle Learning from Mistakes]]
`2024 Zhang` | [[./files/NLP/[2024 Zhang] RAFT_Adapting Language Model to Domain Specific RAG.pdf|RAFT: Adapting Language Model to Domain Specific RAG]]
`2024 Zhang` | [[./files/NLP/[2024 Zhang] Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an Entity-Centric Perspective.pdf|Rethinking the Evaluation of Pre-trained Text-and-Layout Models from an Entity-Centric Perspective]]
`2024 Zhao` | [[./files/NLP/[2024 @emnlp @agent Zhao] LongAgent_Scaling Language Models to 128k Context through Multi-Agent Collaboration.pdf|LongAgent: Scaling Language Models to 128k Context through Multi-Agent Collaboration]] | #paper/emnlp #paper/agent
`2024 Zhao` | [[./files/NLP/[2024 Zhao] A Survey of Large Language Models.pdf|A Survey of Large Language Models]]
`2024 Zhou` | [[./files/NLP/[2024 @pretrain-data Zhou] Programming Every Example_Lifting Pre-training Data Quality Like Experts at Scale.pdf|Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale]] | #paper/pretrain-data
`2024 Zhuge` | [[./files/NLP/[2024 @agent-talk Zhuge] Agent-as-a-Judge_Evaluate Agents with Agents.pdf|Agent-as-a-Judge: Evaluate Agents with Agents]] | #paper/agent-talk
`2023 Bommasani` | [[./files/NLP/[2023 Bommasani] The Foundation Model Transparency Index.pdf|The Foundation Model Transparency Index]]
`2023 Cai` | [[./files/NLP/[2023 @google Cai] Large Language Models as Tool Makers.pdf|Large Language Models as Tool Makers]] | #paper/google
`2023 Chang` | [[./files/NLP/[2023 Chang] A Survey on Evaluation of Large Language Models.pdf|A Survey on Evaluation of Large Language Models]]
`2023 Chang` | [[./files/NLP/[2023 Chang] Learning to Generate Better Than Your LLM.pdf|Learning to Generate Better Than Your LLM]]
`2023 Chen` | [[./files/NLP/[2023 Chen] ChatGPT's One-year Anniversary_Are Open-Source Large Language Models Catching up.pdf|ChatGPT's One-year Anniversary: Are Open-Source Large Language Models Catching up]]
`2023 Chen` | [[./files/NLP/[2023 Chen] Understanding Retrieval Augmentation for Long-Form Question Answering.pdf|Understanding Retrieval Augmentation for Long-Form Question Answering]]
`2023 Dankers` | [[./files/NLP/[2023 @emnlp Dankers] Memorisation Cartography_Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation.pdf|Memorisation Cartography: Mapping out the Memorisation-Generalisation Continuum in Neural Machine Translation]] | #paper/emnlp
`2023 Gao` | [[./files/NLP/[2023 Gao] Retrieval-Augmented Generation for Large Language Models_A Survey.pdf|Retrieval-Augmented Generation for Large Language Models: A Survey]]
`2023 Google` | [[./files/NLP/[2023 @google Google] Gemini_A Family of Highly Capable Multimodal Models.pdf|Gemini: A Family of Highly Capable Multimodal Models]] | #paper/google
`2023 Goyal` | [[./files/NLP/[2023 Goyal] News Summarization and Evaluation in the Era of GPT-3.pdf|News Summarization and Evaluation in the Era of GPT-3]]
`2023 He` | [[./files/NLP/[2023 He] AnnoLLM_Making Large Language Models to Be Better Crowdsourced Annotators.pdf|AnnoLLM: Making Large Language Models to Be Better Crowdsourced Annotators]]
`2023 He` | [[./files/NLP/[2023 He] Simplifying Transformer Blocks.pdf|Simplifying Transformer Blocks]]
`2023 Huang` | [[./files/NLP/[2023 Huang] OPERA_Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation.pdf|OPERA: Alleviating Hallucination in Multi-Modal Large Language Models via Over-Trust Penalty and Retrospection-Allocation]]
`2023 Jacovi` | [[./files/NLP/[2023 @emnlp Jacovi] Stop Uploading Test Data in Plain Text_Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks.pdf|Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks]] | #paper/emnlp
`2023 Jiang` | [[./files/NLP/[2023 Jiang] Active Retrieval Augmented Generation.pdf|Active Retrieval Augmented Generation]]
`2023 Kaddour` | [[./files/NLP/[2023 Kaddour] Challenges and Applications of Large Language Models.pdf|Challenges and Applications of Large Language Models]]
`2023 Kwon` | [[./files/NLP/[2023 Kwon] Efficient Memory Management for Large Language Model Serving with PagedAttention.pdf|Efficient Memory Management for Large Language Model Serving with PagedAttention]]
`2023 Lee` | [[./files/NLP/[2023 @google @rlhf Lee] RLAIF_Scaling Reinforcement Learning from Human Feedback with AI Feedback.pdf|RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback]] | #paper/google #paper/rlhf
`2023 Li` | [[./files/NLP/[2023 Li] CoAnnotating_Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation.pdf|CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation]]
`2023 Liu` | [[./files/NLP/[2023 @emnlp Liu] G-EVAL_NLG Evaluation using GPT-4 with Better Human Alignment.pdf|G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment]] | #paper/emnlp
`2023 Liu` | [[./files/NLP/[2023 Liu] Pre-train, Prompt, and Predict_A Systematic Survey of Prompting Methods in Natural Language Processing.pdf|Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing]]
`2023 Long` | [[./files/NLP/[2023 Long] Adapt in Contexts_Retrieval-Augmented Domain Adaptation via In-Context Learning.pdf|Adapt in Contexts: Retrieval-Augmented Domain Adaptation via In-Context Learning]]
`2023 Mistral` | [[./files/NLP/[2023 @mistral Mistral] Mistral 7B.pdf|Mistral 7B]] | #paper/mistral
`2023 OpenAI` | [[./files/NLP/[2023 @openai @gpt4 OpenAI] GPT-4 Technical Report.pdf|GPT-4 Technical Report]] | #paper/openai #paper/gpt4
`2023 Patil` | [[./files/NLP/[2023 Patil] Gorilla_Large Language Model Connected with Massive APIs.pdf|Gorilla: Large Language Model Connected with Massive APIs]]
`2023 Rafailov` | [[./files/NLP/[2023 @dpo Rafailov] Direct Preference Optimization_Your Language Model is Secretly a Reward Model.pdf|Direct Preference Optimization: Your Language Model is Secretly a Reward Model]] | #paper/dpo
`2023 Ram` | [[./files/NLP/[2023 Ram] In-Context Retrieval-Augmented Language Models.pdf|In-Context Retrieval-Augmented Language Models]]
`2023 Sainz` | [[./files/NLP/[2023 Sainz] GoLLIE_Annotation Guidelines improve Zero-Shot Information-Extraction.pdf|GoLLIE: Annotation Guidelines improve Zero-Shot Information-Extraction]]
`2023 Schaeffer` | [[./files/NLP/[2023 Schaeffer] Are Emergent Abilities of Large Language Models a Mirage.pdf|Are Emergent Abilities of Large Language Models a Mirage]]
`2023 Schick` | [[./files/NLP/[2023 @meta Schick] Toolformer_Language Models Can Teach Themselves to Use Tools.pdf|Toolformer: Language Models Can Teach Themselves to Use Tools]] | #paper/meta
`2023 Shaikh` | [[./files/NLP/[2023 Shaikh] On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning.pdf|On Second Thought, Let's Not Think Step by Step! Bias and Toxicity in Zero-Shot Reasoning]]
`2023 Sheng` | [[./files/NLP/[2023 Sheng] S-LoRA_Serving Thousands of Concurrent LoRA Adapters.pdf|S-LoRA: Serving Thousands of Concurrent LoRA Adapters]]
`2023 Shi` | [[./files/NLP/[2023 Shi] In-Context Pretraining_Language Modeling Beyond Document Boundaries.pdf|In-Context Pretraining: Language Modeling Beyond Document Boundaries]]
`2023 Shinn` | [[./files/NLP/[2023 @agent-talk Shinn] Reflexion_Language Agents with Verbal Reinforcement Learning.pdf|Reflexion: Language Agents with Verbal Reinforcement Learning]] | #paper/agent-talk
`2023 Siriwardhana` | [[./files/NLP/[2023 Siriwardhana] Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering.pdf|Improving the Domain Adaptation of Retrieval Augmented Generation (RAG) Models for Open Domain Question Answering]]
`2023 Sun` | [[./files/NLP/[2023 @microsoft Sun] Retentive Network_A Successor to Transformer for Large Language Models.pdf|Retentive Network: A Successor to Transformer for Large Language Models]] | #paper/microsoft
`2023 Tirumala` | [[./files/NLP/[2023 @neurips @meta Tirumala] D4_Improving LLM Pretraining via Document De-Duplication and Diversification.pdf|D4: Improving LLM Pretraining via Document De-Duplication and Diversification]] | #paper/neurips #paper/meta
`2023 Touvron` | [[./files/NLP/[2023 @meta @lama Touvron] LLaMA_Open and Efficient Foundation Language Models.pdf|LLaMA: Open and Efficient Foundation Language Models]] | #paper/meta #paper/lama
`2023 Touvron` | [[./files/NLP/[2023 @meta @llama2 Touvron] LLaMA 2_Open Foundation and Fine-Tuned Chat Models.pdf|LLaMA 2: Open Foundation and Fine-Tuned Chat Models]] | #paper/meta #paper/llama2
`2023 Wang` | [[./files/NLP/[2023 @agent Wang] A Survey on Large Language Model based Autonomous Agents.pdf|A Survey on Large Language Model based Autonomous Agents]] | #paper/agent
`2023 Wang` | [[./files/NLP/[2023 @emnlp Wang] Label Words are Anchors_An Information Flow Perspective for Understanding In-Context Learning.pdf|Label Words are Anchors: An Information Flow Perspective for Understanding In-Context Learning]] | #paper/emnlp
`2023 Wang` | [[./files/NLP/[2023 @neurips Wang] DORIS-MAE_Scientific Document Retrieval using Multi-level Aspect-based Queries.pdf|DORIS-MAE: Scientific Document Retrieval using Multi-level Aspect-based Queries]] | #paper/neurips
`2023 Weng` | [[./files/NLP/[2023 @agent @blog Weng] LLM Powered Autonomous Agents.pdf|LLM Powered Autonomous Agents]] | #paper/agent #paper/blog
`2023 Xiong` | [[./files/NLP/[2023 @meta Xiong] Effective Long-Context Scaling of Foundation Models.pdf|Effective Long-Context Scaling of Foundation Models]] | #paper/meta
`2023 Xu` | [[./files/NLP/[2023 Xu] Retrieval Meets Long Context Large Language Models.pdf|Retrieval Meets Long Context Large Language Models]]
`2023 Yang` | [[./files/NLP/[2023 @google Yang] Large Language Models as Optimizers.pdf|Large Language Models as Optimizers]] | #paper/google
`2023 Yang` | [[./files/NLP/[2023 @neurips Yang] ResMem_Learn what you can and memorize the rest.pdf|ResMem: Learn what you can and memorize the rest]] | #paper/neurips
`2023 Yao` | [[./files/NLP/[2023 Yao] Tree of Thoughts_Deliberate Problem Solving with Large Language Models.pdf|Tree of Thoughts: Deliberate Problem Solving with Large Language Models]]
`2023 Yin` | [[./files/NLP/[2023 Yin] A Survey on Multimodal Large Language Models.pdf|A Survey on Multimodal Large Language Models]]
`2023 Zhao` | [[./files/NLP/[2023 Zhao] A Survey of Large Language Models.pdf|A Survey of Large Language Models]]
`2023 Zhou` | [[./files/NLP/[2023 @iclr Zhou] Large Language Models Are Human-Level Prompt Engineers.pdf|Large Language Models Are Human-Level Prompt Engineers]] | #paper/iclr
`2022 Bommasani` | [[./files/NLP/[2022 @milestone Bommasani] On the Opportunities and Risks of Foundation Models.pdf|On the Opportunities and Risks of Foundation Models]] | #paper/milestone
`2022 Borgeaud` | [[./files/NLP/[2022 @deepmind Borgeaud] Improving language models by retrieving from trillions of tokens.pdf|Improving language models by retrieving from trillions of tokens]] | #paper/deepmind
`2022 Borgeaud` | [[./files/NLP/[2022 @icml Borgeaud] Improving language models by retrieving from trillions of tokens.pdf|Improving language models by retrieving from trillions of tokens]] | #paper/icml
`2022 Chowdhery` | [[./files/NLP/[2022 @google Chowdhery] PaLM_Scaling Language Modeling with Pathways.pdf|PaLM: Scaling Language Modeling with Pathways]] | #paper/google
`2022 Hernandez` | [[./files/NLP/[2022 @anthropic Hernandez] Scaling Laws and Interpretability of Learning from Repeated Data.pdf|Scaling Laws and Interpretability of Learning from Repeated Data]] | #paper/anthropic
`2022 Izacard` | [[./files/NLP/[2022 Izacard] Atlas_Few-shot Learning with Retrieval Augmented Language Models.pdf|Atlas: Few-shot Learning with Retrieval Augmented Language Models]]
`2022 Liu` | [[./files/NLP/[2022 @finetuning Liu] P-Tuning v2_Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks.pdf|P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks]] | #paper/finetuning
`2022 Min` | [[./files/NLP/[2022 @emnlp Min] Rethinking the Role of Demonstrations_What Makes In-Context Learning Work.pdf|Rethinking the Role of Demonstrations: What Makes In-Context Learning Work]] | #paper/emnlp
`2022 Ouyang` | [[./files/NLP/[2022 @openai @rlhf Ouyang] Training language models to follow instructions with human feedback.pdf|Training language models to follow instructions with human feedback]] | #paper/openai #paper/rlhf
`2022 Wang` | [[./files/NLP/[2022 @microsoft Wang] Training Data is More Valuable than You Think_A Simple and Effective Method by Retrieving from Training Data.pdf|Training Data is More Valuable than You Think: A Simple and Effective Method by Retrieving from Training Data]] | #paper/microsoft
`2022 Wei` | [[./files/NLP/[2022 @google @prompt Wei] Chain-of-Thought Prompting Elicits Reasoning in Large Language Models.pdf|Chain-of-Thought Prompting Elicits Reasoning in Large Language Models]] | #paper/google #paper/prompt
`2021 Das` | [[./files/NLP/[2021 Das] Case-Based Reasoning for Natural Language Queries over Knowledge Bases.pdf|Case-Based Reasoning for Natural Language Queries over Knowledge Bases]]
`2021 Hu` | [[./files/NLP/[2021 @microsoft @finetuning Hu] LoRA_Low-Rank Adaptation of Large Language Models.pdf|LoRA: Low-Rank Adaptation of Large Language Models]] | #paper/microsoft #paper/finetuning
`2021 Huang` | [[./files/NLP/[2021 Huang] WhiteningBERT_An Easy Unsupervised Sentence Embedding Approach.pdf|WhiteningBERT: An Easy Unsupervised Sentence Embedding Approach]]
`2021 Li` | [[./files/NLP/[2021 @naacl Li] Document-Level Event Argument Extraction by Conditional Generation.pdf|Document-Level Event Argument Extraction by Conditional Generation]] | #paper/naacl
`2021 Liu` | [[./files/NLP/[2021 Liu] Pre-train, Prompt, and Predict_A Systematic Survey of Prompting Methods in Natural Language Processing.pdf|Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing]]
`2021 Mao` | [[./files/NLP/[2021 @microsoft Mao] Generation-Augmented Retrieval for Open-Domain Question Answering.pdf|Generation-Augmented Retrieval for Open-Domain Question Answering]] | #paper/microsoft
`2021 Narayanan` | [[./files/NLP/[2021 @nvidia @distributed Narayanan] Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM.pdf|Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM]] | #paper/nvidia #paper/distributed
`2020 Brown` | [[./files/NLP/[2020 @openai @gpt3 Brown] Language Models are Few-Shot Learners.pdf|Language Models are Few-Shot Learners]] | #paper/openai #paper/gpt3
`2020 Gururangan` | [[./files/NLP/[2020 @acl Gururangan] Don't Stop Pretraining_Adapt Language Models to Domains and Tasks.pdf|Don't Stop Pretraining: Adapt Language Models to Domains and Tasks]] | #paper/acl
`2020 Guu` | [[./files/NLP/[2020 @google Guu] REALM_Retrieval-Augmented Language Model Pre-Training.pdf|REALM: Retrieval-Augmented Language Model Pre-Training]] | #paper/google
`2020 Kaplan` | [[./files/NLP/[2020 @openai @milestone Kaplan] Scaling Laws for Neural Language Models.pdf|Scaling Laws for Neural Language Models]] | #paper/openai #paper/milestone
`2020 Khandelwal` | [[./files/NLP/[2020 @iclr Khandelwal] Generalization through Memorization_Nearest Neighbor Language Models.pdf|Generalization through Memorization: Nearest Neighbor Language Models]] | #paper/iclr
`2020 Lewis` | [[./files/NLP/[2020 @facebook Lewis] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.pdf|Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks]] | #paper/facebook
`2019 Dai` | [[./files/NLP/[2019 @acl Dai] Transformer-XL_Attentive Language Models Beyond a Fixed-Length Context.pdf|Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context]] | #paper/acl
`2019 Liu` | [[./files/NLP/[2019 @meta Liu] RoBERTa_A Robustly Optimized BERT Pretraining Approach.pdf|RoBERTa: A Robustly Optimized BERT Pretraining Approach]] | #paper/meta
`2019 Radford` | [[./files/NLP/[2019 @openai @gpt2 Radford] Language Models are Unsupervised Multitask Learners.pdf|Language Models are Unsupervised Multitask Learners]] | #paper/openai #paper/gpt2
`2019 Raffel` | [[./files/NLP/[2019 @google @t5 @milestone Raffel] Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.pdf|Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer]] | #paper/google #paper/t5 #paper/milestone
`2019 Wang` | [[./files/NLP/[2019 @iclr Wang] GLUE_A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding.pdf|GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding]] | #paper/iclr
`2019 Wang` | [[./files/NLP/[2019 @neurips Wang] SuperGLUE_A Stickier Benchmark for General-Purpose Language Understanding.pdf|SuperGLUE: A Stickier Benchmark for General-Purpose Language Understanding]] | #paper/neurips
`2019 Yang` | [[./files/NLP/[2019 @neurips Yang] XLNet_Generalized Autoregressive Pretraining for Language Understanding.pdf|XLNet: Generalized Autoregressive Pretraining for Language Understanding]] | #paper/neurips
`2019 Ziegler` | [[./files/NLP/[2019 @openai @rlhf Ziegler] Fine-Tuning Language Models from Human Preferences.pdf|Fine-Tuning Language Models from Human Preferences]] | #paper/openai #paper/rlhf
`2018 Devlin` | [[./files/NLP/[2018 @google @milestone Devlin] BERT_Pre-Training of Deep Bidirectional Transformers for Language Understanding.pdf|BERT: Pre-Training of Deep Bidirectional Transformers for Language Understanding]] | #paper/google #paper/milestone
`2018 Radford` | [[./files/NLP/[2018 @openai @gpt @milestone Radford] Improving Language Understanding by Generative Pre-Training.pdf|Improving Language Understanding by Generative Pre-Training]] | #paper/openai #paper/gpt #paper/milestone
`2017 Vaswani` | [[./files/NLP/[2017 @google @milestone Vaswani] Attention Is All You Need.pdf|Attention Is All You Need]] | #paper/google #paper/milestone
`2013 Mikolov` | [[./files/NLP/[2013 Mikolov] Distributed Representations of Words and Phrases and their Compositionality.pdf|Distributed Representations of Words and Phrases and their Compositionality]]
`2013 Mikolov` | [[./files/NLP/[2013 Mikolov] Efficient Estimation of Word Representations in Vector Space.pdf|Efficient Estimation of Word Representations in Vector Space]]
%%AUTOGENERATED_NLP%%

## Multimodal

%%AUTOGENERATED_MM%%
`2025 Arif` | [[./files/MM/[2025 @aaai Arif] HiRED_Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models.pdf|HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models]] | #paper/aaai
`2025 Chen` | [[./files/MM/[2025 @salesforce Chen] BLIP3-o_A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset.pdf|BLIP3-o: A Family of Fully Open Unified Multimodal Models-Architecture, Training and Dataset]] | #paper/salesforce
`2025 Feng` | [[./files/MM/[2025 @bytedance Feng] Dolphin_Document Image Parsing via Heterogeneous Anchor Prompting.pdf|Dolphin: Document Image Parsing via Heterogeneous Anchor Prompting]] | #paper/bytedance
`2025 Guo` | [[./files/MM/[2025 @bytedance Guo] Seed1.5-VL Technical Report.pdf|Seed1.5-VL Technical Report]] | #paper/bytedance
`2025 KimiTeam` | [[./files/MM/[2025 @kimi KimiTeam] Kimi-VL Technical Report.pdf|Kimi-VL Technical Report]] | #paper/kimi
`2025 Li` | [[./files/MM/[2025 @microsoft Li] Imagine while Reasoning in Space_Multimodal Visualization-of-Thought.pdf|Imagine while Reasoning in Space: Multimodal Visualization-of-Thought]] | #paper/microsoft
`2025 Lu` | [[./files/MM/[2025 Lu] InternVL-X_Advancing and Accelerating InternVL Series with Efficient Visual Token Compression.pdf|InternVL-X: Advancing and Accelerating InternVL Series with Efficient Visual Token Compression]]
`2025 Neo` | [[./files/MM/[2025 @iclr Neo] Towards Interpreting Visual Information Processing in Vision-Language Models.pdf|Towards Interpreting Visual Information Processing in Vision-Language Models]] | #paper/iclr
`2025 QwenTeam` | [[./files/MM/[2025 @qwen2-5-omni QwenTeam] Qwen2.5-Omni Technical Report.pdf|Qwen2.5-Omni Technical Report]] | #paper/qwen2-5-omni
`2025 QwenTeam` | [[./files/MM/[2025 @qwen2-5-vl QwenTeam] Qwen2.5-VL Technical Report.pdf|Qwen2.5-VL Technical Report]] | #paper/qwen2-5-vl
`2025 Rang` | [[./files/MM/[2025 @aaai Rang] Eve_Efficient Multimodal Vision Language Models with Elastic Visual Experts.pdf|Eve: Efficient Multimodal Vision Language Models with Elastic Visual Experts]] | #paper/aaai
`2025 Wang` | [[./files/MM/[2025 @bytedance Wang] Vision as LoRA.pdf|Vision as LoRA]] | #paper/bytedance
`2025 Wolf` | [[./files/MM/[2025 Wolf] CM1 - A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models.pdf|CM1 - A Dataset for Evaluating Few-Shot Information Extraction with Large Vision Language Models]]
`2025 Xu` | [[./files/MM/[2025 Xu] Visual Planning_Let's Think Only with Images.pdf|Visual Planning: Let's Think Only with Images]]
`2025 Yang` | [[./files/MM/[2025 @iclr Yang] SWE-Bench Multimodal_Do AI Systems Generalize to Visual Software Domains?.pdf|SWE-Bench Multimodal: Do AI Systems Generalize to Visual Software Domains?]] | #paper/iclr
`2025 Yang` | [[./files/MM/[2025 @microsoft Yang] Magma_A Foundation Model for Multimodal AI Agents.pdf|Magma: A Foundation Model for Multimodal AI Agents]] | #paper/microsoft
`2025 Zhu` | [[./files/MM/[2025 @internvl-3 Zhu] InternVL3_Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models.pdf|InternVL3: Exploring Advanced Training and Test-Time Recipes for Open-Source Multimodal Models]] | #paper/internvl-3
`2024 Bordes` | [[./files/MM/[2024 @meta Bordes] An Introduction to Vision-Language Modeling.pdf|An Introduction to Vision-Language Modeling]] | #paper/meta
`2024 Chen` | [[./files/MM/[2024 @internvl-1-5 Chen] How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites.pdf|How Far Are We to GPT-4V? Closing the Gap to Commercial Multimodal Models with Open-Source Suites]] | #paper/internvl-1-5
`2024 Chen` | [[./files/MM/[2024 @internvl-2-5 Chen] Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling.pdf|Expanding Performance Boundaries of Open-Source Multimodal Models with Model, Data, and Test-Time Scaling]] | #paper/internvl-2-5
`2024 Chen` | [[./files/MM/[2024 Chen] Next Token Prediction Towards Multimodal Intelligence_A Comprehensive Survey.pdf|Next Token Prediction Towards Multimodal Intelligence: A Comprehensive Survey]]
`2024 Cheng` | [[./files/MM/[2024 Cheng] YOLO-World_Real-Time Open-Vocabulary Object Detection.pdf|YOLO-World: Real-Time Open-Vocabulary Object Detection]]
`2024 Fuest` | [[./files/MM/[2024 Fuest] Diffusion Models and Representation Learning_A Survey.pdf|Diffusion Models and Representation Learning: A Survey]]
`2024 Gao` | [[./files/MM/[2024 @mini-internvl Gao] Mini-InternVL_A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance.pdf|Mini-InternVL: A Flexible-Transfer Pocket Multimodal Model with 5% Parameters and 90% Performance]] | #paper/mini-internvl
`2024 Gou` | [[./files/MM/[2024 Gou] Eyes Closed, Safety On_Protecting Multimodal LLMs via Image-to-Text Transformation.pdf|Eyes Closed, Safety On: Protecting Multimodal LLMs via Image-to-Text Transformation]]
`2024 Li` | [[./files/MM/[2024 Li] Multimodal Alignment and Fusion_A Survey.pdf|Multimodal Alignment and Fusion: A Survey]]
`2024 Lin` | [[./files/MM/[2024 Lin] MoE-LLaVA_Mixture of Experts for Large Vision-Language Models.pdf|MoE-LLaVA: Mixture of Experts for Large Vision-Language Models]]
`2024 Masry` | [[./files/MM/[2024 Masry] ChartInstruct_Instruction Tuning for Chart Comprehension and Reasoning.pdf|ChartInstruct: Instruction Tuning for Chart Comprehension and Reasoning]]
`2024 Wang` | [[./files/MM/[2024 @alibaba @qwen2-vl Wang] Qwen2-VL_Enhancing Vision-Language Models Perception of the World at Any Resolution.pdf|Qwen2-VL: Enhancing Vision-Language Models Perception of the World at Any Resolution]] | #paper/alibaba #paper/qwen2-vl
`2024 Wardle` | [[./files/MM/[2024 Wardle] Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks.pdf|Image First or Text First? Optimising the Sequencing of Modalities in Large Language Model Prompting and Reasoning Tasks]]
`2024 Yang` | [[./files/MM/[2024 Yang] Law of Vision Representation in MLLMs.pdf|Law of Vision Representation in MLLMs]]
`2024 Yu` | [[./files/MM/[2024 Yu] VisRAG_Vision-based Retrieval-augmented Generation on Multi-modality Documents.pdf|VisRAG: Vision-based Retrieval-augmented Generation on Multi-modality Documents]]
`2024 Zhou` | [[./files/MM/[2024 @meta Zhou] Transfusion_Predict the Next Token and Diffuse Images with One Multi-Modal Model.pdf|Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model]] | #paper/meta
`2024 Zong` | [[./files/MM/[2024 @mmlab Zong] MoVA_Adapting Mixture of Vision Experts to Multimodal Context.pdf|MoVA: Adapting Mixture of Vision Experts to Multimodal Context]] | #paper/mmlab
`2023 Bai` | [[./files/MM/[2023 @alibaba @qwen-vl Bai] Qwen-VL_A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond.pdf|Qwen-VL: A Versatile Vision-Language Model for Understanding, Localization, Text Reading, and Beyond]] | #paper/alibaba #paper/qwen-vl
`2023 Bai` | [[./files/MM/[2023 Bai] Sequential Modeling Enables Scalable Learning for Large Vision Models.pdf|Sequential Modeling Enables Scalable Learning for Large Vision Models]]
`2023 Li` | [[./files/MM/[2023 @cvpr Li] Monkey_Image Resolution and Text Label Are Important Things for Large Multi-modal Models.pdf|Monkey: Image Resolution and Text Label Are Important Things for Large Multi-modal Models]] | #paper/cvpr
`2023 Lin` | [[./files/MM/[2023 @neurips @microsoft Lin] LayoutPrompter_Awaken the Design Ability of Large Language Models.pdf|LayoutPrompter: Awaken the Design Ability of Large Language Models]] | #paper/neurips #paper/microsoft
`2023 Zhao` | [[./files/MM/[2023 @emnlp Zhao] Retrieving Multimodal Information for Augmented Generation_A Survey.pdf|Retrieving Multimodal Information for Augmented Generation: A Survey]] | #paper/emnlp
`2022 Peebles` | [[./files/MM/[2022 @dit @sora Peebles] Scalable Diffusion Models with Transformers.pdf|Scalable Diffusion Models with Transformers]] | #paper/dit #paper/sora
`2021 Dosovitskiy` | [[./files/MM/[2021 @google @vit Dosovitskiy] An Image is Worth 16x16 Words_Transformers for Image Recognition at Scale.pdf|An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale]] | #paper/google #paper/vit
`2021 Liu` | [[./files/MM/[2021 @microsoft @swin Liu] Swin Transformer V2_Scaling Up Capacity and Resolution.pdf|Swin Transformer V2: Scaling Up Capacity and Resolution]] | #paper/microsoft #paper/swin
`2021 Liu` | [[./files/MM/[2021 @microsoft @swin Liu] Swin Transformer_Hierarchical Vision Transformer using Shifted Windows.pdf|Swin Transformer: Hierarchical Vision Transformer using Shifted Windows]] | #paper/microsoft #paper/swin
`2021 Radford` | [[./files/MM/[2021 @openai @clip Radford] Learning Transferable Visual Models From Natural Language Supervision.pdf|Learning Transferable Visual Models From Natural Language Supervision]] | #paper/openai #paper/clip
`2021 Rombach` | [[./files/MM/[2021 @diffusion Rombach] High-Resolution Image Synthesis with Latent Diffusion Models.pdf|High-Resolution Image Synthesis with Latent Diffusion Models]] | #paper/diffusion
%%AUTOGENERATED_MM%%

## UNSORTED

%%AUTOGENERATED_UNSORTED%%
`2025 Shen` | [[./files/UNSORTED/[2025 @sap Shen] ACL'25 HELM.pdf|ACL'25 HELM]] | #paper/sap
`2024 HAI` | [[./files/UNSORTED/[2024 HAI] AI Index Report 2024.pdf|AI Index Report 2024]]
`2023 Liu` | [[./files/UNSORTED/[2023 Liu] iTransformer_Inverted Transformers Are Effective for Time Series Forecasting.pdf|iTransformer: Inverted Transformers Are Effective for Time Series Forecasting]]
%%AUTOGENERATED_UNSORTED%%
