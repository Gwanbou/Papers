import datetime
import os
import re
from typing import List

import pandas as pd
from tabulate import tabulate


def update_database(file_path: str, data_path: str, topics: List[str], columns: List[str]) -> pd.DataFrame:
    paper_df = pd.DataFrame(columns=columns)

    for topic in topics:
        paper_files = [f for f in os.listdir(file_path + topic) if f.endswith('.pdf')]
        paper_files.sort()

        note_files = [f for f in os.listdir(file_path + topic) if f.endswith('.md')]
        note_files.sort()

        for paper_file in paper_files:
            paper_file_name = paper_file.replace('.pdf', '')
            metadata = re.search(r'\[(.*?)\]', paper_file_name).group(1)
            year = metadata.split(' ')[0]
            author = metadata.split(' ')[-1]
            title = paper_file_name.split('] ')[1]
            link = os.path.join(file_path, topic, paper_file)
            tag = re.findall(r'@([\w\.-]+)', paper_file_name)
            tag = ' '.join(f'#paper/{t}' for t in tag)
            date = datetime.datetime.fromtimestamp(os.stat(link).st_mtime).strftime('%Y-%m-%d')
            note = paper_file_name if paper_file_name + '.md' in note_files else ''

            row = pd.DataFrame([[topic, year, author, title, link, tag, date, note]], columns=columns)
            paper_df = pd.concat([paper_df, row], ignore_index=True)

    printed_columns = ['topic', 'year', 'author', 'title', 'tags', 'date']
    markdown_table = tabulate(paper_df[printed_columns], headers='keys', tablefmt='pipe', showindex=False)
    print(markdown_table)
    print(f'Extracted {len(paper_df)} papers.')

    paper_df = paper_df.sort_values(['topic', 'date', 'link'], ascending=[True, False, True], ignore_index=True)
    paper_df.to_csv(data_path, index=False)


def load_table_entries(path: str, topic: str, format: str) -> List[str]:
    df = pd.read_csv(path, dtype=str)
    df = df[df['topic'] == topic]
    df.columns = df.columns.str.strip()
    if format == 'markdown':
        return [format_entry_markdown(row) for _, row in df.iterrows()]
    elif format == 'paper_vault':
        return [format_entry_paper_vault(row) for _, row in df.iterrows()]


def format_entry_markdown(entry: pd.Series) -> str:
    year = entry.loc['year']
    author = entry.loc['author']
    title = entry.loc['title'].replace('_', ': ')
    link = entry.loc['link'].replace(' ', '%20')
    tags = entry.loc['tags'] if isinstance(entry.loc['tags'], str) else ''
    tags = tags.replace('paper/', '')
    entry_str = f'- `{year} {author}` | [{title}]({link})'
    if tags:
        entry_str += f' | {tags}'

    return entry_str


def format_entry_paper_vault(entry: pd.Series) -> str:
    year = entry.loc['year']
    author = entry.loc['author']
    title = entry.loc['title'].replace('_', ': ')
    link = entry.loc['link']
    tags = entry.loc['tags'] if isinstance(entry.loc['tags'], str) else ''
    note = entry.loc['note'] if isinstance(entry.loc['note'], str) else None
    entry_str = f'[[{note}|:LiNotepadText:]] ' if note is not None else ''
    entry_str += f'`{year} {author}` | [[{link}|{title}]]'
    if tags:
        entry_str += f' | {tags}'

    return entry_str


def read_lines_from_file(path: str) -> List[str]:
    '''Reads lines from file and strips trailing whitespaces.'''
    with open(path) as file:
        return [line.rstrip() for line in file]


def inject_markdown_table_into_readme(readme_lines: List[str], table_lines: List[str], topic: str,
                                      tokens: dict) -> List[str]:
    '''Injects markdown table into readme.'''
    lines_with_token_indexes = search_lines_with_token(lines=readme_lines, token=tokens.get(topic))
    if len(lines_with_token_indexes) != 2:
        raise Exception(f'Please inject two {tokens.get(topic)} '
                        f'tokens to signal start and end of autogenerated table.')

    [table_start_line_index, table_end_line_index] = lines_with_token_indexes
    return readme_lines[:table_start_line_index + 1] + table_lines + readme_lines[table_end_line_index:]


def search_lines_with_token(lines: List[str], token: str) -> List[int]:
    '''Searches for lines with token. '''
    result = []
    for line_index, line in enumerate(lines):
        if token in line:
            result.append(line_index)
    return result


def save_lines_to_file(path: str, lines: List[str]) -> None:
    '''Saves lines to file. '''
    with open(path, 'w') as f:
        for line in lines:
            f.write('%s\n' % line)


if __name__ == '__main__':
    file_path = './files/'
    data_path = './automation/database.csv'
    readme_path = './README.md'
    paper_vault_path = './Paper Vault.md'

    columns = ['topic', 'year', 'author', 'title', 'link', 'tags', 'date', 'note']
    topics = [f for f in os.listdir(file_path) if os.path.isdir(os.path.join(file_path, f))]
    topics.sort()
    markdown_tokens = {}
    paper_vault_tokens = {}
    for topic in topics:
        markdown_tokens[topic] = f'<!-- AUTOGENERATED_{topic} -->'
        paper_vault_tokens[topic] = f'%%AUTOGENERATED_{topic}%%'

    update_database(file_path=file_path, data_path=data_path, topics=topics, columns=columns)

    for topic in topics:
        # Update README
        table_lines = load_table_entries(path=data_path, topic=topic, format='markdown')
        readme_lines = read_lines_from_file(path=readme_path)
        readme_lines = inject_markdown_table_into_readme(readme_lines=readme_lines,
                                                         table_lines=table_lines,
                                                         topic=topic,
                                                         tokens=markdown_tokens)
        save_lines_to_file(path=readme_path, lines=readme_lines)

        # Update Paper Vault
        table_lines = load_table_entries(path=data_path, topic=topic, format='paper_vault')
        readme_lines = read_lines_from_file(path=paper_vault_path)
        readme_lines = inject_markdown_table_into_readme(readme_lines=readme_lines,
                                                         table_lines=table_lines,
                                                         topic=topic,
                                                         tokens=paper_vault_tokens)
        save_lines_to_file(path=paper_vault_path, lines=readme_lines)
